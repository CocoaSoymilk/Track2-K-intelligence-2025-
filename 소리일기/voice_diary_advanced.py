import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import json
import os
import base64
import io
import numpy as np
from typing import Dict, List, Tuple, Optional
import tempfile
import warnings
warnings.filterwarnings('ignore')

# íŒ¨í‚¤ì§€ import ì•ˆì „ì„± ì²˜ë¦¬
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    st.error("Plotly íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    PLOTLY_AVAILABLE = False
    px = None
    go = None

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    st.warning("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    OPENAI_AVAILABLE = False
    openai = None

try:
    import librosa
    import scipy.stats
    from scipy import signal
    AUDIO_ANALYSIS_AVAILABLE = True
except ImportError:
    st.warning("ìŒì„± ë¶„ì„ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ë§Œ ì œê³µë©ë‹ˆë‹¤.")
    AUDIO_ANALYSIS_AVAILABLE = False
    librosa = None
    scipy = None

try:
    import parselmouth
    from parselmouth.praat import call
    PRAAT_AVAILABLE = True
except ImportError:
    st.info("Praat ë¶„ì„ íŒ¨í‚¤ì§€ê°€ ì—†ì–´ ê¸°ë³¸ ìŒì„± ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    PRAAT_AVAILABLE = False
    parselmouth = None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - ê³ ë„í™”",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .emotion-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #667eea;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        transition: transform 0.2s ease;
    }
    
    .emotion-card:hover {
        transform: translateY(-2px);
    }
    
    .voice-analysis-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #ff9800;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(255, 152, 0, 0.1);
    }
    
    .metric-container {
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        text-align: center;
        border: 1px solid #e9ecef;
        transition: all 0.3s ease;
    }
    
    .metric-container:hover {
        box-shadow: 0 6px 20px rgba(0,0,0,0.15);
        transform: translateY(-3px);
    }
    
    .feedback-box {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #2196f3;
        margin: 1rem 0;
        box-shadow: 0 4px 12px rgba(33, 150, 243, 0.15);
    }
    
    .recording-container {
        text-align: center;
        padding: 2rem;
        background: #f8f9fa;
        border-radius: 15px;
        margin: 1rem 0;
        border: 2px dashed #667eea;
    }
    
    .prosodic-meter {
        background: white;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    /* ë°˜ì‘í˜• ë””ìì¸ */
    @media (max-width: 768px) {
        .main-header {
            padding: 1rem;
        }
        
        .emotion-card, .metric-container, .feedback-box, .voice-analysis-card {
            margin: 0.5rem 0;
            padding: 1rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'diary_entries' not in st.session_state:
    st.session_state.diary_entries = []

# OpenAI API í‚¤ ì„¤ì •
@st.cache_resource
def init_openai():
    """OpenAI API ì´ˆê¸°í™”"""
    if not OPENAI_AVAILABLE:
        return None
        
    try:
        if "OPENAI_API_KEY" in st.secrets:
            return openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        elif "openai_api_key" in st.session_state and st.session_state.openai_api_key:
            return openai.OpenAI(api_key=st.session_state.openai_api_key)
        else:
            return None
    except Exception as e:
        st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = init_openai()

class VoiceFeatureExtractor:
    """ìŒì„± í”¼ì²˜ ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.sample_rate = 22050
        
    def extract_prosodic_features(self, audio_bytes: bytes) -> Dict:
        """ìŒì„±ì—ì„œ prosodic features ì¶”ì¶œ"""
        try:
            if not AUDIO_ANALYSIS_AVAILABLE:
                return self._get_default_features()
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(audio_bytes)
                tmp_file_path = tmp_file.name
            
            try:
                # librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
                y, sr = librosa.load(tmp_file_path, sr=self.sample_rate)
                
                # ê¸°ë³¸ í”¼ì²˜ë“¤ ì¶”ì¶œ
                features = {}
                
                # 1. Pitch (F0) ë¶„ì„
                pitch_features = self._extract_pitch_features(y, sr)
                features.update(pitch_features)
                
                # 2. ì—ë„ˆì§€/ê°•ë„ ë¶„ì„
                energy_features = self._extract_energy_features(y, sr)
                features.update(energy_features)
                
                # 3. ë§í•˜ê¸° ì†ë„ ë¶„ì„
                tempo_features = self._extract_tempo_features(y, sr)
                features.update(tempo_features)
                
                # 4. ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± ë¶„ì„
                spectral_features = self._extract_spectral_features(y, sr)
                features.update(spectral_features)
                
                # 5. Praat ê¸°ë°˜ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
                if PRAAT_AVAILABLE:
                    praat_features = self._extract_praat_features(tmp_file_path)
                    features.update(praat_features)
                
                return features
                
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(tmp_file_path):
                    os.unlink(tmp_file_path)
                    
        except Exception as e:
            st.warning(f"ìŒì„± í”¼ì²˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._get_default_features()
    
    def _extract_pitch_features(self, y: np.ndarray, sr: int) -> Dict:
        """í”¼ì¹˜ ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # í”¼ì¹˜ ì¶”ì¶œ (librosaì˜ piptrack ì‚¬ìš©)
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr, threshold=0.1, fmin=50, fmax=400)
            
            # ìœ íš¨í•œ í”¼ì¹˜ ê°’ë§Œ ì¶”ì¶œ
            valid_pitches = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    valid_pitches.append(pitch)
            
            if len(valid_pitches) == 0:
                return {
                    'pitch_mean': 150.0,  # ê¸°ë³¸ê°’
                    'pitch_std': 20.0,
                    'pitch_range': 50.0,
                    'pitch_variation': 0.13
                }
            
            pitch_array = np.array(valid_pitches)
            
            return {
                'pitch_mean': float(np.mean(pitch_array)),
                'pitch_std': float(np.std(pitch_array)),
                'pitch_range': float(np.max(pitch_array) - np.min(pitch_array)),
                'pitch_variation': float(np.std(pitch_array) / np.mean(pitch_array)) if np.mean(pitch_array) > 0 else 0.1
            }
        except:
            return {
                'pitch_mean': 150.0,
                'pitch_std': 20.0,
                'pitch_range': 50.0,
                'pitch_variation': 0.13
            }
    
    def _extract_energy_features(self, y: np.ndarray, sr: int) -> Dict:
        """ì—ë„ˆì§€/ê°•ë„ ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # RMS ì—ë„ˆì§€
            rms_energy = librosa.feature.rms(y=y)[0]
            
            # ìŠ¤í™íŠ¸ëŸ¼ ë¡¤ì˜¤í”„ (ì—ë„ˆì§€ ë¶„í¬ì˜ 85% ì§€ì )
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            
            return {
                'energy_mean': float(np.mean(rms_energy)),
                'energy_std': float(np.std(rms_energy)),
                'energy_max': float(np.max(rms_energy)),
                'spectral_rolloff_mean': float(np.mean(spectral_rolloff))
            }
        except:
            return {
                'energy_mean': 0.1,
                'energy_std': 0.02,
                'energy_max': 0.3,
                'spectral_rolloff_mean': 3000.0
            }
    
    def _extract_tempo_features(self, y: np.ndarray, sr: int) -> Dict:
        """í…œí¬/ë¦¬ë“¬ ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # í…œí¬ ì¶”ì •
            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
            
            # Zero Crossing Rate (ìŒì„± í™œë™ì„±ì˜ ì§€í‘œ)
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            
            return {
                'tempo': float(tempo),
                'zcr_mean': float(np.mean(zcr)),
                'zcr_std': float(np.std(zcr))
            }
        except:
            return {
                'tempo': 120.0,
                'zcr_mean': 0.1,
                'zcr_std': 0.05
            }
    
    def _extract_spectral_features(self, y: np.ndarray, sr: int) -> Dict:
        """ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # Spectral Centroid (ìŒìƒ‰ì˜ ë°ê¸°)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            
            # Spectral Bandwidth
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            
            # MFCC (ìŒì„± íŠ¹ì„±)
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            return {
                'spectral_centroid_mean': float(np.mean(spectral_centroids)),
                'spectral_centroid_std': float(np.std(spectral_centroids)),
                'spectral_bandwidth_mean': float(np.mean(spectral_bandwidth)),
                'mfcc_mean': float(np.mean(mfccs[1:5])),  # 1-4ë²ˆì§¸ MFCC ê³„ìˆ˜ë“¤ì˜ í‰ê· 
                'mfcc_std': float(np.mean(np.std(mfccs[1:5], axis=1)))
            }
        except:
            return {
                'spectral_centroid_mean': 2000.0,
                'spectral_centroid_std': 500.0,
                'spectral_bandwidth_mean': 1500.0,
                'mfcc_mean': 0.0,
                'mfcc_std': 1.0
            }
    
    def _extract_praat_features(self, audio_path: str) -> Dict:
        """Praatì„ í†µí•œ ê³ ê¸‰ ìŒì„±í•™ì  ë¶„ì„"""
        try:
            sound = parselmouth.Sound(audio_path)
            
            # Pitch ê°ì²´ ìƒì„±
            pitch = sound.to_pitch()
            
            # Jitterì™€ Shimmer (ìŒì„± ì•ˆì •ì„± ì§€í‘œ)
            point_process = call(sound, "To PointProcess (periodic, cc)", 75, 500)
            jitter = call(point_process, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3)
            shimmer = call([sound, point_process], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
            
            # Harmonics-to-Noise Ratio
            harmonicity = sound.to_harmonicity()
            hnr = call(harmonicity, "Get mean", 0, 0)
            
            return {
                'jitter': float(jitter) if not np.isnan(jitter) else 0.01,
                'shimmer': float(shimmer) if not np.isnan(shimmer) else 0.05,
                'hnr': float(hnr) if not np.isnan(hnr) else 15.0
            }
        except Exception as e:
            return {
                'jitter': 0.01,
                'shimmer': 0.05,
                'hnr': 15.0
            }
    
    def _get_default_features(self) -> Dict:
        """ê¸°ë³¸ í”¼ì²˜ ê°’ë“¤ (ë¶„ì„ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°)"""
        return {
            'pitch_mean': 150.0,
            'pitch_std': 20.0,
            'pitch_range': 50.0,
            'pitch_variation': 0.13,
            'energy_mean': 0.1,
            'energy_std': 0.02,
            'energy_max': 0.3,
            'spectral_rolloff_mean': 3000.0,
            'tempo': 120.0,
            'zcr_mean': 0.1,
            'zcr_std': 0.05,
            'spectral_centroid_mean': 2000.0,
            'spectral_centroid_std': 500.0,
            'spectral_bandwidth_mean': 1500.0,
            'mfcc_mean': 0.0,
            'mfcc_std': 1.0,
            'jitter': 0.01,
            'shimmer': 0.05,
            'hnr': 15.0
        }

class EmotionAnalyzer:
    """ìŒì„± í”¼ì²˜ ê¸°ë°˜ ê°ì • ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ê°ì •ë³„ ìŒì„± í”¼ì²˜ ê¸°ì¤€ê°’ (ì„ í–‰ ì—°êµ¬ ê¸°ë°˜)
        self.emotion_profiles = {
            'ê¸°ì¨': {
                'pitch_mean': (180, 220),  # ë†’ì€ í”¼ì¹˜
                'pitch_variation': (0.15, 0.25),  # ë†’ì€ ë³€ë™ì„±
                'energy_mean': (0.15, 0.35),  # ë†’ì€ ì—ë„ˆì§€
                'tempo': (130, 160),  # ë¹ ë¥¸ í…œí¬
                'spectral_centroid_mean': (2200, 3000),  # ë°ì€ ìŒìƒ‰
                'jitter': (0.005, 0.015),  # ë‚®ì€ jitter (ì•ˆì •ì )
            },
            'ìŠ¬í””': {
                'pitch_mean': (100, 140),  # ë‚®ì€ í”¼ì¹˜
                'pitch_variation': (0.08, 0.15),  # ë‚®ì€ ë³€ë™ì„±
                'energy_mean': (0.05, 0.15),  # ë‚®ì€ ì—ë„ˆì§€
                'tempo': (80, 110),  # ëŠë¦° í…œí¬
                'spectral_centroid_mean': (1500, 2200),  # ì–´ë‘ìš´ ìŒìƒ‰
                'jitter': (0.008, 0.020),  # ì•½ê°„ ë†’ì€ jitter
            },
            'ë¶„ë…¸': {
                'pitch_mean': (160, 200),  # ë†’ì€ í”¼ì¹˜
                'pitch_variation': (0.20, 0.35),  # ë§¤ìš° ë†’ì€ ë³€ë™ì„±
                'energy_mean': (0.20, 0.40),  # ë§¤ìš° ë†’ì€ ì—ë„ˆì§€
                'tempo': (140, 180),  # ë§¤ìš° ë¹ ë¥¸ í…œí¬
                'spectral_centroid_mean': (2500, 3500),  # ë§¤ìš° ë°ì€/ê±°ì¹œ ìŒìƒ‰
                'jitter': (0.015, 0.030),  # ë†’ì€ jitter (ë¶ˆì•ˆì •)
            },
            'ë¶ˆì•ˆ': {
                'pitch_mean': (150, 190),  # ì•½ê°„ ë†’ì€ í”¼ì¹˜
                'pitch_variation': (0.18, 0.30),  # ë†’ì€ ë³€ë™ì„±
                'energy_mean': (0.10, 0.25),  # ì¤‘ê°„ ì—ë„ˆì§€
                'tempo': (110, 140),  # ì•½ê°„ ë¹ ë¥¸ í…œí¬
                'spectral_centroid_mean': (2000, 2800),  # ì•½ê°„ ë°ì€ ìŒìƒ‰
                'jitter': (0.012, 0.025),  # ë†’ì€ jitter
            },
            'í‰ì˜¨': {
                'pitch_mean': (130, 160),  # ì¤‘ê°„ í”¼ì¹˜
                'pitch_variation': (0.10, 0.18),  # ë‚®ì€ ë³€ë™ì„±
                'energy_mean': (0.08, 0.20),  # ì¤‘ê°„ ì—ë„ˆì§€
                'tempo': (100, 130),  # ì¤‘ê°„ í…œí¬
                'spectral_centroid_mean': (1800, 2400),  # ë¶€ë“œëŸ¬ìš´ ìŒìƒ‰
                'jitter': (0.005, 0.012),  # ë‚®ì€ jitter (ì•ˆì •ì )
            }
        }
    
    def analyze_emotion_from_voice(self, voice_features: Dict) -> Dict:
        """ìŒì„± í”¼ì²˜ë¡œë¶€í„° ê°ì • ë¶„ì„"""
        emotion_scores = {}
        
        for emotion, profile in self.emotion_profiles.items():
            score = self._calculate_emotion_score(voice_features, profile)
            emotion_scores[emotion] = score
        
        # ì ìˆ˜ ì •ê·œí™”
        total_score = sum(emotion_scores.values())
        if total_score > 0:
            emotion_scores = {k: v/total_score for k, v in emotion_scores.items()}
        
        # ìƒìœ„ ê°ì •ë“¤ ì„ íƒ
        sorted_emotions = sorted(emotion_scores.items(), key=lambda x: x[1], reverse=True)
        detected_emotions = [emotion for emotion, score in sorted_emotions[:3] if score > 0.15]
        
        if not detected_emotions:
            detected_emotions = ['ì¤‘ë¦½']
        
        # ê°ì • ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤/ì—ë„ˆì§€/ê¸°ë¶„ ì ìˆ˜ ê³„ì‚°
        stress_level = self._calculate_stress_level(voice_features, emotion_scores)
        energy_level = self._calculate_energy_level(voice_features, emotion_scores)
        mood_score = self._calculate_mood_score(voice_features, emotion_scores)
        
        return {
            'detected_emotions': detected_emotions,
            'emotion_scores': emotion_scores,
            'voice_stress_level': stress_level,
            'voice_energy_level': energy_level,
            'voice_mood_score': mood_score,
            'voice_features': voice_features
        }
    
    def _calculate_emotion_score(self, features: Dict, profile: Dict) -> float:
        """íŠ¹ì • ê°ì •ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        feature_count = 0
        
        for feature_name, (min_val, max_val) in profile.items():
            if feature_name in features:
                feature_value = features[feature_name]
                
                # ë²”ìœ„ ë‚´ì— ìˆìœ¼ë©´ 1, ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ê±°ë¦¬ì— ë”°ë¼ ê°ì†Œ
                if min_val <= feature_value <= max_val:
                    score += 1.0
                else:
                    # ë²”ìœ„ì—ì„œ ë²—ì–´ë‚œ ì •ë„ì— ë”°ë¼ ì ìˆ˜ ê°ì†Œ
                    range_center = (min_val + max_val) / 2
                    range_width = max_val - min_val
                    distance = abs(feature_value - range_center)
                    normalized_distance = distance / (range_width / 2)
                    score += max(0, 1 - normalized_distance * 0.5)
                
                feature_count += 1
        
        return score / feature_count if feature_count > 0 else 0.0
    
    def _calculate_stress_level(self, features: Dict, emotion_scores: Dict) -> int:
        """ìŒì„± ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ë ˆë²¨ ê³„ì‚° (0-100) - ë³´ì¡°ì  ì—­í• """
        base_stress = 20  # ê¸°ë³¸ê°’ì„ ë‚®ì¶¤
        
        # ê°ì •ë³„ ìŠ¤íŠ¸ë ˆìŠ¤ ê°€ì¤‘ì¹˜ (ì™„í™”)
        stress_weights = {
            'ë¶„ë…¸': 25,      # 35 -> 25
            'ë¶ˆì•ˆ': 20,      # 30 -> 20  
            'ìŠ¬í””': 15,      # 20 -> 15
            'ê¸°ì¨': -20,     # -15 -> -20 (ê¸ì • ë³´ìƒ ì¦ê°€)
            'í‰ì˜¨': -25      # -20 -> -25 (í‰ì˜¨ ë³´ìƒ ì¦ê°€)
        }
        
        for emotion, weight in stress_weights.items():
            if emotion in emotion_scores:
                base_stress += weight * emotion_scores[emotion] * 0.6  # ìŒì„± ì˜í–¥ë ¥ ê°ì†Œ
        
        # ìŒì„± í”¼ì²˜ ê¸°ë°˜ ì¡°ì • (ì™„í™”)
        if features.get('jitter', 0) > 0.025:  # ì„ê³„ê°’ ìƒí–¥ (0.02 -> 0.025)
            base_stress += 8  # í˜ë„í‹° ê°ì†Œ (15 -> 8)
        
        if features.get('pitch_variation', 0) > 0.30:  # ì„ê³„ê°’ ìƒí–¥ (0.25 -> 0.30)
            base_stress += 5  # í˜ë„í‹° ê°ì†Œ (10 -> 5)
        
        return max(0, min(100, int(base_stress)))
    
    def _calculate_energy_level(self, features: Dict, emotion_scores: Dict) -> int:
        """ìŒì„± ê¸°ë°˜ ì—ë„ˆì§€ ë ˆë²¨ ê³„ì‚° (0-100) - ë³´ì¡°ì  ì—­í• """
        base_energy = 55  # ê¸°ë³¸ê°’ì„ ì•½ê°„ ìƒí–¥
        
        # ê°ì •ë³„ ì—ë„ˆì§€ ê°€ì¤‘ì¹˜ (ê¸ì • ê°ì • ë³´ê°•)
        energy_weights = {
            'ê¸°ì¨': 30,      # 25 -> 30 (ê¸ì • ë³´ìƒ ì¦ê°€)
            'ë¶„ë…¸': 20,      # 30 -> 20 (ë¶„ë…¸ëŠ” ì—ë„ˆì§€ë³´ë‹¤ ìŠ¤íŠ¸ë ˆìŠ¤)
            'ë¶ˆì•ˆ': 5,       # 10 -> 5
            'ìŠ¬í””': -20,     # -25 -> -20 (ì™„í™”)
            'í‰ì˜¨': 0        # -5 -> 0 (í‰ì˜¨ì€ ì¤‘ë¦½ì )
        }
        
        for emotion, weight in energy_weights.items():
            if emotion in emotion_scores:
                base_energy += weight * emotion_scores[emotion] * 0.7  # ìŒì„± ì˜í–¥ë ¥ ì ë‹¹íˆ ì œí•œ
        
        # ìŒì„± í”¼ì²˜ ê¸°ë°˜ ì¡°ì • (ì™„í™”)
        energy_mean = features.get('energy_mean', 0.1)
        if energy_mean > 0.25:  # ì„ê³„ê°’ ìƒí–¥ (0.2 -> 0.25)
            base_energy += 10  # ë³´ìƒ ê°ì†Œ (15 -> 10)
        elif energy_mean < 0.06:  # ì„ê³„ê°’ í•˜í–¥ (0.08 -> 0.06)
            base_energy -= 10  # í˜ë„í‹° ê°ì†Œ (15 -> 10)
        
        tempo = features.get('tempo', 120)
        if tempo > 150:  # ì„ê³„ê°’ ìƒí–¥ (140 -> 150)
            base_energy += 8  # ë³´ìƒ ê°ì†Œ (10 -> 8)
        elif tempo < 90:  # ì„ê³„ê°’ í•˜í–¥ (100 -> 90)
            base_energy -= 8  # í˜ë„í‹° ê°ì†Œ (10 -> 8)
        
        return max(0, min(100, int(base_energy)))
    
    def _calculate_mood_score(self, features: Dict, emotion_scores: Dict) -> int:
        """ìŒì„± ê¸°ë°˜ ê¸°ë¶„ ì ìˆ˜ ê³„ì‚° (-70 to +70) - ë³´ì¡°ì  ì—­í• """
        base_mood = 5  # ì•½ê°„ ê¸ì •ì  ê¸°ë³¸ê°’
        
        # ê°ì •ë³„ ê¸°ë¶„ ê°€ì¤‘ì¹˜ (ê¸ì • ê°ì • ê°•í™”)
        mood_weights = {
            'ê¸°ì¨': 45,      # 40 -> 45 (ê¸ì • ë³´ìƒ ì¦ê°€)
            'í‰ì˜¨': 25,      # 20 -> 25 (í‰ì˜¨ ë³´ìƒ ì¦ê°€)
            'ìŠ¬í””': -25,     # -35 -> -25 (í˜ë„í‹° ê°ì†Œ)
            'ë¶„ë…¸': -20,     # -25 -> -20 (í˜ë„í‹° ê°ì†Œ)
            'ë¶ˆì•ˆ': -15      # -20 -> -15 (í˜ë„í‹° ê°ì†Œ)
        }
        
        for emotion, weight in mood_weights.items():
            if emotion in emotion_scores:
                base_mood += weight * emotion_scores[emotion] * 0.5  # ìŒì„± ì˜í–¥ë ¥ í¬ê²Œ ì œí•œ
        
        # ìŒì„± í’ˆì§ˆ ê¸°ë°˜ ì¡°ì • (ë¯¸ë¯¸í•˜ê²Œ)
        hnr = features.get('hnr', 15.0)
        if hnr > 22:  # ì„ê³„ê°’ ìƒí–¥ (20 -> 22)
            base_mood += 3  # ë³´ìƒ ê°ì†Œ (5 -> 3)
        elif hnr < 8:  # ì„ê³„ê°’ í•˜í–¥ (10 -> 8)
            base_mood -= 3  # í˜ë„í‹° ê°ì†Œ (5 -> 3)
        
        return max(-70, min(70, int(base_mood)))

def transcribe_audio_with_whisper(audio_bytes):
    """Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not openai_client:
        return None
    
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name
        
        # Whisper API í˜¸ì¶œ
        with open(tmp_file_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ko"
            )
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(tmp_file_path)
        
        return transcript.text
        
    except Exception as e:
        st.error(f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
        return None

def analyze_emotion_with_gpt(text: str, voice_analysis: Optional[Dict] = None) -> Dict:
    """GPT-4ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ìŒì„± ë¶„ì„ì„ ì¢…í•©í•œ ê°ì • ë¶„ì„"""
    if not openai_client:
        return analyze_emotion_simulation(text, voice_analysis)
    
    try:
        # ìŒì„± ë¶„ì„ ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        voice_context = ""
        if voice_analysis:
            voice_context = f"""
            
            ì¶”ê°€ë¡œ, ìŒì„± ë¶„ì„ ê²°ê³¼ë„ ì°¸ê³ í•´ì£¼ì„¸ìš”:
            - ìŒì„±ìœ¼ë¡œ ê°ì§€ëœ ê°ì •: {', '.join(voice_analysis.get('detected_emotions', []))}
            - ìŒì„± ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤: {voice_analysis.get('voice_stress_level', 30)}%
            - ìŒì„± ê¸°ë°˜ ì—ë„ˆì§€: {voice_analysis.get('voice_energy_level', 50)}%
            - ìŒì„± ê¸°ë°˜ ê¸°ë¶„: {voice_analysis.get('voice_mood_score', 0)}
            """
        
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": f"""ë‹¹ì‹ ì€ "ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨" ì„œë¹„ìŠ¤ì˜ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ AI ë§ˆìŒ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
                    ì‚¬ìš©ìê°€ ìŒì„±ì´ë‚˜ ê¸€ë¡œ ë“¤ë ¤ì¤€ í•˜ë£¨ ì´ì•¼ê¸°ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
                    
                    í…ìŠ¤íŠ¸ ë¶„ì„ê³¼ ìŒì„± ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë” ì •í™•í•œ ê°ì • ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                    {voice_context}
                    
                    ì‘ë‹µ í˜•ì‹:
                    {{
                        "emotions": ["ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ë¶ˆì•ˆ", "í‰ì˜¨", "ì¤‘ë¦½" ì¤‘ í•´ë‹¹í•˜ëŠ” ê²ƒë“¤ì˜ ë°°ì—´],
                        "stress_level": ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¹˜ (0-100ì˜ ì •ìˆ˜),
                        "energy_level": ì—ë„ˆì§€ ìˆ˜ì¹˜ (0-100ì˜ ì •ìˆ˜),
                        "mood_score": ì „ì²´ì ì¸ ë§ˆìŒ ì ìˆ˜ (-70ë¶€í„° +70 ì‚¬ì´ì˜ ì •ìˆ˜),
                        "summary": "ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ í†¤ìœ¼ë¡œ í•œë‘ ë¬¸ì¥ ìš”ì•½",
                        "keywords": ["í•µì‹¬ í‚¤ì›Œë“œë“¤"],
                        "tone": "ê¸ì •ì " ë˜ëŠ” "ì¤‘ë¦½ì " ë˜ëŠ” "ë¶€ì •ì ",
                        "confidence": ë¶„ì„ ì‹ ë¢°ë„ (0.0-1.0, ìŒì„± ë¶„ì„ì´ ìˆìœ¼ë©´ ë” ë†’ê²Œ)
                    }}
                    
                    ì‚¬ìš©ìì˜ ë§ˆìŒì„ ê¹Šì´ ì´í•´í•˜ê³ , ë”°ëœ»í•˜ê²Œ ê³µê°í•˜ëŠ” ë¶„ì„ì„ í•´ì£¼ì„¸ìš”."""
                },
                {
                    "role": "user",
                    "content": f"ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ì£¼ì„¸ìš”: {text}"
                }
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1]
            
            result = json.loads(result_text.strip())
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
            required_fields = {
                'emotions': ['ì¤‘ë¦½'],
                'stress_level': 30,
                'energy_level': 50,
                'mood_score': 0,
                'summary': 'ì¼ë°˜ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.',
                'keywords': [],
                'tone': 'ì¤‘ë¦½ì ',
                'confidence': 0.7
            }
            
            for field, default_value in required_fields.items():
                if field not in result:
                    result[field] = default_value
            
            # ìŒì„± ë¶„ì„ì´ ìˆìœ¼ë©´ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ê²°í•©
            if voice_analysis:
                result = combine_text_and_voice_analysis(result, voice_analysis)
            
            return result
            
        except json.JSONDecodeError:
            st.warning("GPT ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            return analyze_emotion_simulation(text, voice_analysis)
        
    except Exception as e:
        st.error(f"GPT ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return analyze_emotion_simulation(text, voice_analysis)

def combine_text_and_voice_analysis(text_analysis: Dict, voice_analysis: Dict) -> Dict:
    """í…ìŠ¤íŠ¸ ë¶„ì„ê³¼ ìŒì„± ë¶„ì„ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„± - í…ìŠ¤íŠ¸ ìš°ì„ """
    
    # ê°€ì¤‘ì¹˜ ì„¤ì • (í…ìŠ¤íŠ¸ ìš°ì„ : í…ìŠ¤íŠ¸ 80%, ìŒì„± 20%)
    text_weight = 0.8
    voice_weight = 0.2
    
    # ê°ì • ê²°í•© (í…ìŠ¤íŠ¸ ê°ì •ì„ ìš°ì„ í•˜ë˜, ìŒì„±ì€ ë³´ì¡°ì ìœ¼ë¡œ)
    text_emotions = set(text_analysis.get('emotions', []))
    voice_emotions = set(voice_analysis.get('detected_emotions', []))
    
    # í…ìŠ¤íŠ¸ ê°ì •ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ê³ , ìŒì„±ì€ ë³´ì¡°ì ìœ¼ë¡œë§Œ ì¶”ê°€
    combined_emotions = list(text_emotions)
    for voice_emotion in voice_emotions:
        if voice_emotion not in combined_emotions and len(combined_emotions) < 3:
            combined_emotions.append(voice_emotion)
    
    if not combined_emotions:
        combined_emotions = ['ì¤‘ë¦½']
    
    # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê¸ì •ì„± ì²´í¬
    text_positive = any(emotion in ['ê¸°ì¨', 'í‰ì˜¨'] for emotion in text_emotions)
    text_negative = any(emotion in ['ìŠ¬í””', 'ë¶„ë…¸', 'ë¶ˆì•ˆ'] for emotion in text_emotions)
    
    # ìˆ˜ì¹˜ ê²°í•© (í…ìŠ¤íŠ¸ ìš°ì„ , ìŒì„±ì€ ë¯¸ì„¸ ì¡°ì •)
    text_stress = text_analysis.get('stress_level', 30)
    voice_stress = voice_analysis.get('voice_stress_level', 30)
    text_energy = text_analysis.get('energy_level', 50)
    voice_energy = voice_analysis.get('voice_energy_level', 50)
    text_mood = text_analysis.get('mood_score', 0)
    voice_mood = voice_analysis.get('voice_mood_score', 0)
    
    # í…ìŠ¤íŠ¸ê°€ ê¸ì •ì ì´ë©´ ìŒì„±ì˜ ë¶€ì •ì  ì˜í–¥ ì œí•œ
    if text_positive:
        # ê¸ì •ì  í…ìŠ¤íŠ¸ì¸ ê²½ìš°, ìŒì„± ì˜í–¥ë ¥ ë” ì¶•ì†Œ
        combined_stress = int(text_stress * 0.9 + voice_stress * 0.1)
        combined_energy = int(text_energy * 0.85 + voice_energy * 0.15)
        combined_mood = int(text_mood * 0.85 + voice_mood * 0.15)
        
        # ì¶”ê°€ì ìœ¼ë¡œ ê¸ì • ë³´ì •
        combined_stress = max(10, combined_stress - 10)  # ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”
        combined_energy = min(90, combined_energy + 5)   # ì—ë„ˆì§€ ì•½ê°„ ì¦ê°€
        combined_mood = min(70, combined_mood + 8)       # ê¸°ë¶„ ê°œì„ 
        
    elif text_negative:
        # ë¶€ì •ì  í…ìŠ¤íŠ¸ì¸ ê²½ìš°, ìŒì„±ì´ ì™„í™” ì—­í• ì„ í•  ìˆ˜ ìˆë„ë¡
        combined_stress = int(text_stress * 0.75 + voice_stress * 0.25)
        combined_energy = int(text_energy * 0.75 + voice_energy * 0.25)
        combined_mood = int(text_mood * 0.75 + voice_mood * 0.25)
        
    else:
        # ì¤‘ë¦½ì ì¸ ê²½ìš°, í‘œì¤€ ê°€ì¤‘ì¹˜
        combined_stress = int(text_stress * text_weight + voice_stress * voice_weight)
        combined_energy = int(text_energy * text_weight + voice_energy * voice_weight)
        combined_mood = int(text_mood * text_weight + voice_mood * voice_weight)
    
    # ì „ì²´ì ì¸ ê· í˜• ì¡°ì • (ì›°ë¹™ ê³ ë ¤)
    # ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ì™„í™”
    if combined_stress > 70:
        combined_stress = int(combined_stress * 0.85)
    
    # ì‹ ë¢°ë„ í–¥ìƒ (ìŒì„± ë¶„ì„ì´ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ë¶„ì„ì˜ ì‹ ë¢°ë„ ë³´ê°•)
    base_confidence = text_analysis.get('confidence', 0.7)
    confidence = min(1.0, base_confidence + 0.15)  # ì ë‹¹í•œ ì‹ ë¢°ë„ ì¦ê°€
    
    return {
        'emotions': combined_emotions[:3],  # ìµœëŒ€ 3ê°œ ê°ì •
        'stress_level': max(0, min(100, combined_stress)),
        'energy_level': max(0, min(100, combined_energy)),
        'mood_score': max(-70, min(70, combined_mood)),
        'summary': text_analysis.get('summary', 'í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¢…í•© ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
        'keywords': text_analysis.get('keywords', []),
        'tone': text_analysis.get('tone', 'ì¤‘ë¦½ì '),  # í…ìŠ¤íŠ¸ í†¤ ìš°ì„ 
        'confidence': confidence,
        'voice_analysis': voice_analysis  # ìŒì„± ë¶„ì„ ê²°ê³¼ë„ ì €ì¥ (ì°¸ê³ ìš©)
    }

def analyze_emotion_simulation(text: str, voice_analysis: Optional[Dict] = None) -> Dict:
    """GPT API ì—†ì´ ê¸°ë³¸ ê°ì • ë¶„ì„"""
    emotions_map = {
        'ê¸°ì¨': ['ì¢‹ë‹¤', 'í–‰ë³µ', 'ê¸°ì˜ë‹¤', 'ì¦ê²ë‹¤', 'ì›ƒìŒ', 'ì„±ê³µ', 'ë¿Œë“¯', 'ë§Œì¡±', 'ì‚¬ë‘', 'ê³ ë§ˆìš´'],
        'ìŠ¬í””': ['ìŠ¬í”„ë‹¤', 'ìš°ìš¸', 'ëˆˆë¬¼', 'í˜ë“¤ë‹¤', 'ì‹¤ë§', 'ì•„í”„ë‹¤', 'ì™¸ë¡­ë‹¤', 'ê·¸ë¦½ë‹¤'],
        'ë¶„ë…¸': ['í™”ë‚˜ë‹¤', 'ì§œì¦', 'ë¶„í•˜ë‹¤', 'ì–µìš¸', 'ë‹µë‹µ', 'ì—´ë°›ë‹¤', 'ë¯¸ì¹˜ê² ë‹¤'],
        'ë¶ˆì•ˆ': ['ê±±ì •', 'ë¶ˆì•ˆ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'ë‘ë µë‹¤', 'ê¸´ì¥', 'ë¬´ì„œì›Œ', 'ì´ˆì¡°'],
        'í‰ì˜¨': ['í‰ì˜¨', 'ì°¨ë¶„', 'ì•ˆì •', 'í¸ì•ˆ', 'íœ´ì‹', 'ì—¬ìœ ', 'ê³ ìš”']
    }
    
    detected_emotions = []
    stress_level = 30
    energy_level = 50
    keywords = []
    
    text_lower = text.lower()
    
    # ê°ì • í‚¤ì›Œë“œ ê°ì§€
    for emotion, emotion_keywords in emotions_map.items():
        for keyword in emotion_keywords:
            if keyword in text_lower:
                detected_emotions.append(emotion)
                keywords.append(keyword)
                break
    
    # ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ì—ë„ˆì§€ ìˆ˜ì¤€ ì¶”ì •
    stress_keywords = ['ìŠ¤íŠ¸ë ˆìŠ¤', 'í˜ë“¤ë‹¤', 'í”¼ê³¤', 'ì§€ì³', 'í™”ë‚˜ë‹¤', 'ê±±ì •', 'ë°”ì˜ë‹¤']
    energy_keywords = ['ì¢‹ë‹¤', 'í–‰ë³µ', 'ì—ë„ˆì§€', 'í™œê¸°', 'ë¿Œë“¯', 'ì¦ê²ë‹¤', 'ì‹ ë‚˜ë‹¤']
    
    stress_count = sum(1 for word in stress_keywords if word in text_lower)
    energy_count = sum(1 for word in energy_keywords if word in text_lower)
    
    if stress_count > energy_count:
        stress_level = min(80, 40 + stress_count * 15)
        energy_level = max(20, 60 - stress_count * 15)
        tone = "ë¶€ì •ì "
    elif energy_count > stress_count:
        stress_level = max(15, 40 - energy_count * 10)
        energy_level = min(85, 50 + energy_count * 15)
        tone = "ê¸ì •ì "
    else:
        tone = "ì¤‘ë¦½ì "
    
    mood_score = energy_level - stress_level
    
    result = {
        'emotions': detected_emotions if detected_emotions else ['ì¤‘ë¦½'],
        'stress_level': stress_level,
        'energy_level': energy_level,
        'mood_score': mood_score,
        'summary': f"{tone} ìƒíƒœë¡œ, ì£¼ìš” ê°ì •ì€ {', '.join(detected_emotions[:2]) if detected_emotions else 'ì¤‘ë¦½'}ì…ë‹ˆë‹¤.",
        'keywords': keywords[:5],
        'tone': tone,
        'confidence': 0.5
    }
    
    # ìŒì„± ë¶„ì„ì´ ìˆìœ¼ë©´ ê²°í•©
    if voice_analysis:
        result = combine_text_and_voice_analysis(result, voice_analysis)
    
    return result

def generate_personalized_feedback(entries: List[Dict]) -> str:
    """ê°œì¸í™”ëœ í”¼ë“œë°± ìƒì„±"""
    if not entries:
        return "ì²« ë²ˆì§¸ ìŒì„± ì¼ê¸°ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!"
    
    recent_entries = entries[-7:]  # ìµœê·¼ 7ì¼
    
    if not openai_client:
        return generate_basic_feedback(recent_entries)
    
    try:
        # ìµœê·¼ ë°ì´í„° ìš”ì•½ (ìŒì„± ë¶„ì„ í¬í•¨)
        summary_data = []
        for entry in recent_entries:
            entry_summary = {
                'date': entry['date'],
                'emotions': entry['analysis']['emotions'],
                'stress': entry['analysis']['stress_level'],
                'energy': entry['analysis']['energy_level'],
                'tone': entry['analysis'].get('tone', 'ì¤‘ë¦½ì '),
                'confidence': entry['analysis'].get('confidence', 0.5)
            }
            
            # ìŒì„± ë¶„ì„ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if 'voice_analysis' in entry['analysis']:
                entry_summary['voice_emotions'] = entry['analysis']['voice_analysis'].get('detected_emotions', [])
                entry_summary['voice_confidence'] = 'high' if entry['analysis'].get('confidence', 0.5) > 0.8 else 'medium'
            
            summary_data.append(entry_summary)
        
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ "ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨" ì„œë¹„ìŠ¤ì˜ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ AI ë§ˆìŒ ì¼€ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. 
                    ì‚¬ìš©ìì˜ ìµœê·¼ ì¼ì£¼ì¼ê°„ ë§ˆìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•˜ì„¸ìš”:
                    
                    1. ë§ˆìŒ íŒ¨í„´ì— ëŒ€í•œ ë”°ëœ»í•œ ê´€ì°° (1-2ë¬¸ì¥)
                    2. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë§ˆìŒ ì¼€ì–´ ì¡°ì–¸ (1-2ë¬¸ì¥)
                    3. ê²©ë ¤ì™€ ìœ„ë¡œì˜ ë©”ì‹œì§€ (1ë¬¸ì¥)
                    
                    ì „ì²´ 3-4ë¬¸ì¥ìœ¼ë¡œ, ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    ìŒì„± ë¶„ì„ì´ í¬í•¨ëœ ê²½ìš° ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í–ˆë‹¤ëŠ” ì ì„ ì–¸ê¸‰í•´ì£¼ì„¸ìš”."""
                },
                {
                    "role": "user",
                    "content": f"ìµœê·¼ ì¼ì£¼ì¼ê°„ì˜ ë§ˆìŒ ë°ì´í„°ë¥¼ ì‚´í´ë´ ì£¼ì„¸ìš”:\n{json.dumps(summary_data, ensure_ascii=False, indent=2)}"
                }
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return generate_basic_feedback(recent_entries)

def generate_basic_feedback(entries: List[Dict]) -> str:
    """ê¸°ë³¸ í”¼ë“œë°± ìƒì„±"""
    if not entries:
        return "ì²« ë²ˆì§¸ ìŒì„± ì¼ê¸°ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!"
    
    avg_stress = sum(entry['analysis']['stress_level'] for entry in entries) / len(entries)
    avg_energy = sum(entry['analysis']['energy_level'] for entry in entries) / len(entries)
    
    # ê°ì • ë¹ˆë„ ë¶„ì„
    all_emotions = []
    for entry in entries:
        all_emotions.extend(entry['analysis']['emotions'])
    
    emotion_counts = {}
    for emotion in all_emotions:
        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
    
    most_frequent = max(emotion_counts.items(), key=lambda x: x[1])[0] if emotion_counts else "ì¤‘ë¦½"
    
    # ìŒì„± ë¶„ì„ í¬í•¨ ì—¬ë¶€ ì²´í¬
    voice_analyzed_count = sum(1 for entry in entries if 'voice_analysis' in entry['analysis'])
    voice_feedback = f" íŠ¹íˆ ìŒì„± ë¶„ì„ì„ í†µí•´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤." if voice_analyzed_count > 0 else ""
    
    if avg_stress > 65:
        return f"ìµœê·¼ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ê°€ {avg_stress:.0f}%ë¡œ ë†’ì€ í¸ì´ì—ìš”. ê¹Šì€ í˜¸í¡ì´ë‚˜ ì§§ì€ ì‚°ì±…ìœ¼ë¡œ ë§ˆìŒì„ ë‹¬ë˜ë³´ì„¸ìš”.{voice_feedback} ì‘ì€ íœ´ì‹ë„ í° ë„ì›€ì´ ë©ë‹ˆë‹¤!"
    elif avg_energy < 35:
        return f"ìµœê·¼ ì—ë„ˆì§€ê°€ {avg_energy:.0f}%ë¡œ ë‚®ì•„ ë³´ì—¬ìš”. ì¶©ë¶„í•œ ìˆ˜ë©´ê³¼ ì¢‹ì•„í•˜ëŠ” í™œë™ìœ¼ë¡œ ì—ë„ˆì§€ë¥¼ ì¶©ì „í•´ë³´ì„¸ìš”.{voice_feedback} ë‹¹ì‹ ì„ ìœ„í•œ ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”!"
    elif most_frequent == "ê¸°ì¨":
        return f"ìµœê·¼ ê¸ì •ì ì¸ ê°ì •ì´ ë§ì´ ë³´ì´ë„¤ìš”!{voice_feedback} ì´ ì¢‹ì€ ì—ë„ˆì§€ë¥¼ ìœ ì§€í•˜ë©° ìƒˆë¡œìš´ ëª©í‘œì— ë„ì „í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
    else:
        return f"ì „ì²´ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ë³´ì´ê³  ìˆì–´ìš”.{voice_feedback} ê¾¸ì¤€íˆ ìì‹ ì˜ ê°ì •ì„ ê¸°ë¡í•˜ëŠ” ìŠµê´€ì´ ì •ë§ í›Œë¥­í•©ë‹ˆë‹¤! ê³„ì† ì‘ì›í• ê²Œìš”!"

# ì „ì—­ ê°ì²´ ì´ˆê¸°í™”
voice_extractor = VoiceFeatureExtractor()
emotion_analyzer = EmotionAnalyzer()

# ë©”ì¸ í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ™ï¸ ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - ê³ ë„í™”</h1>
    <p>ëª©ì†Œë¦¬ë¡œ ë‹´ëŠ” ì˜¤ëŠ˜, AIê°€ ì½ì–´ì£¼ëŠ” ë§ˆìŒ</p>
    <small style="opacity: 0.8;">ìŒì„± í”¼ì²˜ ë¶„ì„ìœ¼ë¡œ ë” ì •í™•í•œ ê°ì • ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤</small>
</div>
""", unsafe_allow_html=True)

# ê¸°ëŠ¥ ìƒíƒœ í‘œì‹œ
with st.sidebar:
    st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    
    status_indicators = []
    if OPENAI_AVAILABLE and openai_client:
        status_indicators.append("âœ… OpenAI API")
    else:
        status_indicators.append("âš ï¸ OpenAI API ì„¤ì • í•„ìš”")
    
    if AUDIO_ANALYSIS_AVAILABLE:
        status_indicators.append("âœ… ìŒì„± ë¶„ì„ (Librosa)")
    else:
        status_indicators.append("âš ï¸ ê¸°ë³¸ ìŒì„± ë¶„ì„")
    
    if PRAAT_AVAILABLE:
        status_indicators.append("âœ… ê³ ê¸‰ ìŒì„±í•™ ë¶„ì„ (Praat)")
    else:
        status_indicators.append("â„¹ï¸ í‘œì¤€ ìŒì„±í•™ ë¶„ì„")
    
    if PLOTLY_AVAILABLE:
        status_indicators.append("âœ… ì‹œê°í™”")
    else:
        status_indicators.append("âš ï¸ ê¸°ë³¸ ì°¨íŠ¸ë§Œ ê°€ëŠ¥")
    
    for indicator in status_indicators:
        st.markdown(f"- {indicator}")

# API í‚¤ ì„¤ì • ì²´í¬
if not openai_client:
    with st.sidebar:
        st.warning("ğŸ”‘ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        with st.expander("API í‚¤ ì…ë ¥í•˜ê¸°"):
            st.markdown("**ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨**ì˜ AI ê°ì • ë¶„ì„ì„ ìœ„í•´ OpenAI API í‚¤ê°€ í•„ìš”í•´ìš”.")
            api_key = st.text_input("OpenAI API í‚¤", type="password", help="sk-ë¡œ ì‹œì‘í•˜ëŠ” API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            if st.button("ì €ì¥"):
                if api_key.startswith("sk-"):
                    st.session_state.openai_api_key = api_key
                    st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                else:
                    st.error("ì˜¬ë°”ë¥¸ API í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        st.info("ğŸ’¡ API í‚¤ ì—†ì´ë„ ìŒì„± í”¼ì²˜ ê¸°ë°˜ ê°ì • ë¶„ì„ì„ ì²´í—˜í•  ìˆ˜ ìˆì–´ìš”.")

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
with st.sidebar:
    st.title("ğŸŒŸ ì˜¤ëŠ˜ì˜ ë§ˆìŒ")
    
    # ì˜¤ëŠ˜ ì¼ê¸° ì‘ì„± ì—¬ë¶€ í™•ì¸
    today = datetime.now().strftime("%Y-%m-%d")
    today_entries = [entry for entry in st.session_state.diary_entries if entry['date'] == today]
    
    if today_entries:
        st.success(f"âœ… ì˜¤ëŠ˜ {len(today_entries)}ë²ˆì˜ ë§ˆìŒì„ ê¸°ë¡í–ˆì–´ìš”")
        # ìŒì„± ë¶„ì„ í¬í•¨ ì—¬ë¶€
        voice_count = sum(1 for entry in today_entries if 'voice_analysis' in entry.get('analysis', {}))
        if voice_count > 0:
            st.info(f"ğŸµ {voice_count}ê°œ í•­ëª©ì—ì„œ ìŒì„± ë¶„ì„ ì™„ë£Œ")
    else:
        st.info("ğŸ’­ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”")
    
    page = st.selectbox(
        "í˜ì´ì§€ ì„ íƒ",
        ["ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°", "ğŸ’– ë§ˆìŒ ë¶„ì„", "ğŸ“ˆ ê°ì • ì—¬ì •", "ğŸµ ìŒì„± ë¶„ì„", "ğŸ’¡ ë§ˆìŒ ì¼€ì–´", "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤"],
        help="ì›í•˜ëŠ” í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    st.markdown("---")
    
    # í†µê³„ ìš”ì•½
    if st.session_state.diary_entries:
        st.markdown("### ğŸ“Š ë‚˜ì˜ ì—¬ì •")
        total_entries = len(st.session_state.diary_entries)
        st.metric("ê¸°ë¡í•œ ì´ì•¼ê¸°", f"{total_entries}ê°œ")
        
        if total_entries > 0:
            latest_entry = st.session_state.diary_entries[-1]
            days_since_start = (datetime.now() - datetime.strptime(st.session_state.diary_entries[0]['date'], "%Y-%m-%d")).days + 1
            st.metric("í•¨ê»˜í•œ ë‚ ë“¤", f"{days_since_start}ì¼ì§¸")
            
            # ìµœê·¼ ê°ì • ìƒíƒœ
            recent_mood = latest_entry['analysis'].get('tone', 'ì¤‘ë¦½ì ')
            mood_emoji = {"ê¸ì •ì ": "ğŸ˜Š", "ì¤‘ë¦½ì ": "ğŸ˜", "ë¶€ì •ì ": "ğŸ˜”"}
            st.metric("ì§€ê¸ˆì˜ ë§ˆìŒ", f"{mood_emoji.get(recent_mood, 'ğŸ˜')} {recent_mood}")
            
            # ë¶„ì„ ì‹ ë¢°ë„
            confidence = latest_entry['analysis'].get('confidence', 0.5)
            confidence_text = "ë†’ìŒ" if confidence > 0.8 else "ë³´í†µ" if confidence > 0.6 else "ê¸°ë³¸"
            st.metric("ë¶„ì„ ì‹ ë¢°ë„", confidence_text)

# í˜ì´ì§€ë³„ ì½˜í…ì¸ 
if page == "ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°":
    # ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸° í˜ì´ì§€ ë‚´ìš©
    st.header("ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **ğŸ’ ë§ˆìŒì„ ë‚˜ëˆ„ëŠ” ì‹œê°„:**
        - 1ë¶„ë§Œ íˆ¬ìí•´ë³´ì„¸ìš”, ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ê°€ ì†Œì¤‘í•´ìš”
        - ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼, ëŠë‚€ ê°ì •ì„ ììœ ë¡­ê²Œ ë§í•´ë³´ì„¸ìš”
        - ìŒì„±ìœ¼ë¡œ ë§í•˜ë©´ ëª©ì†Œë¦¬ì˜ ë†’ë‚®ì´, ì†ë„, ì—ë„ˆì§€ê¹Œì§€ ë¶„ì„í•´ë“œë ¤ìš”
        - íŠ¹ë³„í•œ ì¼ì´ ì—†ì–´ë„ ê´œì°®ì•„ìš”, í‰ë²”í•œ í•˜ë£¨ë„ ì˜ë¯¸ ìˆì–´ìš”
        """)
    
    with col2:
        # ì˜¤ëŠ˜ ì‘ì„±í•œ ì¼ê¸° ìˆ˜
        if today_entries:
            st.info(f"ğŸŒŸ ì˜¤ëŠ˜ {len(today_entries)}ë²ˆì§¸ ì´ì•¼ê¸°")
        else:
            st.info("ğŸŒ± ì˜¤ëŠ˜ ì²« ë²ˆì§¸ ì´ì•¼ê¸°")
        
        # ìŒì„± ë¶„ì„ ê¸°ëŠ¥ ì•ˆë‚´
        if AUDIO_ANALYSIS_AVAILABLE:
            st.success("ğŸµ ìŒì„± í”¼ì²˜ ë¶„ì„ ì§€ì›")
        else:
            st.warning("ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ìœ„ì£¼")
    
    # ìŒì„± ë…¹ìŒ ì„¹ì…˜
    st.markdown("### ğŸ™ï¸ ëª©ì†Œë¦¬ë¡œ ë“¤ë ¤ì£¼ì„¸ìš”")
    
    with st.container():
        st.markdown('<div class="recording-container">', unsafe_allow_html=True)
        
        # Streamlit ë‚´ì¥ ìŒì„± ì…ë ¥ ì‚¬ìš©
        audio_value = st.audio_input(
            "ğŸ¤ ë§ˆìŒì„ í¸í•˜ê²Œ ë§í•´ë³´ì„¸ìš”",
            help="ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”. ìŒì„±ì˜ ë†’ë‚®ì´, ì†ë„, ì—ë„ˆì§€ê¹Œì§€ ë¶„ì„í•´ë“œë ¤ìš”"
        )
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # í…ìŠ¤íŠ¸ ì…ë ¥ ëŒ€ì•ˆ
    st.markdown("### âœï¸ ë˜ëŠ” ê¸€ë¡œ ì ì–´ë³´ì„¸ìš”")
    text_input = st.text_area(
        "ë§ˆìŒì„ ê¸€ë¡œ í‘œí˜„í•´ë³´ì„¸ìš”",
        placeholder="ì˜¤ëŠ˜ì€ ì–´ë–¤ í•˜ë£¨ì˜€ë‚˜ìš”? ëŠë‚€ ê°ì •ì´ë‚˜ ìƒê°ì„ ììœ ë¡­ê²Œ ì¨ë³´ì„¸ìš”...",
        height=120,
        help="ëª©ì†Œë¦¬ ëŒ€ì‹  ê¸€ë¡œ ë§ˆìŒì„ í‘œí˜„í•˜ì…”ë„ ì¢‹ì•„ìš”"
    )
    
    # ì¼ê¸° ì €ì¥ ë²„íŠ¼
    if st.button("ğŸ’ ë§ˆìŒ ë¶„ì„í•˜ê³  ì†Œì¤‘íˆ ë³´ê´€í•˜ê¸°", type="primary", use_container_width=True):
        diary_text = ""
        audio_data = None
        voice_analysis = None
        
        # ìŒì„± ë°ì´í„° ì²˜ë¦¬
        if audio_value is not None:
            audio_bytes = audio_value.read()
            audio_data = base64.b64encode(audio_bytes).decode()
            
            with st.spinner("ğŸµ ìŒì„±ì˜ í”¼ì¹˜, ì—ë„ˆì§€, í…œí¬ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                # ìŒì„± í”¼ì²˜ ì¶”ì¶œ
                voice_features = voice_extractor.extract_prosodic_features(audio_bytes)
                
                # ìŒì„± ê¸°ë°˜ ê°ì • ë¶„ì„
                voice_analysis = emotion_analyzer.analyze_emotion_from_voice(voice_features)
                
                st.success("âœ… ìŒì„± í”¼ì²˜ ë¶„ì„ ì™„ë£Œ!")
                
                # ìŒì„± ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                if voice_analysis:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ìŒì„± ê°ì •", ', '.join(voice_analysis['detected_emotions'][:2]))
                    with col2:
                        st.metric("ìŒì„± ì—ë„ˆì§€", f"{voice_analysis['voice_energy_level']}%")
                    with col3:
                        st.metric("ìŒì„± ìŠ¤íŠ¸ë ˆìŠ¤", f"{voice_analysis['voice_stress_level']}%")
            
            with st.spinner("ğŸ¤– ë‹¹ì‹ ì˜ ëª©ì†Œë¦¬ë¥¼ ë§ˆìŒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘..."):
                if openai_client:
                    diary_text = transcribe_audio_with_whisper(audio_bytes)
                    if diary_text:
                        st.success("âœ… ëª©ì†Œë¦¬ê°€ ê¸€ë¡œ ë°”ë€Œì—ˆì–´ìš”!")
                        st.info(f"**ë“¤ì€ ì´ì•¼ê¸°:** {diary_text}")
                    else:
                        st.error("ìŒì„± ë³€í™˜ì— ì‹¤íŒ¨í–ˆì–´ìš”. ê¸€ë¡œ ì ì–´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?")
                else:
                    st.warning("API í‚¤ê°€ ì—†ì–´ ìŒì„± ë³€í™˜ì„ í•  ìˆ˜ ì—†ì–´ìš”. ê¸€ë¡œ ì ì–´ì£¼ì„¸ìš”.")
        
        # í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
        if not diary_text and text_input.strip():
            diary_text = text_input.strip()
        
        if diary_text:
            with st.spinner("ğŸ¤– í…ìŠ¤íŠ¸ì™€ ìŒì„±ì„ ì¢…í•©í•˜ì—¬ ë§ˆìŒì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                analysis = analyze_emotion_with_gpt(diary_text, voice_analysis)
            
            # ì¼ê¸° ì €ì¥
            entry = {
                'id': len(st.session_state.diary_entries) + 1,
                'date': datetime.now().strftime("%Y-%m-%d"),
                'time': datetime.now().strftime("%H:%M"),
                'text': diary_text,
                'analysis': analysis,
                'timestamp': datetime.now(),
                'audio_data': audio_data
            }
            
            st.session_state.diary_entries.append(entry)
            
            # ê²°ê³¼ í‘œì‹œ
            st.success("ğŸ‰ ì†Œì¤‘í•œ ì´ì•¼ê¸°ê°€ ì•ˆì „í•˜ê²Œ ë³´ê´€ë˜ì—ˆì–´ìš”!")
            
            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            st.markdown("---")
            st.markdown("## ğŸ¤– AIê°€ ì½ì–´ë“œë¦° ë‹¹ì‹ ì˜ ë§ˆìŒ")
            
            # ì¢…í•© ë¶„ì„ ê²°ê³¼
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown(f"""
                <div class="emotion-card">
                    <h4>ğŸ’– ê°ì§€ëœ ê°ì •</h4>
                    <p><strong>{', '.join(analysis['emotions'])}</strong></p>
                    <small>í•µì‹¬ ë‹¨ì–´: {', '.join(analysis.get('keywords', [])[:3])}</small>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="emotion-card">
                    <h4>ğŸ“Š ë§ˆìŒ ìƒíƒœ</h4>
                    <p>ìŠ¤íŠ¸ë ˆìŠ¤: <strong>{analysis['stress_level']}%</strong></p>
                    <p>í™œë ¥: <strong>{analysis['energy_level']}%</strong></p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                confidence_emoji = "ğŸ¯" if analysis.get('confidence', 0.5) > 0.8 else "ğŸ“" if analysis.get('confidence', 0.5) > 0.6 else "ğŸ“Œ"
                st.markdown(f"""
                <div class="emotion-card">
                    <h4>ğŸ¯ ì˜¤ëŠ˜ì˜ ì»¨ë””ì…˜</h4>
                    <p>ë§ˆìŒ ì ìˆ˜: <strong>{analysis['mood_score']}</strong></p>
                    <p>ë¶„ì„ ì‹ ë¢°ë„: <strong>{confidence_emoji} {analysis.get('confidence', 0.5):.1f}</strong></p>
                </div>
                """, unsafe_allow_html=True)
            
            # ìŒì„± ë¶„ì„ì´ í¬í•¨ëœ ê²½ìš° ì¶”ê°€ ì •ë³´
            if voice_analysis:
                st.markdown("### ğŸµ ìŒì„± ë¶„ì„ ìƒì„¸ ê²°ê³¼")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"""
                    <div class="voice-analysis-card">
                        <h4>ğŸ¤ ìŒì„± íŠ¹ì„±</h4>
                        <p>í”¼ì¹˜ í‰ê· : <strong>{voice_analysis['voice_features'].get('pitch_mean', 0):.1f} Hz</strong></p>
                        <p>ì—ë„ˆì§€: <strong>{voice_analysis['voice_features'].get('energy_mean', 0):.3f}</strong></p>
                        <p>ë§í•˜ê¸° ì†ë„: <strong>{voice_analysis['voice_features'].get('tempo', 0):.0f} BPM</strong></p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="voice-analysis-card">
                        <h4>ğŸ¯ ìŒì„± ê°ì • ì ìˆ˜</h4>
                        <p>ìŒì„± ìŠ¤íŠ¸ë ˆìŠ¤: <strong>{voice_analysis['voice_stress_level']}%</strong></p>
                        <p>ìŒì„± í™œë ¥: <strong>{voice_analysis['voice_energy_level']}%</strong></p>
                        <p>ìŒì„± ê¸°ë¶„: <strong>{voice_analysis['voice_mood_score']}</strong></p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # AI ìš”ì•½
            if 'summary' in analysis:
                confidence_text = "ë†’ì€ ì‹ ë¢°ë„" if analysis.get('confidence', 0.5) > 0.8 else "ë³´í†µ ì‹ ë¢°ë„" if analysis.get('confidence', 0.5) > 0.6 else "ê¸°ë³¸ ë¶„ì„"
                st.markdown(f"""
                <div class="feedback-box">
                    <h4>ğŸ¤– AIê°€ ì „í•´ë“œë¦¬ëŠ” ë§ ({confidence_text})</h4>
                    <p>{analysis['summary']}</p>
                </div>
                """, unsafe_allow_html=True)
            
        else:
            st.warning("âš ï¸ ëª©ì†Œë¦¬ë‚˜ ê¸€ë¡œ ë§ˆìŒì„ ë“¤ë ¤ì£¼ì„¸ìš”!")

elif page == "ğŸµ ìŒì„± ë¶„ì„":
    st.header("ìŒì„± í”¼ì²˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    if not st.session_state.diary_entries:
        st.info("ğŸ“ ìŒì„±ìœ¼ë¡œ ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ ìƒì„¸í•œ ìŒì„± ë¶„ì„ì„ ë³¼ ìˆ˜ ìˆì–´ìš”!")
    else:
        # ìŒì„± ë¶„ì„ì´ í¬í•¨ëœ í•­ëª©ë“¤ë§Œ í•„í„°ë§
        voice_entries = [entry for entry in st.session_state.diary_entries 
                        if 'voice_analysis' in entry.get('analysis', {})]
        
        if not voice_entries:
            st.warning("ğŸ¤ ìŒì„±ìœ¼ë¡œ ê¸°ë¡ëœ ì¼ê¸°ê°€ ì—†ì–´ìš”. ëª©ì†Œë¦¬ë¡œ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”!")
        else:
            st.success(f"ğŸµ {len(voice_entries)}ê°œì˜ ìŒì„± ë¶„ì„ ë°ì´í„°ê°€ ìˆì–´ìš”!")
            
            # ìµœê·¼ ìŒì„± ë¶„ì„ ê²°ê³¼
            latest_voice = voice_entries[-1]
            voice_analysis = latest_voice['analysis']['voice_analysis']
            
            st.markdown("### ğŸ¯ ìµœê·¼ ìŒì„± ë¶„ì„ ê²°ê³¼")
            
            # ìŒì„± í”¼ì²˜ ìƒì„¸ í‘œì‹œ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="prosodic-meter">
                    <h4>ğŸ¼ í”¼ì¹˜ (Hz)</h4>
                    <h2 style="color: #667eea;">{voice_analysis['voice_features'].get('pitch_mean', 0):.1f}</h2>
                    <small>ë³€ë™ì„±: {voice_analysis['voice_features'].get('pitch_variation', 0):.2f}</small>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="prosodic-meter">
                    <h4>âš¡ ì—ë„ˆì§€</h4>
                    <h2 style="color: #51cf66;">{voice_analysis['voice_features'].get('energy_mean', 0):.3f}</h2>
                    <small>ìµœëŒ€: {voice_analysis['voice_features'].get('energy_max', 0):.3f}</small>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="prosodic-meter">
                    <h4>ğŸƒ ë§í•˜ê¸° ì†ë„</h4>
                    <h2 style="color: #ffd43b;">{voice_analysis['voice_features'].get('tempo', 0):.0f}</h2>
                    <small>BPM</small>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                jitter = voice_analysis['voice_features'].get('jitter', 0)
                stability = "ì•ˆì •ì " if jitter < 0.015 else "ë³´í†µ" if jitter < 0.025 else "ë¶ˆì•ˆì •"
                st.markdown(f"""
                <div class="prosodic-meter">
                    <h4>ğŸšï¸ ìŒì„± ì•ˆì •ì„±</h4>
                    <h2 style="color: #ff6b6b;">{stability}</h2>
                    <small>Jitter: {jitter:.3f}</small>
                </div>
                """, unsafe_allow_html=True)

elif page == "ğŸ’– ë§ˆìŒ ë¶„ì„":
    st.header("ë§ˆìŒ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    if not st.session_state.diary_entries:
        st.info("ğŸ“ ì•„ì§ ê¸°ë¡ëœ ì´ì•¼ê¸°ê°€ ì—†ì–´ìš”. ì²« ë²ˆì§¸ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”!")
    else:
        st.write("ë§ˆìŒ ë¶„ì„ í˜ì´ì§€ ë‚´ìš©...")

elif page == "ğŸ“ˆ ê°ì • ì—¬ì •":
    st.header("ë§ˆìŒì˜ ë³€í™”ë¥¼ ì‚´í´ë³´ì„¸ìš”")
    
    if not st.session_state.diary_entries:
        st.info("ğŸ“Š ì´ì•¼ê¸°ë¥¼ ê¸°ë¡í•˜ë©´ ë§ˆìŒì˜ ë³€í™”ë¥¼ ì•„ë¦„ë‹¤ìš´ ê·¸ë˜í”„ë¡œ ë³¼ ìˆ˜ ìˆì–´ìš”!")
    else:
        st.write("ê°ì • ì—¬ì • í˜ì´ì§€ ë‚´ìš©...")

elif page == "ğŸ’¡ ë§ˆìŒ ì¼€ì–´":
    st.header("ë‹¹ì‹ ë§Œì„ ìœ„í•œ ë§ˆìŒ ì¼€ì–´")
    
    if not st.session_state.diary_entries:
        st.info("ğŸ“ ì´ì•¼ê¸°ë¥¼ ê¸°ë¡í•˜ë©´ AIê°€ ë‹¹ì‹ ë§Œì˜ ë§ì¶¤ ì¼€ì–´ë¥¼ ì¶”ì²œí•´ë“œë ¤ìš”!")
    else:
        st.write("ë§ˆìŒ ì¼€ì–´ í˜ì´ì§€ ë‚´ìš©...")

elif page == "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤":
    st.header("ì†Œì¤‘í•œ ì´ì•¼ê¸° ì•„ì¹´ì´ë¸Œ")
    
    if not st.session_state.diary_entries:
        st.info("ğŸ“ ì•„ì§ ê¸°ë¡ëœ ì´ì•¼ê¸°ê°€ ì—†ì–´ìš”.")
    else:
        st.write("ì´ì•¼ê¸° ì•„ì¹´ì´ë¸Œ í˜ì´ì§€ ë‚´ìš©...")

# ì‚¬ì´ë“œë°” - ë°ì´í„° ê´€ë¦¬
with st.sidebar:
    if st.session_state.diary_entries:
        st.markdown("---")
        st.markdown("### ğŸ’¾ ì†Œì¤‘í•œ ê¸°ë¡ ê´€ë¦¬")
        
        # í†µê³„ ë‚´ë³´ë‚´ê¸°
        if st.button("ğŸ“Š ë§ˆìŒ ë¦¬í¬íŠ¸ ìƒì„±"):
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            export_data = []
            for entry in st.session_state.diary_entries:
                row = {
                    'date': entry['date'],
                    'time': entry['time'],
                    'text': entry['text'],
                    'emotions': ', '.join(entry['analysis']['emotions']),
                    'stress_level': entry['analysis']['stress_level'],
                    'energy_level': entry['analysis']['energy_level'],
                    'mood_score': entry['analysis']['mood_score'],
                    'summary': entry['analysis'].get('summary', ''),
                    'keywords': ', '.join(entry['analysis'].get('keywords', [])),
                    'tone': entry['analysis'].get('tone', 'ì¤‘ë¦½ì '),
                    'confidence': entry['analysis'].get('confidence', 0.5),
                    'has_voice_analysis': 'voice_analysis' in entry.get('analysis', {})
                }
                
                # ìŒì„± ë¶„ì„ ë°ì´í„° ì¶”ê°€
                if 'voice_analysis' in entry.get('analysis', {}):
                    voice_analysis = entry['analysis']['voice_analysis']
                    row.update({
                        'voice_emotions': ', '.join(voice_analysis.get('detected_emotions', [])),
                        'voice_stress': voice_analysis.get('voice_stress_level', ''),
                        'voice_energy': voice_analysis.get('voice_energy_level', ''),
                        'voice_mood': voice_analysis.get('voice_mood_score', ''),
                        'pitch_mean': voice_analysis['voice_features'].get('pitch_mean', ''),
                        'energy_mean': voice_analysis['voice_features'].get('energy_mean', ''),
                        'tempo': voice_analysis['voice_features'].get('tempo', ''),
                        'jitter': voice_analysis['voice_features'].get('jitter', ''),
                        'hnr': voice_analysis['voice_features'].get('hnr', '')
                    })
                
                export_data.append(row)
            
            df_export = pd.DataFrame(export_data)
            
            csv = df_export.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“ ë§ˆìŒ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"ì†Œë¦¬ë¡œ_ì“°ëŠ”_í•˜ë£¨_ê³ ë„í™”_ë¦¬í¬íŠ¸_{datetime.now().strftime('%Y%m%d')}.csv",
                mime='text/csv'
            )
        
        # ë°±ì—… ì €ì¥
        if st.button("ğŸ’¾ ì „ì²´ ì´ì•¼ê¸° ë°±ì—…"):
            backup_data = {
                'service_name': 'ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - ê³ ë„í™”',
                'version': '2.0',
                'entries': st.session_state.diary_entries,
                'export_date': datetime.now().isoformat(),
                'total_count': len(st.session_state.diary_entries),
                'features': {
                    'voice_analysis': AUDIO_ANALYSIS_AVAILABLE,
                    'praat_analysis': PRAAT_AVAILABLE,
                    'openai_integration': OPENAI_AVAILABLE and openai_client is not None
                }
            }
            backup_json = json.dumps(backup_data, ensure_ascii=False, indent=2, default=str)
            st.download_button(
                label="ğŸ“¦ ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=backup_json,
                file_name=f"ì†Œë¦¬ë¡œ_ì“°ëŠ”_í•˜ë£¨_ê³ ë„í™”_ë°±ì—…_{datetime.now().strftime('%Y%m%d')}.json",
                mime='application/json'
            )
        
        # ë°ì´í„° ì´ˆê¸°í™”
        st.markdown("---")
        if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ë¡ ì‚­ì œ", type="secondary"):
            if st.checkbox("âš ï¸ ì •ë§ë¡œ ì†Œì¤‘í•œ ëª¨ë“  ì´ì•¼ê¸°ë¥¼ ì‚­ì œí•˜ì‹œê² ì–´ìš”?"):
                st.session_state.diary_entries = []
                st.success("âœ… ëª¨ë“  ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆì–´ìš”. ìƒˆë¡œìš´ ì‹œì‘ì´ì—ìš”!")
                st.rerun()

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem 0;">
    <p><strong>ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - ê³ ë„í™”</strong> - ëª©ì†Œë¦¬ë¡œ ë‹´ëŠ” ì˜¤ëŠ˜, AIê°€ ì½ì–´ì£¼ëŠ” ë§ˆìŒ</p>
    <p>ìŒì„± í”¼ì²˜ ë¶„ì„ìœ¼ë¡œ ë” ì •í™•í•˜ê³  í’ë¶€í•œ ê°ì • ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤ âœ¨</p>
    <small style="color: #999;">Made with â¤ï¸ using Streamlit, OpenAI, Librosa & Praat</small>
</div>
""", unsafe_allow_html=True)

# app.py
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pytz, io, os, json, base64, tempfile, hashlib, random, calendar, warnings
warnings.filterwarnings("ignore")

# =============================
# Optional Heavy Imports (lazy)
# =============================
@st.cache_resource(show_spinner=False)
def get_librosa():
    try:
        import librosa
        return librosa
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_parselmouth():
    try:
        import parselmouth
        from parselmouth.praat import call  # noqa
        return parselmouth
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_soundfile():
    try:
        import soundfile as sf
        return sf
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_webrtcvad():
    try:
        import webrtcvad
        return webrtcvad
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_pypdf2():
    try:
        import PyPDF2
        return PyPDF2
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_openai_client():
    # OpenAI v1 SDK-style client
    try:
        import openai
        if "OPENAI_API_KEY" in st.secrets:
            return openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        elif "openai_api_key" in st.session_state and st.session_state.openai_api_key:
            return openai.OpenAI(api_key=st.session_state.openai_api_key)
        else:
            return None
    except Exception:
        return None

openai_client = get_openai_client()
librosa = get_librosa()
parselmouth = get_parselmouth()
sf = get_soundfile()
webrtcvad = get_webrtcvad()
PyPDF2 = get_pypdf2()

# =============================
# Timezone / Keys
# =============================
KST = pytz.timezone("Asia/Seoul")
def kst_now(): return datetime.now(KST)
def today_key(): return kst_now().strftime("%Y-%m-%d")
def current_time(): return kst_now().strftime("%H:%M")

# =============================
# Page Config
# =============================
st.set_page_config(
    page_title="ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - AI ê°ì • ì½”ì¹˜",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================
# Session State
# =============================
def init_ss():
    ss = st.session_state
    ss.setdefault("diary_entries", [])
    ss.setdefault("prosody_baseline", {})
    ss.setdefault("user_goals", [])
    ss.setdefault("show_disclaimer", True)
    ss.setdefault("onboarding_completed", False)
    ss.setdefault("demo_data_loaded", False)
    ss.setdefault("kb_index", None)
    ss.setdefault("kb_meta", None)
    ss.setdefault("kb_ready", False)
    ss.setdefault("show_weekly_report", False)
    ss.setdefault("weekly_report", None)
    ss.setdefault("openai_api_key", "")
init_ss()

# =============================
# Styles
# =============================
st.markdown("""
<style>
  .main-header{ text-align:center; padding:1.5rem; background:linear-gradient(135deg,#667eea 0%,#764ba2 100%); color:#fff; border-radius:15px; margin-bottom:20px; box-shadow: 0 4px 15px rgba(0,0,0,0.1);}
  .card{ background:#fff; border:1px solid #e0e6ed; border-left:4px solid #667eea; border-radius:12px; padding:1.2rem; box-shadow:0 2px 10px rgba(0,0,0,0.05); margin-bottom:1rem;}
  .success-card{ background:linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border-left:4px solid #28a745;}
  .warning-card{ background:linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); border-left:4px solid #ffc107;}
  .disclaimer-banner{ background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 4px solid #2196f3; padding: 1rem; border-radius: 8px; margin: 1rem 0;}
  .metric-positive { color: #28a745; font-weight: bold; }
  .metric-negative { color: #dc3545; font-weight: bold; }
  .metric-neutral { color: #6c757d; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# =============================
# Disclaimer
# =============================
def show_disclaimer():
    if st.session_state.show_disclaimer:
        st.markdown("""
        <div class="disclaimer-banner">
            <h4>ğŸ›¡ï¸ ì„œë¹„ìŠ¤ ì´ìš© ì•ˆë‚´</h4>
            <ul>
                <li><strong>ì˜ë£Œì  í•œê³„:</strong> ë³¸ ì„œë¹„ìŠ¤ëŠ” ìê¸° ì„±ì°° ë³´ì¡° ë„êµ¬ì´ë©°, ì˜ë£Œì  ì§„ë‹¨/ì¹˜ë£Œê°€ ì•„ë‹™ë‹ˆë‹¤.</li>
                <li><strong>ë°ì´í„° ë³´ì•ˆ:</strong> ëª¨ë“  ê¸°ë¡ì€ ì„¸ì…˜ì—ë§Œ ì €ì¥, ë¸Œë¼ìš°ì € ì¢…ë£Œ ì‹œ ì‚­ì œë©ë‹ˆë‹¤.</li>
                <li><strong>AI í•œê³„:</strong> ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ìµœì¢… íŒë‹¨ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.</li>
                <li><strong>ê¸´ê¸‰ìƒí™©:</strong> ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ì´ìŠˆëŠ” ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        c1, c2 = st.columns(2)
        with c1:
            if st.button("âœ… ì´í•´í–ˆìŠµë‹ˆë‹¤", type="primary"):
                st.session_state.show_disclaimer = False
                st.rerun()
        with c2:
            if st.button("ğŸ“Š ë°ëª¨ ë°ì´í„°ë¡œ ì‹œì‘í•˜ê¸°"):
                load_demo_data()
                st.session_state.show_disclaimer = False
                st.success("ê°€ìƒ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

# =============================
# Demo Data
# =============================
def load_demo_data():
    if st.session_state.demo_data_loaded: return
    scenarios = [
        {"t":"ì˜¤ëŠ˜ì€ ì¤‘ê°„ê³ ì‚¬ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆì–´ìš”. ìˆ˜í•™ ì‹œí—˜ì´ ì •ë§ ì–´ë ¤ì› ëŠ”ë° ê·¸ë˜ë„ ë‚˜ë¦„ ì¤€ë¹„í•œ ë§Œí¼ì€ ì“´ ê²ƒ ê°™ì•„ìš”. ì¹œêµ¬ë“¤ì´ë‘ ì¹˜í‚¨ ë¨¹ìœ¼ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ í’€ì—ˆì–´ìš”.",
         "e":["ê¸°ì¨","í‰ì˜¨"],"S":35,"E":70,"M":25,"tone":"ê¸ì •ì "},
        {"t":"ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬ì—ê²Œ ê³ ë°±í• ê¹Œ ê³ ë¯¼ì´ ë§ì•„ìš”. ê±°ì ˆì´ ë‘ë ¤ì›Œ ë¶ˆì•ˆí•˜ì§€ë§Œ ì„¤ë ˆìš”.",
         "e":["ë¶ˆì•ˆ","ì„¤ë ˜"],"S":65,"E":50,"M":-5,"tone":"ì¤‘ë¦½ì "},
        {"t":"ê³¼ì œ ë§ˆê°ì´ ë‚´ì¼ì¸ë° ì•„ì§ ë°˜ë„ ëª»í–ˆì–´ìš”. ë°¤ìƒˆì›Œì•¼ í•  ë“¯. ì»¨ë””ì…˜ì´ ì•ˆ ì¢‹ì•„ìš”.",
         "e":["ìŠ¤íŠ¸ë ˆìŠ¤","í”¼ë¡œ"],"S":85,"E":25,"M":-35,"tone":"ë¶€ì •ì "},
        {"t":"ê³ ë°±í–ˆëŠ”ë° ë‹´ë‹´íˆ ë°›ì•„ì¤¬ì–´ìš”. ì—°ì¸ì€ ì•„ë‹ˆì§€ë§Œ ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆì„ ê²ƒ ê°™ëŒ€ìš”. ë§ˆìŒì´ í›„ë ¨í•´ìš”.",
         "e":["ê¸°ì¨","ë§Œì¡±"],"S":40,"E":75,"M":30,"tone":"ê¸ì •ì "},
        {"t":"í‰ë²”í•œ í•˜ë£¨. ìˆ˜ì—… ë“£ê³  ê³µë¶€í•˜ê³  ë„·í”Œë¦­ìŠ¤. ë°”ë¹´ë˜ ìš”ì¦˜ì— í‰ì˜¨í•¨ì´ ì¢‹ë„¤ìš”.",
         "e":["í‰ì˜¨","ë§Œì¡±"],"S":20,"E":60,"M":15,"tone":"ê¸ì •ì "},
        {"t":"íŒ€ í”„ë¡œì íŠ¸ ì¡°ì› í•œ ëª…ì´ ì ìˆ˜. ë°œí‘œê°€ ë‹¤ìŒ ì£¼ë¼ ë‹¹í™©. ìŠ¤íŠ¸ë ˆìŠ¤ê°€ í½ë‹ˆë‹¤.",
         "e":["ë¶„ë…¸","ìŠ¤íŠ¸ë ˆìŠ¤"],"S":90,"E":40,"M":-40,"tone":"ë¶€ì •ì "},
        {"t":"ì¹œêµ¬ë“¤ì´ë‘ MT ë‹¤ë…€ì™”ì–´ìš”! ë°¤ìƒˆ ì´ì•¼ê¸°í•˜ë©° í–‰ë³µí–ˆì–´ìš”.",
         "e":["ê¸°ì¨","í–‰ë³µ"],"S":15,"E":85,"M":45,"tone":"ê¸ì •ì "},
    ]
    base = kst_now() - timedelta(days=6)
    for i, s in enumerate(scenarios):
        d = (base + timedelta(days=i))
        entry = {
            "id": i+1,
            "date": d.strftime("%Y-%m-%d"),
            "time": f"{random.randint(18,22):02d}:{random.randint(0,59):02d}",
            "text": s["t"],
            "analysis": {
                "emotions": s["e"],
                "stress_level": s["S"],
                "energy_level": s["E"],
                "mood_score": s["M"],
                "summary": f"{s['tone']} ìƒíƒœì˜ í•˜ë£¨.",
                "keywords": [],
                "tone": s["tone"],
                "confidence": round(random.uniform(0.7,0.9),2)
            },
            "audio_data": None,
            "mental_state": {
                "state": "ì•ˆì •/íšŒë³µ" if s["S"]<40 else ("ê³ ìŠ¤íŠ¸ë ˆìŠ¤" if s["S"]>70 else "ì¤‘ë¦½"),
                "summary": f"ìŠ¤íŠ¸ë ˆìŠ¤ {s['S']}%, ì—ë„ˆì§€ {s['E']}%.",
                "positives": ["ì¹œêµ¬ì™€ì˜ ì‹œê°„","ì„±ì·¨"] if s["tone"]=="ê¸ì •ì " else [],
                "recommendations": ["íœ´ì‹","ì¹œêµ¬ì™€ ì‹œê°„","ê·œì¹™ì  ìƒí™œ"],
                "motivation": "í•˜ë£¨í•˜ë£¨ ìµœì„ ì„ ë‹¤í•´ìš”!"
            }
        }
        st.session_state.diary_entries.append(entry)
    st.session_state.user_goals = [
        {"id":1,"type":"stress","target":50,"description":"ìŠ¤íŠ¸ë ˆìŠ¤ 50 ì´í•˜ ìœ ì§€","created_date":(kst_now()-timedelta(days=5)).strftime("%Y-%m-%d"),"active":True},
        {"id":2,"type":"consistency","target":5,"description":"ì£¼ 5íšŒ ì´ìƒ ê¸°ë¡","created_date":(kst_now()-timedelta(days=5)).strftime("%Y-%m-%d"),"active":True},
    ]
    st.session_state.demo_data_loaded = True

# =============================
# Header
# =============================
def header():
    if not st.session_state.show_disclaimer:
        st.markdown(f"""
        <div class="main-header">
          <h1>ğŸ™ï¸ ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ â€“ AI ê°ì • ì½”ì¹˜</h1>
          <p>ğŸ“… {kst_now().strftime('%Yë…„ %mì›” %dì¼ %A')} | â° {current_time()}</p>
          <p>ê°ì • ë¼ë²¨ì€ <b>í…ìŠ¤íŠ¸ ê¸°ë°˜</b>, ëª©ì†Œë¦¬ëŠ” <b>ë³´ì¡° ì§€í‘œ</b>ë¡œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤</p>
        </div>
        """, unsafe_allow_html=True)

# =============================
# Audio: Feature Extractor
# =============================
class VoiceFeatureExtractor:
    def __init__(self, target_sr=22050): self.sample_rate=target_sr

    def _load_audio(self, audio_bytes:bytes):
        if not librosa: return None, None
        try:
            y, sr = librosa.load(io.BytesIO(audio_bytes), sr=self.sample_rate, mono=True)
            return y, sr
        except Exception:
            return None, None

    def extract(self, audio_bytes:bytes):
        if not librosa:
            return self._default()
        try:
            y, sr = self._load_audio(audio_bytes)
            if y is None or y.size==0 or sr is None: return self._default()
            dur = max(0.001, len(y)/sr)

            rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]
            energy_mean = float(np.mean(rms)); energy_max = float(np.max(rms))

            tempo = 110.0
            if dur>=2.5:
                tempo,_ = librosa.beat.beat_track(y=y, sr=sr)

            zcr = librosa.feature.zero_crossing_rate(y, frame_length=1024, hop_length=256)[0]
            zcr_mean = float(np.mean(zcr))

            sc = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_centroid_mean = float(np.mean(sc))

            pitch_mean=150.0; pitch_var=0.13
            try:
                if dur>=1.0:
                    pitches, mags = librosa.piptrack(y=y, sr=sr, fmin=50, fmax=400)
                    valid=[]
                    for t in range(pitches.shape[1]):
                        idx=int(np.argmax(mags[:,t])); p=float(pitches[idx,t])
                        if p>0: valid.append(p)
                    if valid:
                        va=np.array(valid,dtype=float)
                        pitch_mean=float(np.mean(va)); pitch_var=float(np.std(va)/(np.mean(va)+1e-6))
            except Exception: pass

            hnr=15.0; jitter=0.012
            if parselmouth:
                tmp=None
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t2:
                        if sf: sf.write(t2, y, sr, subtype="PCM_16", format="WAV")
                        else:
                            # fallback write via numpy (no header) â€“ skip parselmouth if no soundfile
                            raise RuntimeError("soundfile not available")
                        tmp=t2.name
                    snd=parselmouth.Sound(tmp)
                    harm=snd.to_harmonicity_cc()
                    hnr=float(np.nan_to_num(harm.values.mean(), nan=15.0))
                    pp=parselmouth.praat.call(snd, "To PointProcess (periodic, cc)", 75, 500)
                    jitter=float(parselmouth.praat.call(pp, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3))
                except Exception: pass
                finally:
                    if tmp and os.path.exists(tmp):
                        try: os.unlink(tmp)
                        except Exception: pass

            return {
                "duration_sec":float(dur),
                "pitch_mean":float(pitch_mean),
                "pitch_variation":float(pitch_var),
                "energy_mean":float(energy_mean),
                "energy_max":float(energy_max),
                "tempo":float(tempo),
                "zcr_mean":float(zcr_mean),
                "spectral_centroid_mean":float(spectral_centroid_mean),
                "hnr":float(hnr),
                "jitter":float(jitter),
            }
        except Exception:
            return self._default()

    def _default(self):
        return {"duration_sec":0.0,"pitch_mean":150.0,"pitch_variation":0.13,
                "energy_mean":0.08,"energy_max":0.12,"tempo":110.0,
                "zcr_mean":0.10,"spectral_centroid_mean":2000.0,"hnr":15.0,"jitter":0.012}

# =============================
# Prosody â†’ Cues
# =============================
def prosody_to_dimensions(f, baseline=None):
    def norm(k,v):
        if not baseline or k not in baseline: return v
        b=float(baseline.get(k,0.0)); return (v/b) if b else v
    tempo=norm("tempo", float(f.get("tempo",110.0)))
    energy=norm("energy_mean", float(f.get("energy_mean",0.08)))
    hnr=norm("hnr", float(f.get("hnr",15.0)))
    jitter=float(f.get("jitter",0.012)); zcr=float(f.get("zcr_mean",0.10))
    sc=norm("spectral_centroid_mean", float(f.get("spectral_centroid_mean",2000.0)))
    arousal=float(np.clip(35 + 120*energy + 0.06*(tempo-110) + 0.004*(sc-2000),0,100))
    tension=float(np.clip(28 + 120*jitter + 0.55*(zcr-0.10)*100,0,100))
    stability=float(np.clip(60 + 1.3*(hnr-15) - 85*jitter,0,100))
    duration=float(f.get("duration_sec",4.0))
    quality=float(np.clip(0.28*(duration/8.0) + 0.42*np.clip((hnr-10)/15,0,1) + 0.30*np.clip((energy-0.06)/0.20,0,1),0,1))
    return {"arousal":arousal,"tension":tension,"stability":stability,"quality":quality}

def analyze_voice_as_cues(vf, baseline=None):
    return {"voice_cues":prosody_to_dimensions(vf, baseline),"voice_features":vf}

def update_baseline(vf):
    keys=["pitch_mean","tempo","energy_mean","hnr","spectral_centroid_mean"]
    b=st.session_state.prosody_baseline; cnt=int(b.get("_count",0)); new_cnt=min(20,cnt+1); alpha=1.0/new_cnt
    for k in keys:
        v=float(vf.get(k,0.0)); prev=float(b.get(k,v)); b[k]=(1-alpha)*prev + alpha*v
    b["_count"]=new_cnt

# =============================
# Text Analysis (LLM 1ì°¨) â€“ Prompt Engineering ê°•í™”
# =============================
TEXT_ANALYZER_SYSTEM = (
    "ë‹¹ì‹ ì€ í•œêµ­ì–´ ê°ì • ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.\n"
    "1) ê°ì • ë¼ë²¨(emotions)ì€ ì˜¤ì§ í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤(ë³´ì´ìŠ¤ ì§€í‘œëŠ” ì°¸ê³ ìš©ì¼ ë¿ ë¼ë²¨ ë³€ê²½ ê¸ˆì§€).\n"
    "2) í—ˆìš© ë¼ë²¨: ê¸°ì¨/ìŠ¬í””/ë¶„ë…¸/ë¶ˆì•ˆ/í‰ì˜¨/ì¤‘ë¦½. ìµœëŒ€ 2ê°œ.\n"
    "3) ì˜ë£Œì  ì§„ë‹¨/ì•½ë¬¼/ìí•´/ìœ„í—˜ íŒë‹¨ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¼ë°˜ì  ì „ë¬¸ê°€ ìƒë‹´ ê¶Œê³ ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
    "4) ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”(ì¶”ê°€ í…ìŠ¤íŠ¸ ê¸ˆì§€)."
)

def safe_json_parse(content:str)->dict:
    if not content: return {}
    s=content.strip()
    if s.startswith("```"): s="\n".join(s.split("\n")[1:-1])
    if s.startswith("```json"): s=s[7:]
    if s.endswith("```"): s=s[:-3]
    s=s.strip()
    try:
        return json.loads(s)
    except Exception:
        try:
            i=s.find("{"); j=s.rfind("}")+1
            if i>=0 and j>i: return json.loads(s[i:j])
        except Exception: return {}
        return {}

def call_llm_safely(fn, *args, **kwargs):
    import time
    for i in range(3):
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            time.sleep(0.6*(2**i) + random.random()*0.3)
    return None

def analyze_text_with_llm(text:str, voice_cues_for_prompt=None)->dict:
    if not openai_client or not text.strip():
        return analyze_text_simulation(text)
    cues_text=""
    if voice_cues_for_prompt:
        c=voice_cues_for_prompt
        cues_text = f"(ë³´ì¡°ì§€í‘œ) ê°ì„±:{int(c.get('arousal',0))}, ê¸´ì¥:{int(c.get('tension',0))}, ì•ˆì •:{int(c.get('stability',0))}, í’ˆì§ˆ:{float(c.get('quality',0)):.2f}"
    user_prompt = (
        "ë‹¤ìŒ ì¼ê¸°ë¥¼ ë¶„ì„í•´ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ìŠ¤í‚¤ë§ˆ:\n"
        '{"emotions":["ê°ì •1","ê°ì •2"],"stress_level":0,"energy_level":0,"mood_score":0,'
        '"summary":"ìš”ì•½","keywords":["í‚¤ì›Œë“œ"],"tone":"ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ","confidence":0.0}\n'
        f"ì¼ê¸°: {text}\n{cues_text}"
    )
    def _call():
        return openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.3,
            max_tokens=500,
            response_format={"type":"json_object"},
            messages=[
                {"role":"system","content":TEXT_ANALYZER_SYSTEM},
                {"role":"user","content":user_prompt}
            ]
        )
    resp = call_llm_safely(_call)
    if not resp or not resp.choices or not resp.choices[0].message.content:
        return analyze_text_simulation(text)
    data = safe_json_parse(resp.choices[0].message.content)
    if not data: return analyze_text_simulation(text)
    data.setdefault("emotions",["ì¤‘ë¦½"]); data.setdefault("stress_level",30)
    data.setdefault("energy_level",50); data.setdefault("mood_score",0)
    data.setdefault("summary","ì¼ë°˜ì ì¸ ìƒíƒœì…ë‹ˆë‹¤."); data.setdefault("keywords",[])
    data.setdefault("tone","ì¤‘ë¦½ì "); data.setdefault("confidence",0.7)
    # Boundaries
    data["stress_level"]=int(np.clip(data["stress_level"],0,100))
    data["energy_level"]=int(np.clip(data["energy_level"],0,100))
    data["mood_score"]=int(np.clip(data["mood_score"],-70,70))
    data["emotions"]=data["emotions"][:2]
    return data

def analyze_text_simulation(text:str)->dict:
    t=text.lower()
    pos_kw=["ì¢‹","í–‰ë³µ","ë¿Œë“¯","ê¸°ì¨","ì¦ê²","í‰ì˜¨","ë§Œì¡±","ê°ì‚¬","ì„±ê³µ","ì¢‹ì•„"]
    neg_kw=["í˜ë“¤","ë¶ˆì•ˆ","ê±±ì •","ì§œì¦","í™”","ìš°ìš¸","ìŠ¬í””","ìŠ¤íŠ¸ë ˆìŠ¤","í”¼ê³¤","ì–´ë ¤"]
    pos=sum(k in t for k in pos_kw); neg=sum(k in t for k in neg_kw)
    if pos>neg:
        tone="ê¸ì •ì "; stress=max(10,40-8*pos); energy=min(85,50+10*pos); emos=["ê¸°ì¨"]
    elif neg>pos:
        tone="ë¶€ì •ì "; stress=min(85,40+10*neg); energy=max(20,55-8*neg); emos=["ìŠ¬í””"]
    else:
        tone="ì¤‘ë¦½ì "; stress=30; energy=50; emos=["ì¤‘ë¦½"]
    mood=int(np.clip(energy-stress,-70,70))
    return {"emotions":emos,"stress_level":int(stress),"energy_level":int(energy),"mood_score":mood,
            "summary":f"{tone} ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.","keywords":[],"tone":tone,"confidence":0.55}

# =============================
# Fusion (voice as auxiliary)
# =============================
def combine_text_and_voice(text_analysis, voice_analysis=None):
    if not voice_analysis or "voice_cues" not in voice_analysis:
        return text_analysis
    cues = voice_analysis["voice_cues"]; quality=float(cues.get("quality",0.5))
    base_alpha = 0.25*quality
    # í’ˆì§ˆ ë‚®ìœ¼ë©´ ë³´ì • 0
    if quality < 0.3: base_alpha = 0.0
    tone=text_analysis.get("tone","ì¤‘ë¦½ì ")
    if tone=="ê¸ì •ì ": base_alpha*=0.6
    elif tone=="ë¶€ì •ì ": base_alpha*=0.9
    MAX_DS,MAX_DE,MAX_DM = 12,12,10
    stress=text_analysis.get("stress_level",30)
    energy=text_analysis.get("energy_level",50)
    mood=text_analysis.get("mood_score",0)
    delta_energy = base_alpha * ((cues["arousal"]-50)/50.0)*12
    delta_stress = base_alpha * (((cues["tension"]-50)/50.0)*12 - ((cues["stability"]-50)/50.0)*6)
    delta_mood   = base_alpha * ((cues["stability"]-50)/50.0)*8 - base_alpha*((cues["tension"]-50)/50.0)*6
    delta_stress=float(np.clip(delta_stress,-MAX_DS,MAX_DS))
    delta_energy=float(np.clip(delta_energy,-MAX_DE,MAX_DE))
    delta_mood=float(np.clip(delta_mood,-MAX_DM,MAX_DM))
    combined=dict(text_analysis)
    combined["stress_level"]=int(np.clip(stress+delta_stress,0,100))
    combined["energy_level"]=int(np.clip(energy+delta_energy,0,100))
    combined["mood_score"]=int(np.clip(mood+delta_mood,-70,70))
    combined["confidence"]=float(np.clip(text_analysis.get("confidence",0.7)+0.12*quality,0,1))
    combined["voice_analysis"]=voice_analysis
    return combined

# =============================
# ASR: Preprocess + Prompting + Postprocess
# =============================
def build_initial_prompt_from_history(entries, limit=10):
    kws=[]
    for e in entries[-limit:]:
        a=e.get("analysis",{})
        kws += a.get("keywords",[])
    uniq=[k for k in dict.fromkeys(kws) if 1<len(k)<=15]
    return ("í‚¤ì›Œë“œ: " + ", ".join(uniq[:15])) if uniq else ""

def preprocess_audio_for_asr(audio_bytes:bytes, target_sr=16000)->bytes:
    # Minimal-safe preprocessing pipeline; works even if some deps missing
    if not librosa or not sf:
        return audio_bytes
    y, sr = librosa.load(io.BytesIO(audio_bytes), sr=target_sr, mono=True)
    if y.size==0: return audio_bytes
    # pre-emphasis
    try:
        y = librosa.effects.preemphasis(y, coef=0.97)
    except Exception:
        pass
    # Simple VAD using webrtcvad if available
    if webrtcvad:
        try:
            vad = webrtcvad.Vad(2)
            frame_ms=30; frame_len=int(target_sr*frame_ms/1000)
            pcm=(np.clip(y,-1.0,1.0)*32767).astype(np.int16).tobytes()
            frames=[pcm[i:i+frame_len*2] for i in range(0,len(pcm),frame_len*2)]
            voiced=[]
            for f in frames:
                if len(f)<frame_len*2: continue
                if vad.is_speech(f, target_sr): voiced.append(f)
            if voiced: pcm=b"".join(voiced)
            y = np.frombuffer(pcm, dtype=np.int16).astype(np.float32)/32768.0
        except Exception:
            pass
    # RMS normalize (safe)
    rms = float(np.sqrt(np.mean(y**2))+1e-8)
    gain = float(np.clip(0.08 / rms, 0.5, 4.0))
    y = np.clip(y*gain, -1.0, 1.0)
    buf=io.BytesIO()
    sf.write(buf, y, target_sr, subtype="PCM_16", format="WAV")
    return buf.getvalue()

def postprocess_korean_text(text:str)->str:
    s=text.strip().replace("..",".").replace("  "," ")
    # simple de-dup punctuation
    while ".." in s: s=s.replace("..",".")
    return s

def is_low_quality_for_asr(vf:dict)->bool:
    return (vf.get("duration_sec",0)<2.0) or (vf.get("hnr",15)<8) or (vf.get("energy_mean",0)<0.03)

def transcribe_audio(audio_bytes:bytes)->str|None:
    if not openai_client: return None
    try:
        processed = preprocess_audio_for_asr(audio_bytes, target_sr=16000)
        tmp=None
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t:
            t.write(processed); tmp=t.name
        init_prompt = build_initial_prompt_from_history(st.session_state.diary_entries)
        def _call(temp=0):
            with open(tmp,"rb") as fh:
                return openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=fh,
                    language="ko",
                    temperature=temp,
                    prompt=init_prompt or None
                )
        out = call_llm_safely(_call, 0)
        if (not out or not getattr(out,"text",None)) and not is_low_quality_for_asr(VoiceFeatureExtractor().extract(audio_bytes)):
            # second try with slight temp
            out = call_llm_safely(_call, 0.2)
        if tmp and os.path.exists(tmp):
            try: os.unlink(tmp)
            except Exception: pass
        if not out or not getattr(out,"text",None): return None
        return postprocess_korean_text(out.text)
    except Exception as e:
        print("ASR error:", e)
        return None

# =============================
# Coaching (2ì°¨ LLM with RAG)
# =============================
COACH_SYSTEM = (
    "ë„ˆëŠ” í•œêµ­ì–´ ì›°ë¹™ ì½”ì¹˜ë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¥¸ë‹¤.\n"
    "- ì˜ë£Œì  ì§„ë‹¨/ì•½ë¬¼/ìœ„í—˜íŒë‹¨/ìí•´ ì¡°ì–¸ ê¸ˆì§€. í•„ìš”í•œ ê²½ìš° ì „ë¬¸ê°€ ìƒë‹´ ê¶Œê³  ë¬¸êµ¬ë§Œ.\n"
    "- ì œì•ˆì€ ìƒí™œ ìŠµê´€/í˜¸í¡/ìš´ë™/ì‹œê°„ê´€ë¦¬/í™˜ê²½ì¡°ì •ì˜ ë²”ìœ„ì—ì„œë§Œ.\n"
    "- ì œê³µëœ kb_context(ì§€ì‹ë¬¸ì„œ) ê·¼ê±°ì— **ë°˜ë“œì‹œ** ê¸°ë°˜í•´ì„œ ë‹µí•œë‹¤. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'ê·¼ê±° ì—†ìŒ'ìœ¼ë¡œ ëª…ì‹œ.\n"
    "- í–‰ë™ ì¶”ì²œì€ ìµœëŒ€ 4ê°œ, ê° 1~2ë¬¸ì¥, êµ¬ì²´ì  ìˆ˜ì¹˜(ë¶„/íšŒ/ì‹œê°„)ë¥¼ í¬í•¨.\n"
    "- JSONìœ¼ë¡œë§Œ ì‘ë‹µí•œë‹¤. ìŠ¤í‚¤ë§ˆ: "
    '{"state":"ìƒíƒœ","summary":"ìš”ì•½","positives":["ê¸ì •ìš”ì†Œ"],'
    '"recommendations":["í–‰ë™"],"motivation":"ê²©ë ¤","citations":[{"source":"íŒŒì¼","page":0}]}'
)

def build_coach_payload(text, combined, kb_ctx):
    cues = combined.get("voice_analysis",{}).get("voice_cues",{})
    return {
        "text": text,
        "signal": {
            "stress": combined.get("stress_level",0),
            "energy": combined.get("energy_level",0),
            "mood": combined.get("mood_score",0),
            "voice": {
                "arousal": int(cues.get("arousal",50)),
                "tension": int(cues.get("tension",50)),
                "stability": int(cues.get("stability",50)),
                "quality": float(cues.get("quality",0.5)),
            },
        },
        "kb_context": kb_ctx,
        "constraints": {"max_items":4,"no_medical":True,"language":"ko-KR"}
    }

def coach_with_rag(text, combined, kb_ctx)->dict:
    if not openai_client:
        return assess_mental_state(text, combined)  # fallback
    payload = build_coach_payload(text, combined, kb_ctx)
    def _call():
        return openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.4,
            max_tokens=650,
            response_format={"type":"json_object"},
            messages=[
                {"role":"system","content":COACH_SYSTEM},
                {"role":"user","content":json.dumps(payload, ensure_ascii=False)}
            ]
        )
    resp = call_llm_safely(_call)
    if not resp or not resp.choices or not resp.choices[0].message.content:
        return assess_mental_state(text, combined)
    data = safe_json_parse(resp.choices[0].message.content)
    if not data:
        return assess_mental_state(text, combined)
    data.setdefault("state","ì¤‘ë¦½"); data.setdefault("summary","ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”.")
    data.setdefault("positives",[]); data.setdefault("recommendations",[])
    data.setdefault("motivation","ì‘ì€ ê±¸ìŒì´ í° ë³€í™”ë¥¼ ë§Œë“­ë‹ˆë‹¤."); data.setdefault("citations",[])
    data["recommendations"]=data.get("recommendations",[])[:4]
    data["positives"]=data.get("positives",[])[:4]
    return data

# =============================
# Fallback Coach (rule-based)
# =============================
def extract_positive_events(text:str)->list[str]:
    t=text.lower()
    keys=[("ì¢‹ì•˜","ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ ì "),("í–‰ë³µ","í–‰ë³µí•œ ìˆœê°„"),("ê³ ë§ˆ","ê°ì‚¬í•œ ì¼"),
          ("ì¦ê²","ì¦ê±°ì› ë˜ í™œë™"),("í‰ì˜¨","í‰ì˜¨í–ˆë˜ ìˆœê°„"),("ì„±ê³µ","ì„±ì·¨"),
          ("ë¿Œë“¯","ë¿Œë“¯í–ˆë˜ ì¼"),("ë§Œì¡±","ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì¼"),("ì¹œêµ¬","ì¹œêµ¬ë“¤ê³¼ì˜ ì‹œê°„")]
    tags=[v for k,v in keys if k in t]
    return list(dict.fromkeys(tags))[:4]

def assess_mental_state(text, combined)->dict:
    tone=combined.get("tone","ì¤‘ë¦½ì ")
    stress=combined.get("stress_level",30)
    energy=combined.get("energy_level",50)
    mood=combined.get("mood_score",0)
    cues=combined.get("voice_analysis",{}).get("voice_cues",{})
    arousal=float(cues.get("arousal",50)); tension=float(cues.get("tension",50))
    stability=float(cues.get("stability",50)); quality=float(cues.get("quality",0.5))
    positives=extract_positive_events(text)
    state="ì¤‘ë¦½"
    if tone=="ê¸ì •ì " and mood>=15 and stress<40: state="ì•ˆì •/íšŒë³µ"
    if energy<40 and mood<0: state="ì €í™œë ¥"
    if stress>=60: state="ê³ ìŠ¤íŠ¸ë ˆìŠ¤"
    if quality>0.4:
        if tension>65 and stability<45: state="ê¸´ì¥ ê³¼ë‹¤"
        elif arousal>70 and stress>45: state="ê³¼í¥ë¶„/ê³¼ë¶€í•˜ ê°€ëŠ¥"
        elif arousal<40 and energy<45: state="ì €ê°ì„±"
    recs=[]
    if tone=="ê¸ì •ì " or positives:
        if positives: recs.append("ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ 3ê°€ì§€ë¥¼ 3ì¤„ë¡œ ê¸°ë¡í•´ ë³´ì„¸ìš”.")
        recs.append("ì¢‹ì•˜ë˜ í™œë™ì„ ë‚´ì¼ 10ë¶„ ë” í•´ë³´ê¸°.")
    if tension>60: recs.append("4-7-8 í˜¸í¡ 3íšŒ(4ì´ˆ ë“¤ìˆ¨,7ì´ˆ ë©ˆì¶¤,8ì´ˆ ë‚ ìˆ¨).")
    if stability<50: recs.append("ëª©/ì–´ê¹¨ ì´ì™„ ìŠ¤íŠ¸ë ˆì¹­ 2ë¶„.")
    if arousal<45 or energy<45: recs.append("í–‡ë¹› 10ë¶„ ì‚°ì±… + ê°€ë²¼ìš´ ì›Œí‚¹ 800~1000ë³´.")
    if arousal>65 and stress>50: recs.append("ì•Œë¦¼ ì¤„ì´ê¸°: 25ë¶„ ì§‘ì¤‘+5ë¶„ íœ´ì‹ 2íšŒ.")
    recs=recs[:4]
    mot="ì‘ì€ ìŠµê´€ì´ ì˜¤ëŠ˜ì˜ ì¢‹ì€ íë¦„ì„ ë‚´ì¼ë¡œ ì‡ìŠµë‹ˆë‹¤."
    if state in ("ê³ ìŠ¤íŠ¸ë ˆìŠ¤","ê¸´ì¥ ê³¼ë‹¤"): mot="í˜¸í¡ì„ ê³ ë¥´ê³ , ì²œì²œíˆ. ë‹¹ì‹ ì˜ ì†ë„ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
    elif state in ("ì €í™œë ¥","ì €ê°ì„±"): mot="ì‘ì€ í•œ ê±¸ìŒì´ ì—ë„ˆì§€ë¥¼ ê¹¨ì›ë‹ˆë‹¤. 10ë¶„ë§Œ ì›€ì§ì—¬ë³¼ê¹Œìš”?"
    summary=f"ìƒíƒœ: {state} Â· ìŠ¤íŠ¸ë ˆìŠ¤ {stress} Â· ì—ë„ˆì§€ {energy} Â· ê°ì„± {int(arousal)} / ê¸´ì¥ {int(tension)} / ì•ˆì • {int(stability)}"
    return {"state":state,"summary":summary,"positives":positives,"recommendations":recs,"motivation":mot,"voice_cues":{"arousal":arousal,"tension":tension,"stability":stability,"quality":quality}}

# =============================
# Weekly Report (fallback kept)
# =============================
def generate_simple_weekly_report(entries:list[dict])->dict:
    if len(entries)<3:
        return {"overall_trend":"ì•ˆì •ì ","key_insights":["ë°ì´í„°ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤."],
                "patterns":{"best_days":[],"challenging_days":[],"emotional_patterns":"ë” ë§ì€ ê¸°ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤."},
                "recommendations":{"priority_actions":["ê¾¸ì¤€í•œ ê¸°ë¡"],"wellness_tips":["í•˜ë£¨ 10ë¶„ ì„±ì°°"],"goals_for_next_week":["ë§¤ì¼ ê°ì • ê¸°ë¡"]},
                "encouragement":"ì¢‹ì€ ì‹œì‘ì…ë‹ˆë‹¤! ê³„ì† ì´ì–´ê°€ìš”."}
    recent=entries[-7:]
    avgS=np.mean([e["analysis"].get("stress_level",0) for e in recent])
    avgE=np.mean([e["analysis"].get("energy_level",0) for e in recent])
    avgM=np.mean([e["analysis"].get("mood_score",0) for e in recent])
    trend="ì•ˆì •ì "
    if avgS<40 and avgE>60: trend="ê°œì„ ë¨"
    elif avgS>70 or avgE<30: trend="ì£¼ì˜í•„ìš”"
    best=max(recent, key=lambda x:x["analysis"].get("mood_score",0))
    worst=min(recent, key=lambda x:x["analysis"].get("mood_score",0))
    return {
        "overall_trend":trend,
        "key_insights":[f"í‰ê·  ìŠ¤íŠ¸ë ˆìŠ¤: {avgS:.0f}","í‰ê·  ì—ë„ˆì§€: {avgE:.0f}",f"í‰ê·  ê¸°ë¶„: {avgM:.0f}"],
        "patterns":{"best_days":[best.get("date","")],"challenging_days":[worst.get("date","")],"emotional_patterns":f"ì´ë²ˆ ì£¼ ì „ë°˜ì ìœ¼ë¡œ {trend} ê²½í–¥."},
        "recommendations":{"priority_actions":["ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ì§‘ì¤‘","ê·œì¹™ì  ìš´ë™"] if avgS>50 else ["í˜„ì¬ ë£¨í‹´ ìœ ì§€"],
                           "wellness_tips":["ëª…ìƒ 5ë¶„","ìì—° ì‚°ì±…","ì¶©ë¶„í•œ ìˆ˜ë©´"],
                           "goals_for_next_week":["ìŠ¤íŠ¸ë ˆìŠ¤ 40 ì´í•˜ ìœ ì§€","ë§¤ì¼ ê°ì • ê¸°ë¡"]},
        "encouragement":"ë§¤ì¼ ê¸°ë¡í•˜ëŠ” ë‹¹ì‹ , ì´ë¯¸ ë©‹ì§‘ë‹ˆë‹¤!"
    }

# =============================
# RAG: PDF â†’ Text â†’ Chunk â†’ Vector â†’ Retrieve (No external deps)
# =============================
def default_kb_candidates():
    # Primary path as requested
    paths = ["ì†Œë¦¬ì¼ê¸°/data/ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",
             "./ì†Œë¦¬ì¼ê¸°/data/ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",
             "data/ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",
             "./data/ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf"]
    return [p for p in paths if os.path.exists(p)]

def read_pdf_text(path)->list[dict]:
    """Return list of {'page':i,'text':...}"""
    if not PyPDF2: return []
    out=[]
    try:
        with open(path,"rb") as f:
            r=PyPDF2.PdfReader(f)
            for i in range(len(r.pages)):
                try:
                    t=r.pages[i].extract_text() or ""
                    t=t.replace("\x00","").strip()
                    if t: out.append({"page":i+1,"text":t})
                except Exception: pass
    except Exception as e:
        print("PDF read error:", e)
    return out

def normalize_text(s:str)->str:
    s=s.replace("\u200b"," ").replace("\xa0"," ").replace("  "," ")
    s=s.replace("\t"," ")
    return s.strip()

def chunk_text(text, chunk_chars=1100, overlap=180):
    text = normalize_text(text)
    chunks=[]
    i=0; n=len(text)
    while i<n:
        j=min(n, i+chunk_chars)
        # try cut at last period for nicer split
        cut=text.rfind(".", i, j)
        if cut==-1 or cut<i+chunk_chars*0.6: cut=j
        chunks.append(text[i:cut].strip())
        i = max(cut - overlap, 0) if cut<n else n
    return [c for c in chunks if c]

def hash_str(s:str)->str: return hashlib.md5(s.encode("utf-8")).hexdigest()

def build_vocab(chunks:list[str])->dict:
    vocab={}
    for c in chunks:
        for w in tokenize(c):
            vocab.setdefault(w,0)
    for i,k in enumerate(vocab.keys()):
        vocab[k]=i
    return vocab

def tokenize(s:str)->list[str]:
    s=s.lower()
    for ch in ",.!?:;()[]{}\"'<>/\n\r\t":
        s=s.replace(ch," ")
    tokens=[t for t in s.split(" ") if t and not t.isnumeric() and len(t)<=30]
    return tokens

def tfidf_matrix(chunks:list[str]):
    # Minimal TF-IDF without sklearn
    docs_tokens=[tokenize(c) for c in chunks]
    vocab={}
    for toks in docs_tokens:
        for t in set(toks): vocab[t]=vocab.get(t,0)+1
    N=len(chunks)
    idf={t: np.log((N+1)/(df+1))+1.0 for t,df in vocab.items()}
    rows=[]
    for toks in docs_tokens:
        tf={}
        for t in toks: tf[t]=tf.get(t,0)+1
        denom=max(1,sum(tf.values()))
        vec={}
        for t,cnt in tf.items():
            vec[t]= (cnt/denom) * idf.get(t,0.0)
        rows.append(vec)
    # map to dense with limited top features to save memory
    # keep top 2048 tokens overall
    top_terms=sorted(idf.items(), key=lambda x:x[1], reverse=True)[:2048]
    term_index={t:i for i,(t,_) in enumerate(top_terms)}
    X=np.zeros((len(chunks), len(term_index)), dtype=np.float32)
    for i,vec in enumerate(rows):
        for t,v in vec.items():
            j=term_index.get(t)
            if j is not None: X[i,j]=v
    # row-normalize
    norms=np.linalg.norm(X, axis=1, keepdims=True)+1e-8
    X=X/norms
    return X, term_index

@st.cache_resource(show_spinner=False)
def build_kb_index(paths:list[str]):
    """Return (index_matrix, metas) or (None,None) on failure."""
    metas=[]
    all_chunks=[]
    for p in paths:
        pages=read_pdf_text(p)
        for pg in pages:
            for ch in chunk_text(pg["text"]):
                all_chunks.append(ch)
                metas.append({"source":os.path.basename(p),"page":pg["page"],"chunk":ch})
    if not all_chunks:
        return None, None
    X, term_index = tfidf_matrix(all_chunks)
    return (X, metas)

def retrieve_kb(query:str, kb_index, kb_meta, top_k=4):
    if kb_index is None or kb_meta is None or kb_index.shape[0]==0:
        return []
    q_tokens=tokenize(query)
    if not q_tokens:
        return []
    # quick & dirty query vector by same idf as doc? We don't have idf here; use bag-of-words approximate
    # We approximate by averaging doc vectors which contain query tokens â€“ fallback: random small noise
    # Better: build query vector using the same term_index we used â€“ but not stored.
    # As an approximation, compute cosine between each chunk text and query using Jaccard over tokens + length weight.
    # Simpler & stable: cosine on character 3-gram vectors (lightweight)
    def char_ngrams(s, n=3):
        s=s.lower()
        s=" ".join(s.split())
        return [s[i:i+n] for i in range(0,max(0,len(s)-n+1))]
    q_ngrams=char_ngrams(query,3)
    if not q_ngrams: return []
    # Chunk scores as Jaccard of n-grams (fast enough for few thousand)
    scores=[]
    q_set=set(q_ngrams)
    for i,m in enumerate(kb_meta):
        c_set=set(char_ngrams(m["chunk"],3))
        inter=len(q_set & c_set); union=len(q_set | c_set)+1e-6
        s=inter/union
        scores.append((s,i))
    scores.sort(reverse=True)
    out=[]
    for _,i in scores[:top_k]:
        m=kb_meta[i]
        out.append({"chunk":m["chunk"],"source":m["source"],"page":m["page"]})
    return out

def ensure_kb_ready():
    if st.session_state.kb_ready: return
    candidates = default_kb_candidates()
    # Also allow upload
    up = st.session_state.get("kb_uploaded_bytes")
    if up:
        tmp_path = os.path.join(tempfile.gettempdir(), f"kb_{hashlib.md5(up).hexdigest()}.pdf")
        if not os.path.exists(tmp_path):
            with open(tmp_path,"wb") as f: f.write(up)
        candidates = [tmp_path] + candidates
    if not candidates:
        st.session_state.kb_index, st.session_state.kb_meta = None, None
        st.session_state.kb_ready = True
        return
    idx, meta = build_kb_index(candidates)
    st.session_state.kb_index, st.session_state.kb_meta = idx, meta
    st.session_state.kb_ready=True

# =============================
# Altair Chart helper (x label horizontal)
# =============================
def bar_chart_no_tilt(df, x_col, y_col, title=None):
    try:
        import altair as alt
        chart = alt.Chart(df).mark_bar().encode(
            x=alt.X(f"{x_col}:N", axis=alt.Axis(labelAngle=0)),
            y=alt.Y(f"{y_col}:Q")
        ).properties(title=title).interactive()
        st.altair_chart(chart, use_container_width=True)
    except Exception:
        st.bar_chart(df.set_index(x_col)[[y_col]])

# =============================
# UI Blocks
# =============================
def onboarding():
    if not st.session_state.onboarding_completed:
        with st.expander("ğŸŒŸ ì²˜ìŒ ì‚¬ìš©ì ê°€ì´ë“œ", expanded=True):
            st.markdown("""
            - ğŸ™ï¸ **ìŒì„±ìœ¼ë¡œ ë§í•˜ê¸°**ê°€ ê°€ì¥ ì‰¬ì›Œìš”. 2~3ë¶„ ê¶Œì¥, ì¡°ìš©í•œ ê³³ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ.
            - âœï¸ í…ìŠ¤íŠ¸ë¡œ ì ì–´ë„ ì¢‹ì•„ìš”. ì†”ì§í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ!
            - ë¶„ì„ì€ **í…ìŠ¤íŠ¸ ê¸°ì¤€**, ëª©ì†Œë¦¬ëŠ” **ë³´ì¡° ì§€í‘œ**ì˜ˆìš”.
            """)
            c1,c2=st.columns(2)
            if c1.button("ğŸ¯ ë°”ë¡œ ì‹œì‘í•˜ê¸°"):
                st.session_state.onboarding_completed=True; st.rerun()

def emotion_color(emotions:list[str])->str:
    if not emotions: return "#e9ecef"
    cmap={"ê¸°ì¨":"#28a745","í–‰ë³µ":"#28a745","í‰ì˜¨":"#17a2b8","ë§Œì¡±":"#6f42c1",
          "ìŠ¬í””":"#6c757d","ë¶ˆì•ˆ":"#ffc107","ê±±ì •":"#ffc107","ë¶„ë…¸":"#dc3545",
          "ì§œì¦":"#fd7e14","ìŠ¤íŠ¸ë ˆìŠ¤":"#dc3545","í”¼ë¡œ":"#6c757d","ì„¤ë ˜":"#e83e8c","ì¤‘ë¦½":"#e9ecef"}
    for e in emotions:
        if e in cmap: return cmap[e]
    return "#e9ecef"

def emotion_emoji(emotions:list[str])->str:
    if not emotions: return "ğŸ˜"
    em={"ê¸°ì¨":"ğŸ˜Š","í–‰ë³µ":"ğŸ˜Š","í‰ì˜¨":"ğŸ˜Œ","ë§Œì¡±":"ğŸ™‚","ìŠ¬í””":"ğŸ˜¢","ë¶ˆì•ˆ":"ğŸ˜°","ê±±ì •":"ğŸ˜Ÿ","ë¶„ë…¸":"ğŸ˜ ",
        "ì§œì¦":"ğŸ˜¤","ìŠ¤íŠ¸ë ˆìŠ¤":"ğŸ˜µ","í”¼ë¡œ":"ğŸ˜´","ì„¤ë ˜":"ğŸ˜","ì¤‘ë¦½":"ğŸ˜"}
    for e in emotions:
        if e in em: return em[e]
    return "ğŸ˜"

# =============================
# Main Sidebar
# =============================
if not st.session_state.show_disclaimer:
    with st.sidebar:
        st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        st.markdown(f"- {'âœ…' if openai_client else 'âš ï¸'} OpenAI API")
        st.markdown(f"- {'âœ…' if librosa else 'âš ï¸'} ìŒì„± ë¶„ì„(Librosa)")
        st.markdown(f"- {'âœ…' if parselmouth else 'â„¹ï¸'} ê³ ê¸‰ ìŒì„±í•™(Praat)")
        st.markdown(f"- {'âœ…' if PyPDF2 else 'âš ï¸'} PDF íŒŒì„œ")
        if not openai_client:
            with st.expander("ğŸ”‘ OpenAI API í‚¤ ì…ë ¥"):
                api_key=st.text_input("OpenAI API í‚¤", type="password")
                if st.button("ì €ì¥"):
                    if api_key.startswith("sk-"):
                        st.session_state.openai_api_key=api_key
                        st.success("ì €ì¥ë¨. ìƒë‹¨ Rerunìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error("í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.markdown("---")
        page=st.selectbox("í˜ì´ì§€",["ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°","ğŸ’– ë§ˆìŒ ë¶„ì„","ğŸ“ˆ ê°ì • ì—¬ì •","ğŸ“… ê°ì • ìº˜ë¦°ë”","ğŸ¯ ë‚˜ì˜ ëª©í‘œ","ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ","ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤","ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤"])
        if st.session_state.diary_entries:
            st.markdown("### ğŸ“Š í˜„ì¬ ìƒíƒœ")
            latest=st.session_state.diary_entries[-1]; a=latest.get("analysis",{})
            st.metric("ê¸°ë¡ ìˆ˜", f"{len(st.session_state.diary_entries)}ê°œ")
            st.metric("ìµœê·¼ ìŠ¤íŠ¸ë ˆìŠ¤", f"{a.get('stress_level',0)}%")
            st.metric("ìµœê·¼ ì—ë„ˆì§€", f"{a.get('energy_level',0)}%")
            if len(st.session_state.diary_entries)>=7 and st.button("ğŸ“‹ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±"):
                st.session_state.weekly_report = generate_simple_weekly_report(st.session_state.diary_entries)
                st.session_state.show_weekly_report = True
        st.markdown("---")
        st.markdown("### ğŸ“ ë°ì´í„°/KB")
        up_pdf = st.file_uploader("KB PDF ì—…ë¡œë“œ(ì„ íƒ)", type=["pdf"])
        if up_pdf:
            st.session_state.kb_uploaded_bytes = up_pdf.read()
            st.session_state.kb_ready=False
            st.success("KB ì—…ë¡œë“œë¨. ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤.")
        if st.button("ğŸ” KB ì¸ë±ìŠ¤ êµ¬ì¶•/ê°±ì‹ "):
            st.session_state.kb_ready=False
            ensure_kb_ready()
            if st.session_state.kb_index is not None:
                st.success("KB ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ!")
            else:
                st.info("KB ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.markdown("---")
        st.markdown("### â„¹ï¸ ì•± ì •ë³´")
        st.markdown("**ë²„ì „:** v2.1 (RAG/ASR ê³ ë„í™”)")
        st.markdown("**ì‹œê°„ëŒ€:** í•œêµ­ í‘œì¤€ì‹œ (KST)")

# =============================
# Pages
# =============================
def page_today():
    st.header("ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?")
    onboarding()
    extractor=VoiceFeatureExtractor()
    audio_val = st.audio_input("ğŸ¤ ë§ˆìŒì„ í¸í•˜ê²Œ ë§í•´ë³´ì„¸ìš”", help="ë…¹ìŒ í›„ ì—…ë¡œë“œ (2~3ë¶„ ê¶Œì¥)")
    text_input = st.text_area("âœï¸ ê¸€ë¡œ í‘œí˜„í•´ë„ ì¢‹ì•„ìš”", placeholder="ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ë¥¼ ì ì–´ì£¼ì„¸ìš”...", height=120)

    if st.button("ğŸ’ ë¶„ì„í•˜ê³  ì €ì¥", type="primary"):
        diary_text = text_input.strip()
        voice_analysis=None; audio_b64=None

        if audio_val is not None:
            audio_bytes=audio_val.read()
            audio_b64=base64.b64encode(audio_bytes).decode()
            with st.spinner("ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ ê³„ì‚° ì¤‘..."):
                vf=extractor.extract(audio_bytes)
                update_baseline(vf)
                voice_analysis=analyze_voice_as_cues(vf, st.session_state.prosody_baseline)
            if openai_client and not diary_text:
                with st.spinner("ğŸ¤– ìŒì„± â†’ í…ìŠ¤íŠ¸ ì „ì‚¬ ì¤‘..."):
                    tx = transcribe_audio(audio_bytes)
                    if tx:
                        diary_text=tx
                        st.info(f"ğŸ¤ ë“¤ì€ ì´ì•¼ê¸°: {tx}")
                    else:
                        st.warning("ì „ì‚¬ê°€ ì–´ë ¤ì› ì–´ìš”. í…ìŠ¤íŠ¸ë¡œ ê°„ë‹¨íˆ ì ì–´ì£¼ì„¸ìš”!")

        if not diary_text:
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„±ì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")
            return

        cues_for_prompt = voice_analysis["voice_cues"] if voice_analysis else None
        with st.spinner("ğŸ¤– í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„ ì¤‘..."):
            t_res = analyze_text_with_llm(diary_text, cues_for_prompt)

        final = combine_text_and_voice(t_res, voice_analysis)

        # RAG ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        ensure_kb_ready()
        kb_ctx=[]
        if st.session_state.kb_index is not None:
            q = f"ìŠ¤íŠ¸ë ˆìŠ¤ {final.get('stress_level',0)} ì—ë„ˆì§€ {final.get('energy_level',0)} ê¸°ë¶„ {final.get('mood_score',0)} {diary_text[:200]}"
            kb_ctx = retrieve_kb(q, st.session_state.kb_index, st.session_state.kb_meta, top_k=4)

        with st.spinner("ğŸ§  2ì°¨ ì½”ì¹­ ìƒì„± ì¤‘..."):
            coach_card = coach_with_rag(diary_text, final, kb_ctx) if kb_ctx else assess_mental_state(diary_text, final)

        entry={
            "id": len(st.session_state.diary_entries)+1,
            "date": today_key(),
            "time": current_time(),
            "text": diary_text,
            "analysis": final,
            "audio_data": audio_b64,
            "mental_state": coach_card
        }
        st.session_state.diary_entries.append(entry)
        st.success("ğŸ‰ ì†Œì¤‘í•œ ì´ì•¼ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

        # ê²°ê³¼ í‘œì‹œ
        c1,c2,c3=st.columns(3)
        with c1:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            st.subheader("ğŸ’– ê°ì • (í…ìŠ¤íŠ¸ ê¸°ë°˜)")
            st.write(", ".join(final.get("emotions",[])))
            st.caption("ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.")
            st.markdown("</div>", unsafe_allow_html=True)
        with c2:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            st.subheader("ğŸ“Š ë§ˆìŒ ìƒíƒœ")
            sc="metric-negative" if final['stress_level']>60 else ("metric-positive" if final['stress_level']<30 else "metric-neutral")
            ec="metric-positive" if final['energy_level']>60 else ("metric-negative" if final['energy_level']<40 else "metric-neutral")
            st.markdown(f"**ìŠ¤íŠ¸ë ˆìŠ¤:** <span class='{sc}'>{final['stress_level']}%</span>", unsafe_allow_html=True)
            st.markdown(f"**í™œë ¥:** <span class='{ec}'>{final['energy_level']}%</span>", unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)
        with c3:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            st.subheader("ğŸ¯ ì»¨ë””ì…˜")
            mc="metric-positive" if final['mood_score']>10 else ("metric-negative" if final['mood_score']<-10 else "metric-neutral")
            st.markdown(f"**ë§ˆìŒ ì ìˆ˜:** <span class='{mc}'>{final['mood_score']}</span>", unsafe_allow_html=True)
            st.metric("ë¶„ì„ ì‹ ë¢°ë„", f"{final.get('confidence',0.6):.2f}")
            st.markdown("</div>", unsafe_allow_html=True)

        if voice_analysis:
            st.markdown("### ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ (ë³´ì¡° ì§€í‘œ)")
            cues = final["voice_analysis"]["voice_cues"]
            qtxt="ë†’ìŒ" if cues["quality"]>0.7 else ("ë³´í†µ" if cues["quality"]>0.4 else "ë‚®ìŒ")
            d1,d2,d3,d4=st.columns(4)
            d1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100")
            d2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100")
            d3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100")
            d4.metric("ë…¹ìŒ í’ˆì§ˆ", qtxt)
            st.caption("â€» ëª©ì†Œë¦¬ ì‹ í˜¸ëŠ” ë³´ì¡° ì§€í‘œì…ë‹ˆë‹¤. ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ì…ë‹ˆë‹¤.")

        st.markdown("### ğŸ§  ì˜¤ëŠ˜ì˜ ë§ˆìŒ ì½”ì¹˜")
        card_class = "success-card" if coach_card.get("state")=="ì•ˆì •/íšŒë³µ" else ("warning-card" if "ìŠ¤íŠ¸ë ˆìŠ¤" in coach_card.get("state","") else "card")
        st.markdown(f"<div class='{card_class}'>", unsafe_allow_html=True)
        st.write(f"**ìƒíƒœ:** {coach_card.get('state','ì¤‘ë¦½')}")
        st.write(coach_card.get("summary","ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”."))
        if coach_card.get("positives"):
            st.write("**ğŸŒŸ ì˜¤ëŠ˜ì˜ ë°ì€ í¬ì¸íŠ¸**")
            for p in coach_card["positives"]: st.write(f"â€¢ {p}")
        st.write("**ğŸ’¡ ì¶”ì²œ í–‰ë™**")
        for i, rec in enumerate(coach_card.get("recommendations",[]),1):
            st.write(f"{i}. {rec}")
        if coach_card.get("citations"):
            st.caption("ğŸ“š ê·¼ê±°")
            for c in coach_card["citations"]:
                st.caption(f"- {c.get('source','ë¬¸ì„œ')} p.{c.get('page','?')}")
        st.info(f"ğŸ’ª {coach_card.get('motivation','ì˜¤ëŠ˜ë„ ì˜ í•´ë‚´ì…¨ì–´ìš”.')}")
        st.markdown("</div>", unsafe_allow_html=True)

def page_dashboard():
    st.header("ë§ˆìŒ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ì•„ì§ ì—†ì–´ìš”. ì²« ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”! ğŸ“"); return
    st.subheader("ğŸ“Š ì „ì²´ í†µê³„")
    recent = st.session_state.diary_entries[-30:]
    c1,c2,c3,c4=st.columns(4)
    c1.metric("ì´ ê¸°ë¡ ìˆ˜", f"{len(st.session_state.diary_entries)}ê°œ")
    avgS=np.mean([e["analysis"].get("stress_level",0) for e in recent]); c2.metric("í‰ê·  ìŠ¤íŠ¸ë ˆìŠ¤", f"{avgS:.0f}%")
    avgE=np.mean([e["analysis"].get("energy_level",0) for e in recent]); c3.metric("í‰ê·  ì—ë„ˆì§€", f"{avgE:.0f}%")
    avgM=np.mean([e["analysis"].get("mood_score",0) for e in recent]); c4.metric("í‰ê·  ê¸°ë¶„", f"{avgM:.0f}")

    st.subheader("ğŸ˜Š ê°ì • ë¶„í¬ (ìµœê·¼ 30ê°œ)")
    ec={}
    for e in recent:
        for em in e["analysis"].get("emotions",[]): ec[em]=ec.get(em,0)+1
    if ec:
        df=pd.DataFrame(list(ec.items()), columns=["ê°ì •","íšŸìˆ˜"])
        bar_chart_no_tilt(df, "ê°ì •", "íšŸìˆ˜", title="ê°ì • ë¶„í¬")

    st.subheader("ğŸ“‹ ìƒì„¸ ê¸°ë¡")
    df=pd.DataFrame([{
        "ë‚ ì§œ":e["date"],"ì‹œê°„":e["time"],"ê°ì •":", ".join(e["analysis"].get("emotions",[])),
        "ìŠ¤íŠ¸ë ˆìŠ¤":e["analysis"].get("stress_level",0),
        "ì—ë„ˆì§€":e["analysis"].get("energy_level",0),
        "ê¸°ë¶„":e["analysis"].get("mood_score",0),
        "í†¤":e["analysis"].get("tone","ì¤‘ë¦½ì "),
        "ì‹ ë¢°ë„":f"{e['analysis'].get('confidence',0.6):.2f}"
    } for e in st.session_state.diary_entries])
    c1,c2=st.columns(2)
    with c1: date_filter=st.date_input("ë‚ ì§œ í•„í„° (ì´í›„)", value=None)
    with c2: emotion_filter=st.selectbox("ê°ì • í•„í„°", ["ì „ì²´"]+list(ec.keys()))
    fdf=df.copy()
    if date_filter: fdf=fdf[pd.to_datetime(fdf["ë‚ ì§œ"])>=pd.to_datetime(date_filter)]
    if emotion_filter!="ì „ì²´": fdf=fdf[fdf["ê°ì •"].str.contains(emotion_filter)]
    st.dataframe(fdf, use_container_width=True, hide_index=True,
                 column_config={"ìŠ¤íŠ¸ë ˆìŠ¤":st.column_config.ProgressColumn("ìŠ¤íŠ¸ë ˆìŠ¤",max_value=100),
                                "ì—ë„ˆì§€":st.column_config.ProgressColumn("ì—ë„ˆì§€",max_value=100)})

def page_journey():
    st.header("ì‹œê°„ì— ë”°ë¥¸ ë³€í™”")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ìŒ“ì´ë©´ ì¶”ì„¸ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”. ğŸ“ˆ"); return
    c1,c2=st.columns(2)
    with c1: period=st.selectbox("ê¸°ê°„ ì„ íƒ",["ì „ì²´","ìµœê·¼ 30ì¼","ìµœê·¼ 14ì¼","ìµœê·¼ 7ì¼"])
    entries=st.session_state.diary_entries
    if period=="ìµœê·¼ 30ì¼": entries=entries[-30:]
    elif period=="ìµœê·¼ 14ì¼": entries=entries[-14:]
    elif period=="ìµœê·¼ 7ì¼": entries=entries[-7:]
    if len(entries)<2:
        st.warning("ì¶”ì„¸ ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ 2ê°œ ê¸°ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤."); return
    df=pd.DataFrame([{
        "ë‚ ì§œì‹œê°„": f"{e['date']} {e['time']}",
        "ë‚ ì§œ": e['date'],
        "ìŠ¤íŠ¸ë ˆìŠ¤": e["analysis"].get("stress_level",0),
        "ì—ë„ˆì§€": e["analysis"].get("energy_level",0),
        "ê¸°ë¶„": e["analysis"].get("mood_score",0)+70
    } for e in entries])
    with c2: metric=st.selectbox("ì§€í‘œ ì„ íƒ",["ì „ì²´","ìŠ¤íŠ¸ë ˆìŠ¤","ì—ë„ˆì§€","ê¸°ë¶„"])
    if metric=="ì „ì²´":
        st.line_chart(df.set_index("ë‚ ì§œì‹œê°„")[["ìŠ¤íŠ¸ë ˆìŠ¤","ì—ë„ˆì§€","ê¸°ë¶„"]])
    else:
        st.line_chart(df.set_index("ë‚ ì§œì‹œê°„")[[metric]])
        if metric=="ê¸°ë¶„": st.caption("â€» ì‹œê°í™”ë¥¼ ìœ„í•´ +70 ì¡°ì • (ì‹¤ì œ ë²”ìœ„ -70~70)")
    st.subheader("ğŸ“Š ì¶”ì„¸ ë¶„ì„")
    stress_trend=np.polyfit(range(len(entries)), [e["analysis"].get("stress_level",0) for e in entries], 1)[0]
    energy_trend=np.polyfit(range(len(entries)), [e["analysis"].get("energy_level",0) for e in entries], 1)[0]
    mood_trend=np.polyfit(range(len(entries)), [e["analysis"].get("mood_score",0) for e in entries], 1)[0]
    c1,c2,c3=st.columns(3)
    c1.metric("ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì„¸", "ğŸ“‰ ê°ì†Œ" if stress_trend<-0.1 else ("ğŸ“ˆ ì¦ê°€" if stress_trend>0.1 else "â¡ï¸ ì•ˆì •"), delta=f"{stress_trend:.2f}")
    c2.metric("ì—ë„ˆì§€ ì¶”ì„¸", "ğŸ“ˆ ì¦ê°€" if energy_trend>0.1 else ("ğŸ“‰ ê°ì†Œ" if energy_trend<-0.1 else "â¡ï¸ ì•ˆì •"), delta=f"{energy_trend:.2f}")
    c3.metric("ê¸°ë¶„ ì¶”ì„¸", "ğŸ“ˆ ê°œì„ " if mood_trend>0.1 else ("ğŸ“‰ í•˜ë½" if mood_trend<-0.1 else "â¡ï¸ ì•ˆì •"), delta=f"{mood_trend:.2f}")
    st.subheader("ğŸ” ì¸ì‚¬ì´íŠ¸")
    insights=[]
    if stress_trend<-0.5: insights.append("âœ¨ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ê¾¸ì¤€íˆ ê°ì†Œ ì¤‘! í˜„ì¬ ë°©ì‹ì„ ìœ ì§€í•´ë³´ì„¸ìš”.")
    elif stress_trend>0.5: insights.append("âš ï¸ ìŠ¤íŠ¸ë ˆìŠ¤ ì¦ê°€ ì¶”ì„¸. íœ´ì‹ê³¼ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if energy_trend>0.5: insights.append("ğŸ”‹ ì—ë„ˆì§€ ë ˆë²¨ ìƒìŠ¹ ì¤‘! ì¢‹ì€ ìŠµê´€ì„ ì´ì–´ê°€ìš”.")
    elif energy_trend<-0.5: insights.append("ğŸ˜´ ì—ë„ˆì§€ í•˜ë½. ìˆ˜ë©´/ìš´ë™/ì˜ì–‘ ë£¨í‹´ ì ê²€ì„.")
    if mood_trend>0.5: insights.append("ğŸ˜Š ê¸°ë¶„ì´ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì•„ì§€ê³  ìˆì–´ìš”!")
    elif mood_trend<-0.5: insights.append("ğŸ’™ ê¸°ë¶„ í•˜ë½. ìê¸°ëŒë´„ ì‹œê°„ì„ í™•ë³´í•´ìš”.")
    if not insights: insights.append("ğŸ“Š ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.")
    for s in insights: st.info(s)

def page_calendar():
    st.header("ğŸ“… ê°ì • ìº˜ë¦°ë”")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ìŒ“ì´ë©´ ìº˜ë¦°ë”ë¡œ íŒ¨í„´ì„ ë³¼ ìˆ˜ ìˆì–´ìš”!"); return
    today=kst_now()
    months=set([e["date"][:7] for e in st.session_state.diary_entries])
    months.add(today.strftime("%Y-%m"))
    sorted_months=sorted(list(months), reverse=True)
    col1,col2=st.columns([1,3])
    with col1:
        sel=st.selectbox("ì›” ì„ íƒ", sorted_months, index=0,
                         format_func=lambda x:f"{x.split('-')[0]}ë…„ {int(x.split('-')[1])}ì›”")
        year,month = map(int, sel.split('-'))
    with col2:
        st.markdown(f"### {year}ë…„ {month}ì›”")
    month_entries={}
    for e in st.session_state.diary_entries:
        if e["date"].startswith(sel):
            day=int(e["date"].split("-")[2])
            month_entries.setdefault(day,[]).append(e)
    try:
        cal=calendar.monthcalendar(year, month)
    except Exception:
        st.error("ìº˜ë¦°ë” ìƒì„± ì˜¤ë¥˜"); return
    weekdays=["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
    cols=st.columns(7)
    for i,d in enumerate(weekdays): cols[i].markdown(f"<div style='text-align:center;font-weight:bold;padding:8px'>{d}</div>", unsafe_allow_html=True)
    for week_idx,week in enumerate(cal):
        cols=st.columns(7)
        for day_idx,day in enumerate(week):
            if day==0:
                cols[day_idx].markdown("<div style='height:60px;'></div>", unsafe_allow_html=True)
            else:
                entries=month_entries.get(day,[])
                is_today=(day==today.day and month==today.month and year==today.year)
                if entries:
                    latest=entries[-1]; emotions=latest.get("analysis",{}).get("emotions",[])
                    emoji=emotion_emoji(emotions); color=emotion_color(emotions)
                    key=f"cal_{year}_{month}_{day}_{week_idx}_{day_idx}"
                    clicked=cols[day_idx].button(f"{emoji}\n{day}", key=key, help=f"{', '.join(emotions)} ({len(entries)}ê°œ ê¸°ë¡)", use_container_width=True)
                    border="border:2px solid #667eea;" if is_today else "border:1px solid #ddd;"
                    cols[day_idx].markdown(f"<div style='background:{color};opacity:0.3;{border}border-radius:8px;height:10px;margin-top:2px;'></div>", unsafe_allow_html=True)
                    if clicked:
                        st.session_state[f"show_day_{year}_{month}_{day}"]=True
                else:
                    border="border:2px solid #667eea;" if is_today else "border:1px solid #ddd;"
                    cols[day_idx].markdown(f"<div style='{border}border-radius:8px;padding:20px;margin:2px;text-align:center;background:#fafafa;color:#999'>{day}</div>", unsafe_allow_html=True)
    for d in range(1,32):
        sk=f"show_day_{year}_{month}_{d}"
        if st.session_state.get(sk, False):
            entries=month_entries.get(d,[])
            if entries:
                st.markdown(f"### {year}ë…„ {month}ì›” {d}ì¼ ê¸°ë¡")
                for i,e in enumerate(entries):
                    emotions=", ".join(e.get("analysis",{}).get("emotions",[]))
                    with st.expander(f"ğŸ“ {e.get('time','')} - {emotions}", expanded=(i==0)):
                        st.write(e.get("text",""))
                        a=e.get("analysis",{})
                        c1,c2,c3=st.columns(3)
                        c1.metric("ìŠ¤íŠ¸ë ˆìŠ¤", f"{a.get('stress_level',0)}%")
                        c2.metric("ì—ë„ˆì§€", f"{a.get('energy_level',0)}%")
                        c3.metric("ê¸°ë¶„", f"{a.get('mood_score',0)}")
                if st.button("ë‹«ê¸°", key=f"close_{year}_{month}_{d}"):
                    st.session_state[sk]=False; st.rerun()
            break

def page_goals():
    st.header("ğŸ¯ ë‚˜ì˜ ëª©í‘œ ì„¤ì • & ì¶”ì ")
    with st.expander("â• ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€í•˜ê¸°"):
        c1,c2=st.columns(2)
        with c1:
            gtype=st.selectbox("ëª©í‘œ ìœ í˜•",["stress","energy","mood","consistency"],
                format_func=lambda x:{"stress":"ìŠ¤íŠ¸ë ˆìŠ¤ ë‚®ì¶”ê¸°","energy":"ì—ë„ˆì§€ ë†’ì´ê¸°","mood":"ê¸°ë¶„ ê°œì„ ","consistency":"ì£¼ê°„ ê¸°ë¡ íšŸìˆ˜"}[x])
        with c2:
            if gtype=="consistency":
                target=st.slider("ì£¼ê°„ ëª©í‘œ ê¸°ë¡ íšŸìˆ˜",1,7,5); desc=f"ì¼ì£¼ì¼ì— {target}ë²ˆ ì´ìƒ ê¸°ë¡"
            elif gtype=="stress":
                target=st.slider("ëª©í‘œ ìŠ¤íŠ¸ë ˆìŠ¤ (ì´í•˜)",10,50,30); desc=f"ìŠ¤íŠ¸ë ˆìŠ¤ {target} ì´í•˜ ìœ ì§€"
            elif gtype=="energy":
                target=st.slider("ëª©í‘œ ì—ë„ˆì§€ (ì´ìƒ)",50,90,70); desc=f"ì—ë„ˆì§€ {target} ì´ìƒ ìœ ì§€"
            else:
                target=st.slider("ëª©í‘œ ê¸°ë¶„ (ì´ìƒ)",0,50,20); desc=f"ê¸°ë¶„ {target} ì´ìƒ ìœ ì§€"
        custom=st.text_input("ëª©í‘œ ì„¤ëª… (ì„ íƒ)", value=desc)
        if st.button("ëª©í‘œ ì¶”ê°€"):
            st.session_state.user_goals.append({"id":len(st.session_state.user_goals)+1,"type":gtype,"target":target,"description":custom,"created_date":today_key(),"active":True})
            st.success("ëª©í‘œ ì¶”ê°€ ì™„ë£Œ!"); st.rerun()
    active=[g for g in st.session_state.user_goals if g.get("active",True)]
    if not active:
        st.info("ì„¤ì •ëœ ëª©í‘œê°€ ì—†ìŠµë‹ˆë‹¤."); return
    st.subheader("ğŸ“Š ëª©í‘œ ì§„í–‰ ìƒí™©")
    for g in active:
        info=check_goal_progress(g); prog=info["progress"]; cur=info["current_value"]; status=info["status"]
        st.markdown("<div class='card'>", unsafe_allow_html=True)
        c1,c2,c3=st.columns([3,1,1])
        with c1:
            st.write(f"**{g['description']}**"); st.progress(prog/100); st.caption(f"ì§„í–‰ë¥ : {prog:.1f}% | í˜„ì¬ê°’: {cur:.1f}")
        with c2:
            st.success(status) if status=="ë‹¬ì„±!" else st.info(status)
        with c3:
            if st.button("ğŸ—‘ï¸", key=f"del_goal_{g['id']}"):
                g["active"]=False; st.success("ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."); st.rerun()
        st.markdown("</div>", unsafe_allow_html=True)

def check_goal_progress(goal:dict)->dict:
    rec=st.session_state.diary_entries[-7:]
    if not rec: return {"progress":0,"current_value":0,"status":"ì§„í–‰ì¤‘"}
    tp=goal["type"]; target=goal["target"]
    if tp=="consistency":
        cur=len(rec); prog=min(100, (cur/target)*100)
    else:
        vals=[]
        for e in rec:
            a=e.get("analysis",{})
            if tp=="stress": vals.append(a.get("stress_level",0))
            elif tp=="energy": vals.append(a.get("energy_level",0))
            elif tp=="mood": vals.append(a.get("mood_score",0))
        cur=np.mean(vals) if vals else 0
        if tp=="stress":
            prog = 100 if cur<=target else max(0, min(100, (target/cur)*100))
        else:
            prog = min(100, (cur/target)*100) if target>0 else 0
    status = "ë‹¬ì„±!" if prog>=100 else "ì§„í–‰ì¤‘"
    return {"progress":prog,"current_value":cur,"status":status}

def page_voice():
    st.header("ëª©ì†Œë¦¬ ì‹ í˜¸ ìƒì„¸ ë¶„ì„")
    entries=[e for e in st.session_state.diary_entries if e.get("analysis",{}).get("voice_analysis")]
    if not entries:
        st.info("ìŒì„±ìœ¼ë¡œ ê¸°ë¡ëœ í•­ëª©ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ğŸ¤ ì²« ìŒì„± ê¸°ë¡ì„ ë‚¨ê²¨ë³´ì„¸ìš”!"); return
    sel=st.selectbox("ë¶„ì„í•  ê¸°ë¡ ì„ íƒ", entries, index=len(entries)-1,
                     format_func=lambda x:f"{x['date']} {x['time']} - {', '.join(x['analysis'].get('emotions',[]))}")
    voice=sel["analysis"]["voice_analysis"]; vf=voice["voice_features"]; cues=voice["voice_cues"]
    st.subheader("ğŸ¯ ìŒì„± ë³´ì¡°ì§€í‘œ")
    qtxt="ë†’ìŒ" if cues["quality"]>0.7 else ("ë³´í†µ" if cues["quality"]>0.4 else "ë‚®ìŒ")
    c1,c2,c3,c4=st.columns(4)
    c1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100")
    c2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100")
    c3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100")
    c4.metric("ë…¹ìŒ í’ˆì§ˆ", qtxt)
    st.subheader("ğŸ”¬ ê¸°ì´ˆ ìŒì„± íŠ¹ì„±")
    d1,d2=st.columns(2)
    with d1:
        s1,s2=st.columns(2); s1.metric("í”¼ì¹˜ í‰ê· ", f"{vf.get('pitch_mean',0):.1f} Hz"); s2.metric("í”¼ì¹˜ ë³€ë™", f"{vf.get('pitch_variation',0):.3f}")
        s3,s4=st.columns(2); s3.metric("ìŒì„± ì—ë„ˆì§€", f"{vf.get('energy_mean',0):.3f}"); s4.metric("ìµœëŒ€ ì—ë„ˆì§€", f"{vf.get('energy_max',0):.3f}")
    with d2:
        s5,s6=st.columns(2); s5.metric("ë§í•˜ê¸° ì†ë„", f"{vf.get('tempo',0):.0f} BPM"); s6.metric("ì˜êµì°¨ìœ¨", f"{vf.get('zcr_mean',0):.3f}")
        s7,s8=st.columns(2); s7.metric("HNR(ëª…ë£Œë„)", f"{vf.get('hnr',0):.1f} dB"); s8.metric("Jitter(ì•ˆì •)", f"{vf.get('jitter',0):.4f}")
    if st.session_state.prosody_baseline:
        st.subheader("ğŸ“ˆ ê°œì¸ ë² ì´ìŠ¤ë¼ì¸")
        base=st.session_state.prosody_baseline; st.info(f"{base.get('_count',0)}ê°œ ê¸°ë¡ ê¸°ë°˜ ë² ì´ìŠ¤ë¼ì¸")
        if st.button("ë² ì´ìŠ¤ë¼ì¸ ì´ˆê¸°í™”"):
            st.session_state.prosody_baseline={}; st.success("ì´ˆê¸°í™” ì™„ë£Œ"); st.rerun()
    st.caption("â€» ë³´ì¡°ì§€í‘œì´ë©°, ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.")

def page_archive():
    st.header("ë‚˜ì˜ ì´ì•¼ê¸° ì•„ì¹´ì´ë¸Œ")
    if not st.session_state.diary_entries:
        st.info("ì•„ì§ ê¸°ë¡ì´ ì—†ì–´ìš”. ì²« ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”! âœ¨"); return
    if len(st.session_state.diary_entries)>=7:
        c1,c2=st.columns([1,3])
        with c1:
            if st.button("ğŸ“‹ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
                st.session_state.weekly_report = generate_simple_weekly_report(st.session_state.diary_entries)
                st.session_state.show_weekly_report=True
    if st.session_state.get("show_weekly_report",False) and st.session_state.weekly_report:
        r=st.session_state.weekly_report
        st.markdown("### ğŸ“Š ì£¼ê°„ ì›°ë¹™ ë¦¬í¬íŠ¸")
        icon={"ê°œì„ ë¨":"ğŸŸ¢","ì•ˆì •ì ":"ğŸŸ¡","ì£¼ì˜í•„ìš”":"ğŸ”´"}.get(r.get("overall_trend","ì•ˆì •ì "),"ğŸŸ¡")
        st.markdown(f"**ì „ì²´ ì¶”ì„¸:** {icon} {r.get('overall_trend','ì•ˆì •ì ')}")
        if r.get("key_insights"):
            st.markdown("**ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­**"); [st.write(f"â€¢ {x}") for x in r["key_insights"]]
        pat=r.get("patterns",{})
        if pat:
            c1,c2=st.columns(2)
            with c1:
                if pat.get("best_days"):
                    st.markdown("**ğŸŒŸ ì¢‹ì•˜ë˜ ë‚ ë“¤**"); [st.write(f"â€¢ {d}") for d in pat["best_days"]]
            with c2:
                if pat.get("challenging_days"):
                    st.markdown("**ğŸ’ª ë„ì „ì ì´ì—ˆë˜ ë‚ ë“¤**"); [st.write(f"â€¢ {d}") for d in pat["challenging_days"]]
            if pat.get("emotional_patterns"):
                st.markdown("**ğŸ“ˆ ê°ì • íŒ¨í„´**"); st.write(pat["emotional_patterns"])
        rec=r.get("recommendations",{})
        if rec:
            st.markdown("### ğŸ’¡ ë‹¤ìŒ ì£¼ë¥¼ ìœ„í•œ ì¶”ì²œ")
            if rec.get("priority_actions"):
                st.markdown("**ğŸ¯ ìš°ì„ ìˆœìœ„ í–‰ë™**"); [st.write(f"{i+1}. {x}") for i,x in enumerate(rec["priority_actions"])]
            if rec.get("wellness_tips"):
                st.markdown("**ğŸŒ± ì›°ë¹™ íŒ**"); [st.write(f"â€¢ {x}") for x in rec["wellness_tips"]]
            if rec.get("goals_for_next_week"):
                st.markdown("**ğŸ¯ ë‹¤ìŒ ì£¼ ëª©í‘œ**"); [st.write(f"â€¢ {x}") for x in rec["goals_for_next_week"]]
        st.success(f"ğŸ’ª {r.get('encouragement','ì˜í•˜ê³  ìˆì–´ìš”!')}")
        if st.button("ë¦¬í¬íŠ¸ ë‹«ê¸°"):
            st.session_state.show_weekly_report=False; st.rerun()
        st.markdown("---")
    st.subheader("ğŸ” ê¸°ë¡ íƒìƒ‰")
    c1,c2,c3=st.columns(3)
    with c1: stext=st.text_input("ğŸ” í…ìŠ¤íŠ¸ ê²€ìƒ‰", placeholder="í‚¤ì›Œë“œë¡œ ê²€ìƒ‰â€¦")
    with c2:
        all_em=set([em for e in st.session_state.diary_entries for em in e.get("analysis",{}).get("emotions",[])])
        efilter=st.selectbox("ğŸ˜Š ê°ì • í•„í„°", ["ì „ì²´"]+list(all_em))
    with c3: dfilter=st.date_input("ğŸ“… ë‚ ì§œ ì´í›„", value=None)
    ents=st.session_state.diary_entries
    if stext: ents=[e for e in ents if stext.lower() in e.get("text","").lower()]
    if efilter!="ì „ì²´": ents=[e for e in ents if efilter in e.get("analysis",{}).get("emotions",[])]
    if dfilter: ents=[e for e in ents if e.get("date","")>=dfilter.strftime("%Y-%m-%d")]
    st.write(f"**ì´ {len(ents)}ê°œ** (ì „ì²´ {len(st.session_state.diary_entries)}ê°œ ì¤‘)")
    for i,e in enumerate(reversed(ents[-20:])):
        a=e.get("analysis",{}); emos=a.get("emotions",[]); state=e.get("mental_state",{}).get("state","")
        card="success-card" if state=="ì•ˆì •/íšŒë³µ" else ("warning-card" if any(k in state for k in ["ìŠ¤íŠ¸ë ˆìŠ¤","ê¸´ì¥","ê³¼ë¶€í•˜"]) else "card")
        emoji=emotion_emoji(emos)
        with st.expander(f"{emoji} {e['date']} {e['time']} Â· {', '.join(emos)} Â· {state}", expanded=(i==0)):
            st.markdown(f"<div class='{card}'>", unsafe_allow_html=True)
            st.markdown("**ğŸ“ ê¸°ë¡ ë‚´ìš©**"); st.write(e["text"])
            c1,c2,c3=st.columns(3)
            s=a.get("stress_level",0); en=a.get("energy_level",0); m=a.get("mood_score",0)
            c1.write(f"**ìŠ¤íŠ¸ë ˆìŠ¤:** {'ğŸ”´' if s>60 else ('ğŸŸ¡' if s>30 else 'ğŸŸ¢')} {s}%")
            c2.write(f"**ì—ë„ˆì§€:** {'ğŸŸ¢' if en>60 else ('ğŸŸ¡' if en>40 else 'ğŸ”´')} {en}%")
            c3.write(f"**ê¸°ë¶„:** {'ğŸŸ¢' if m>10 else ('ğŸŸ¡' if m>-10 else 'ğŸ”´')} {m}")
            ms=e.get("mental_state",{})
            if ms.get("summary"): st.markdown("**ğŸ§  ì½”ì¹˜ ìš”ì•½**"); st.info(ms["summary"])
            if a.get("voice_analysis"):
                vc=a["voice_analysis"]["voice_cues"]; st.markdown("**ğŸµ ìŒì„± ë³´ì¡°ì§€í‘œ**")
                v1,v2,v3=st.columns(3); v1.write(f"ê°ì„±:{int(vc.get('arousal',0))}"); v2.write(f"ê¸´ì¥:{int(vc.get('tension',0))}"); v3.write(f"ì•ˆì •:{int(vc.get('stability',0))}")
            st.markdown("</div>", unsafe_allow_html=True)

def page_kb():
    st.header("ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤")
    st.write("í–‰ë™ ì¶”ì²œì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œë¥¼ ìƒ‰ì¸í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    ensure_kb_ready()
    if st.session_state.kb_index is None:
        st.info("KBê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ PDF ì—…ë¡œë“œ ë˜ëŠ” ì¸ë±ìŠ¤ êµ¬ì¶•ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return
    q=st.text_input("ğŸ” KB ê²€ìƒ‰ì–´", placeholder="ì˜ˆ) ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í˜¸í¡ë²•, ìˆ˜ë©´ ë£¨í‹´, ê¸´ì¥ ì™„í™”")
    if st.button("ê²€ìƒ‰") and q.strip():
        ctx=retrieve_kb(q, st.session_state.kb_index, st.session_state.kb_meta, top_k=5)
        if not ctx: st.info("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for c in ctx:
                with st.expander(f"ğŸ“„ {c['source']} Â· p.{c['page']}"):
                    st.write(c["chunk"][:1500]+"...")

# =============================
# Export/Reset Sidebar (bottom)
# =============================
def export_sidebar():
    with st.sidebar:
        if st.session_state.diary_entries:
            st.markdown("---"); st.markdown("### ğŸ“ ë°ì´í„° ê´€ë¦¬")
            if st.button("ğŸ“Š CSV ë‚´ë³´ë‚´ê¸°"):
                rows=[]
                for e in st.session_state.diary_entries:
                    a=e["analysis"]; row={"ë‚ ì§œ":e["date"],"ì‹œê°„":e["time"],"í…ìŠ¤íŠ¸":e["text"],
                        "ê°ì •":", ".join(a.get("emotions",[])),"ìŠ¤íŠ¸ë ˆìŠ¤":a.get("stress_level",0),
                        "ì—ë„ˆì§€":a.get("energy_level",0),"ê¸°ë¶„":a.get("mood_score",0),
                        "í†¤":a.get("tone","ì¤‘ë¦½ì "),"ì‹ ë¢°ë„":a.get("confidence",0.6)}
                    ms=e.get("mental_state")
                    if ms: row.update({"ìƒíƒœ":ms.get("state",""),"ì½”ì¹˜ìš”ì•½":ms.get("summary",""),
                                       "ì¶”ì²œì‚¬í•­":" | ".join(ms.get("recommendations",[]))})
                    v=a.get("voice_analysis")
                    if v:
                        vc=v["voice_cues"]; vf=v["voice_features"]
                        row.update({"ê°ì„±ë„":vc.get("arousal",""),"ê¸´ì¥ë„":vc.get("tension",""),
                                    "ì•ˆì •ë„":vc.get("stability",""),"ìŒì§ˆ":vc.get("quality",""),
                                    "í”¼ì¹˜í‰ê· ":vf.get("pitch_mean",""),"ìŒì„±ì—ë„ˆì§€":vf.get("energy_mean",""),
                                    "ë§ì†ë„":vf.get("tempo",""),"HNR":vf.get("hnr","")})
                    rows.append(row)
                df=pd.DataFrame(rows); csv=df.to_csv(index=False, encoding="utf-8-sig")
                st.download_button("ğŸ“¥ ë‹¤ìš´ë¡œë“œ", csv, file_name=f"voice_diary_{kst_now().strftime('%Y%m%d_%H%M')}.csv", mime="text/csv")
            if st.button("ğŸ“‹ JSON ë‚´ë³´ë‚´ê¸°"):
                export={"exported_at":kst_now().isoformat(),"total_entries":len(st.session_state.diary_entries),
                        "entries":st.session_state.diary_entries,"goals":st.session_state.user_goals,
                        "baseline":st.session_state.prosody_baseline}
                js=json.dumps(export, ensure_ascii=False, indent=2)
                st.download_button("ğŸ“¥ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", js, file_name=f"voice_diary_full_{kst_now().strftime('%Y%m%d_%H%M')}.json", mime="application/json")
            st.markdown("---")
            if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ë¡ ì‚­ì œ", type="secondary"):
                if st.button("âš ï¸ ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?", type="secondary"):
                    st.session_state.diary_entries=[]; st.session_state.user_goals=[]; st.session_state.prosody_baseline={}
                    st.success("ëª¨ë“  ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."); st.rerun()

# =============================
# Footer
# =============================
def footer():
    if not st.session_state.show_disclaimer:
        st.markdown("---")
        st.markdown(f"""
        <div style='text-align:center;color:#666;font-size:0.9rem;padding:1rem;'>
            Made with â¤ï¸ | ê°ì • ë¼ë²¨ì€ <strong>í…ìŠ¤íŠ¸ ìš°ì„ </strong> Â· ëª©ì†Œë¦¬ëŠ” <strong>ë³´ì¡°</strong><br>
            ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {kst_now().strftime('%Y-%m-%d %H:%M KST')} |
            ê¸°ë¡ ìˆ˜: {len(st.session_state.diary_entries)}ê°œ |
            ëª©í‘œ ìˆ˜: {len([g for g in st.session_state.user_goals if g.get('active', True)])}ê°œ
        </div>
        """, unsafe_allow_html=True)

# =============================
# Run
# =============================
header()
show_disclaimer()
if not st.session_state.show_disclaimer:
    # Main Router
    extractor=VoiceFeatureExtractor()
    if 'page' not in locals():
        page="ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°"
    if page=="ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°": page_today()
    elif page=="ğŸ’– ë§ˆìŒ ë¶„ì„": page_dashboard()
    elif page=="ğŸ“ˆ ê°ì • ì—¬ì •": page_journey()
    elif page=="ğŸ“… ê°ì • ìº˜ë¦°ë”": page_calendar()
    elif page=="ğŸ¯ ë‚˜ì˜ ëª©í‘œ": page_goals()
    elif page=="ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ": page_voice()
    elif page=="ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤": page_archive()
    elif page=="ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤": page_kb()
    export_sidebar()
footer()

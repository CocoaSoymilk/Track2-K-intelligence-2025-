# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import pytz
import json
import os
import base64
import tempfile
import warnings
import calendar
import random
import numpy as np
from typing import Dict, List, Optional, Tuple
from pathlib import Path

warnings.filterwarnings("ignore")

# Optional viz libs (xì¶• ë¼ë²¨ ìˆ˜í‰ ìœ ì§€ìš©)
try:
    import altair as alt
except Exception:
    alt = None

try:
    import plotly.express as px
except Exception:
    px = None

# =============================
# Timezone Configuration
# =============================
KST = pytz.timezone('Asia/Seoul')

def get_korean_time():
    """í•œêµ­ ì‹œê°„ ë°˜í™˜"""
    return datetime.now(KST)

def today_key() -> str:
    """ì˜¤ëŠ˜ ë‚ ì§œ í‚¤ (YYYY-MM-DD)"""
    return get_korean_time().strftime("%Y-%m-%d")

def current_time() -> str:
    """í˜„ì¬ ì‹œê°„ (HH:MM)"""
    return get_korean_time().strftime("%H:%M")

# =============================
# Page / App Config
# =============================
st.set_page_config(
    page_title="ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - AI ê°ì • ì½”ì¹˜",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================
# Lazy Import Helpers (cached)
# =============================
@st.cache_resource(show_spinner=False)
def get_librosa():
    try:
        import librosa  # type: ignore
        return librosa
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_parselmouth():
    try:
        import parselmouth  # type: ignore
        from parselmouth.praat import call  # noqa: F401
        return parselmouth
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_openai_client():
    # openai íŒ¨í‚¤ì§€ v1 í˜¸í™˜: openai.OpenAI(api_key=...) ë˜ëŠ” from openai import OpenAI; OpenAI()
    try:
        import openai  # type: ignore
        if "OPENAI_API_KEY" in st.secrets:
            return openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])  # type: ignore
        elif "openai_api_key" in st.session_state and st.session_state.openai_api_key:
            return openai.OpenAI(api_key=st.session_state.openai_api_key)  # type: ignore
        else:
            return None
    except Exception:
        return None

openai_client = get_openai_client()

# =============================
# Session State Initialization
# =============================
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "diary_entries" not in st.session_state:
        st.session_state.diary_entries: List[Dict] = []
    if "prosody_baseline" not in st.session_state:
        st.session_state.prosody_baseline: Dict[str, float] = {}
    if "user_goals" not in st.session_state:
        st.session_state.user_goals: List[Dict] = []
    if "show_disclaimer" not in st.session_state:
        st.session_state.show_disclaimer = True
    if "onboarding_completed" not in st.session_state:
        st.session_state.onboarding_completed = False
    if "demo_data_loaded" not in st.session_state:
        st.session_state.demo_data_loaded = False
    if "kb" not in st.session_state:
        st.session_state.kb = None
    if "kb_auto_loaded" not in st.session_state:
        st.session_state.kb_auto_loaded = False

initialize_session_state()

# =============================
# Path Utility for KB
# =============================
def find_default_kb_paths() -> List[Path]:
    """ì—¬ëŸ¬ ì‹¤í–‰ í™˜ê²½ì—ì„œ PDFë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì°¾ê¸° ìœ„í•œ í›„ë³´ ê²½ë¡œë“¤"""
    here = Path(__file__).resolve().parent
    candidates = [
        here / "data" / "ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",  # ì¼ë°˜ì ì¸ data/
        here / "ì†Œë¦¬ì¼ê¸°" / "data" / "ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",  # ì§ˆì˜ì— ëª…ì‹œëœ ê²½ë¡œ(ë¦¬í¬ ìµœìƒë‹¨ì— app.pyê°€ ìˆê³ , í•˜ìœ„ì— ì†Œë¦¬ì¼ê¸°/)
        here.parent / "ì†Œë¦¬ì¼ê¸°" / "data" / "ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",  # app.pyê°€ repo ë£¨íŠ¸/ì†Œë¦¬ì¼ê¸° ì•ˆì— ìˆëŠ” ê²½ìš°
        Path("/mnt/data") / "ì‹¬ë¦¬ ê±´ê°• ê´€ë¦¬ ì •ë¦¬ íŒŒì¼.pdf",  # ë…¸íŠ¸ë¶/í”ŒëŸ¬ê·¸ì¸ í™˜ê²½
    ]
    uniq = []
    seen = set()
    for p in candidates:
        try:
            if p.exists() and str(p) not in seen:
                uniq.append(p)
                seen.add(str(p))
        except Exception:
            pass
    return uniq

# =============================
# Demo Data Generation
# =============================
def generate_demo_data():
    """20ëŒ€ ë‚¨ì„± ëŒ€í•™ìƒ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ê°€ìƒ ë°ì´í„° ìƒì„±"""
    if st.session_state.demo_data_loaded:
        return
    
    demo_scenarios = [
        {
            "text": "ì˜¤ëŠ˜ì€ ì¤‘ê°„ê³ ì‚¬ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆì–´ìš”. ìˆ˜í•™ ì‹œí—˜ì´ ì •ë§ ì–´ë ¤ì› ëŠ”ë° ê·¸ë˜ë„ ë‚˜ë¦„ ì¤€ë¹„í•œ ë§Œí¼ì€ ì“´ ê²ƒ ê°™ì•„ìš”. ì‹œí—˜ ëë‚˜ê³  ì¹œêµ¬ë“¤ì´ë‘ ì¹˜í‚¨ ë¨¹ìœ¼ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ í’€ì—ˆëŠ”ë°, ì—­ì‹œ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ìˆìœ¼ë‹ˆê¹Œ ê¸°ë¶„ì´ ì¢‹ì•„ì§€ë„¤ìš”. ë‚´ì¼ë¶€í„°ëŠ” ì¢€ ì—¬ìœ ë¡­ê²Œ ì§€ë‚¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.",
            "emotions": ["ê¸°ì¨", "í‰ì˜¨"],
            "stress": 35, "energy": 70, "mood": 25, "tone": "ê¸ì •ì "
        },
        {
            "text": "ìš”ì¦˜ ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬í•œí…Œ ê³ ë°±í• ê¹Œ ë§ê¹Œ ê³ ë¯¼ì´ ë„ˆë¬´ ë§ì•„ìš”. ê°™ì´ ìŠ¤í„°ë””ë„ í•˜ê³  ë°¥ë„ ë¨¹ëŠ”ë° ë‚˜í•œí…Œ ê´€ì‹¬ì´ ìˆëŠ” ê±´ì§€ ì˜ ëª¨ë¥´ê² ì–´ìš”. ì˜¤ëŠ˜ë„ ê°™ì´ ë„ì„œê´€ì—ì„œ ê³µë¶€í–ˆëŠ”ë° ìê¾¸ ì˜ì‹í•˜ê²Œ ë˜ì„œ ì§‘ì¤‘ì´ ì•ˆ ë˜ë”ë¼êµ¬ìš”. ìš©ê¸°ë¥¼ ë‚´ì•¼ í•˜ëŠ”ë° ê±°ì ˆë‹¹í• ê¹Œë´ ë¬´ì„­ê¸°ë„ í•˜ê³ ...",
            "emotions": ["ë¶ˆì•ˆ", "ì„¤ë ˜"],
            "stress": 65, "energy": 50, "mood": -5, "tone": "ì¤‘ë¦½ì "
        },
        {
            "text": "ê³¼ì œ ë§ˆê°ì´ ë‚´ì¼ì¸ë° ì•„ì§ ë°˜ë„ ëª»í–ˆì–´ìš”. êµìˆ˜ë‹˜ì´ ê¹Œë‹¤ë¡œìš°ì‹œê¸°ë¡œ ìœ ëª…í•œë° ëŒ€ì¶© ë‚¼ ìˆ˜ë„ ì—†ê³ ... ë°¤ìƒˆì›Œì•¼ê² ì–´ìš”. ì»¤í”¼ ë§ˆì‹œê³  ê°ì„±ì œì²˜ëŸ¼ ì“°ë©´ì„œ ë²„í…¨ì•¼ê² ëŠ”ë°, ìš”ì¦˜ ê³„ì† ì´ëŸ° ì‹ìœ¼ë¡œ ì‚¬ë‹ˆê¹Œ ì»¨ë””ì…˜ì´ ë„ˆë¬´ ì•ˆ ì¢‹ì•„ìš”. ê·œì¹™ì ìœ¼ë¡œ ì‚´ê³  ì‹¶ì€ë° í˜„ì‹¤ì ìœ¼ë¡œ ì–´ë µë„¤ìš”.",
            "emotions": ["ìŠ¤íŠ¸ë ˆìŠ¤", "í”¼ë¡œ"],
            "stress": 85, "energy": 25, "mood": -35, "tone": "ë¶€ì •ì "
        },
        {
            "text": "ë“œë””ì–´ ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬í•œí…Œ ê³ ë°±í–ˆì–´ìš”! ìƒê°ë³´ë‹¤ ë‹´ë‹´í•˜ê²Œ ë°›ì•„ì¤˜ì„œ ë‹¤í–‰ì´ì—ˆê³ , ì—°ì¸ê¹Œì§€ëŠ” ì•„ë‹ˆì–´ë„ ë” ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤ê³  í•˜ë”ë¼êµ¬ìš”. ì™„ì „íˆ ì„±ê³µì€ ì•„ë‹ˆì§€ë§Œ ê·¸ë˜ë„ ë§ˆìŒì´ í›„ë ¨í•´ìš”. ì¹œêµ¬ë“¤ë„ ìš©ê¸°ëƒˆë‹¤ê³  ì¹­ì°¬í•´ì¤˜ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ìš”. ì˜¤ëŠ˜ì€ ì •ë§ ëœ»ê¹Šì€ í•˜ë£¨ì˜€ì–´ìš”.",
            "emotions": ["ê¸°ì¨", "ë§Œì¡±"],
            "stress": 40, "energy": 75, "mood": 30, "tone": "ê¸ì •ì "
        },
        {
            "text": "ì˜¤ëŠ˜ì€ ì •ë§ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´ìš”. ìˆ˜ì—… ë“£ê³ , ë„ì„œê´€ì—ì„œ ê³µë¶€í•˜ê³ , ì§‘ì— ì™€ì„œ ë„·í”Œë¦­ìŠ¤ ë³´ê³ ... íŠ¹ë³„í•  ê±´ ì—†ì—ˆì§€ë§Œ ê·¸ë˜ë„ í‰ì˜¨í•œ ê²Œ ì¢‹ê¸°ë„ í•´ìš”. ìš”ì¦˜ ë„ˆë¬´ ë°”ë¹´ê±°ë“ ìš”. ì´ë ‡ê²Œ ì—¬ìœ ìˆëŠ” ì‹œê°„ì´ ìˆë‹¤ëŠ” ê²Œ ê°ì‚¬í•˜ë„¤ìš”. ë‚´ì¼ì€ ì¹œêµ¬ë“¤ì´ë‘ ë³¼ë§ ì¹˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆì–´ìš”.",
            "emotions": ["í‰ì˜¨", "ë§Œì¡±"],
            "stress": 20, "energy": 60, "mood": 15, "tone": "ê¸ì •ì "
        },
        {
            "text": "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì¡°ì› í•œ ëª…ì´ ê°‘ìê¸° ì—°ë½ë‘ì ˆë˜ì—ˆì–´ìš”. ë°œí‘œê°€ ë‹¤ìŒ ì£¼ì¸ë° ì •ë§ ë‹¹í™©ìŠ¤ëŸ¬ì›Œìš”. ë‚¨ì€ ì¡°ì›ë“¤ë¼ë¦¬ ê·¸ ì¹œêµ¬ ëª«ê¹Œì§€ í•´ì•¼ í•˜ëŠ” ìƒí™©ì´ ë˜ì—ˆëŠ”ë° ì‹œê°„ì€ ë¶€ì¡±í•˜ê³ ... í™”ê°€ ë‚˜ë©´ì„œë„ ì–´ì©” ìˆ˜ ì—†ì´ í•´ì•¼ í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì´ë§Œì €ë§Œì´ ì•„ë‹ˆì—ìš”. ì´ëŸ° ìƒí™©ì´ ì •ë§ í˜ë“¤ì–´ìš”.",
            "emotions": ["ë¶„ë…¸", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "stress": 90, "energy": 40, "mood": -40, "tone": "ë¶€ì •ì "
        },
        {
            "text": "ì¹œêµ¬ë“¤ì´ë‘ MT ë‹¤ë…€ì™”ì–´ìš”! ì •ë§ ì˜¤ëœë§Œì— ìŠ¤íŠ¸ë ˆìŠ¤ ì™„ì „íˆ ë‚ ë ¤ë²„ë¦¬ê³  ì™”ë„¤ìš”. ê²Œì„ë„ í•˜ê³  ë°”ë² íë„ ë¨¹ê³ , ë°¤ìƒˆ ì´ì•¼ê¸°ë„ í•˜ê³ ... ì—­ì‹œ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜í•˜ëŠ” ì‹œê°„ì´ ìµœê³ ì˜ˆìš”. ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬ë„ ê°™ì´ ê°€ì„œ ë” ê°€ê¹Œì›Œì§„ ê²ƒ ê°™ê³ ìš”. ë‚´ì¼ë¶€í„° ë‹¤ì‹œ í˜„ì‹¤ì´ì§€ë§Œ ì˜¤ëŠ˜ë§Œí¼ì€ ì •ë§ í–‰ë³µí–ˆì–´ìš”.",
            "emotions": ["ê¸°ì¨", "í–‰ë³µ"],
            "stress": 15, "energy": 85, "mood": 45, "tone": "ê¸ì •ì "
        }
    ]
    
    base_date = get_korean_time() - timedelta(days=6)
    for i, scenario in enumerate(demo_scenarios):
        entry_date = base_date + timedelta(days=i)
        entry = {
            "id": i + 1,
            "date": entry_date.strftime("%Y-%m-%d"),
            "time": f"{random.randint(18, 22):02d}:{random.randint(0, 59):02d}",
            "text": scenario["text"],
            "analysis": {
                "emotions": scenario["emotions"],
                "stress_level": scenario["stress"],
                "energy_level": scenario["energy"],
                "mood_score": scenario["mood"],
                "summary": f"{scenario['tone']} ìƒíƒœì˜ í•˜ë£¨ë¥¼ ë³´ëƒˆìŠµë‹ˆë‹¤.",
                "keywords": [],
                "tone": scenario["tone"],
                "confidence": round(random.uniform(0.7, 0.9), 2)
            },
            "audio_data": None,
            "mental_state": {
                "state": "ì•ˆì •/íšŒë³µ" if scenario["stress"] < 40 else ("ê³ ìŠ¤íŠ¸ë ˆìŠ¤" if scenario["stress"] > 70 else "ì¤‘ë¦½"),
                "summary": f"ìŠ¤íŠ¸ë ˆìŠ¤ {scenario['stress']}%, ì—ë„ˆì§€ {scenario['energy']}% ìƒíƒœì…ë‹ˆë‹¤.",
                "positives": ["ì¹œêµ¬ë“¤ê³¼ì˜ ì‹œê°„", "ì„±ì·¨ê°"] if scenario["tone"] == "ê¸ì •ì " else [],
                "recommendations": [
                    "ì¶©ë¶„í•œ íœ´ì‹ ì·¨í•˜ê¸°",
                    "ì¹œêµ¬ë“¤ê³¼ ì‹œê°„ ë³´ë‚´ê¸°",
                    "ê·œì¹™ì ì¸ ìƒí™œ íŒ¨í„´ ìœ ì§€í•˜ê¸°"
                ],
                "motivation": "ëŒ€í•™ìƒí™œë„ ì¸ìƒì˜ ì†Œì¤‘í•œ ì‹œê°„ì´ì—ìš”. í•˜ë£¨í•˜ë£¨ ìµœì„ ì„ ë‹¤í•˜ì„¸ìš”!"
            }
        }
        st.session_state.diary_entries.append(entry)
    st.session_state.user_goals = [
        {
            "id": 1,
            "type": "stress",
            "target": 50,
            "description": "ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ë¥¼ 50 ì´í•˜ë¡œ ìœ ì§€í•˜ê¸°",
            "created_date": (get_korean_time() - timedelta(days=5)).strftime("%Y-%m-%d"),
            "active": True
        },
        {
            "id": 2,
            "type": "consistency",
            "target": 5,
            "description": "ì¼ì£¼ì¼ì— 5ë²ˆ ì´ìƒ ê¸°ë¡í•˜ê¸°",
            "created_date": (get_korean_time() - timedelta(days=5)).strftime("%Y-%m-%d"),
            "active": True
        }
    ]
    st.session_state.demo_data_loaded = True

# =============================
# Styles
# =============================
st.markdown(
    """
    <style>
      .main-header{ 
        text-align:center; 
        padding:1.5rem; 
        background:linear-gradient(135deg,#667eea 0%,#764ba2 100%); 
        color:#fff; 
        border-radius:15px; 
        margin-bottom:20px; 
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
      }
      .card{ 
        background:#fff; 
        border:1px solid #e0e6ed; 
        border-left:4px solid #667eea; 
        border-radius:12px; 
        padding:1.2rem; 
        box-shadow:0 2px 10px rgba(0,0,0,0.05); 
        margin-bottom:1rem;
      }
      .success-card{ 
        background:linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); 
        border-left:4px solid #28a745; 
      }
      .warning-card{ 
        background:linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); 
        border-left:4px solid #ffc107; 
      }
      .calendar-day{
        text-align: center;
        padding: 8px;
        margin: 2px;
        border-radius: 8px;
        min-height: 40px;
        cursor: pointer;
      }
      .calendar-today{
        border: 2px solid #667eea;
        font-weight: bold;
      }
      .disclaimer-banner{
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196f3;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
      }
      .goal-progress{
        background: linear-gradient(90deg, #4caf50 0%, #81c784 100%);
        height: 20px;
        border-radius: 10px;
        margin: 5px 0;
      }
      .note{ color:#666; font-size:0.85rem; font-style: italic; }
      .metric-positive { color: #28a745; font-weight: bold; }
      .metric-negative { color: #dc3545; font-weight: bold; }
      .metric-neutral { color: #6c757d; font-weight: bold; }
    </style>
    """,
    unsafe_allow_html=True,
)

# =============================
# Disclaimer and Safety Notice
# =============================
def show_disclaimer():
    """ì„œë¹„ìŠ¤ ì•ˆë‚´ ë° ê³ ì§€ì‚¬í•­"""
    if st.session_state.show_disclaimer:
        st.markdown(
            """
            <div class="disclaimer-banner">
                <h4>ğŸ›¡ï¸ ì„œë¹„ìŠ¤ ì´ìš© ì•ˆë‚´</h4>
                <ul>
                    <li><strong>ì˜ë£Œì  í•œê³„:</strong> ë³¸ ì„œë¹„ìŠ¤ëŠ” ìê¸° ì„±ì°°ì„ ë•ëŠ” ë³´ì¡° ë„êµ¬ì´ë©°, ì˜ë£Œì  ì§„ë‹¨ì´ë‚˜ ì¹˜ë£Œë¥¼ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</li>
                    <li><strong>ë°ì´í„° ë³´ì•ˆ:</strong> ëª¨ë“  ê¸°ë¡ì€ ì„¸ì…˜ ë‚´ì—ì„œë§Œ ì €ì¥ë˜ë©°, ë¸Œë¼ìš°ì € ì¢…ë£Œ ì‹œ ì‚­ì œë©ë‹ˆë‹¤.</li>
                    <li><strong>AI í•œê³„:</strong> AI ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ê°œì¸ì˜ íŒë‹¨ì´ ìš°ì„ ë©ë‹ˆë‹¤.</li>
                    <li><strong>ê¸´ê¸‰ìƒí™©:</strong> ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ë¬¸ì œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.</li>
                </ul>
            </div>
            """,
            unsafe_allow_html=True,
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì´í•´í–ˆìŠµë‹ˆë‹¤", type="primary"):
                st.session_state.show_disclaimer = False
                st.rerun()
        
        with col2:
            if st.button("ğŸ“Š ë°ëª¨ ë°ì´í„°ë¡œ ì‹œì‘í•˜ê¸°"):
                generate_demo_data()
                st.session_state.show_disclaimer = False
                st.success("20ëŒ€ ëŒ€í•™ìƒ í˜ë¥´ì†Œë‚˜ì˜ ê°€ìƒ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

# =============================
# Header
# =============================
if not st.session_state.show_disclaimer:
    st.markdown(
        f"""
        <div class="main-header">
          <h1>ğŸ™ï¸ ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ â€“ AI ê°ì • ì½”ì¹˜</h1>
          <p>ğŸ“… {get_korean_time().strftime('%Yë…„ %mì›” %dì¼ %A')} | â° {current_time()}</p>
          <p>ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜, ëª©ì†Œë¦¬ëŠ” <b>ë³´ì¡° ì§€í‘œ</b>ë¡œ í™œìš©í•©ë‹ˆë‹¤</p>
        </div>
        """,
        unsafe_allow_html=True,
    )

show_disclaimer()

# =============================
# Visualization Helpers (xì¶• ë¼ë²¨ ìˆ˜í‰ ìœ ì§€)
# =============================
def draw_bar_chart_no_rotate(df: pd.DataFrame, x_col: str, y_col: str, title: Optional[str] = None):
    """xì¶• ë¼ë²¨ ê°ë„ 0Â°, ìë™ ê²¹ì¹¨ ìµœì†Œí™”"""
    if alt is not None:
        chart = (
            alt.Chart(df)
            .mark_bar()
            .encode(
                x=alt.X(f"{x_col}:N", axis=alt.Axis(labelAngle=0, labelOverlap="greedy", title=None)),
                y=alt.Y(f"{y_col}:Q", axis=alt.Axis(title=None)),
                tooltip=[x_col, y_col],
            )
            .properties(height=300, title=title or "")
        )
        st.altair_chart(chart, use_container_width=True)
    elif px is not None:
        fig = px.bar(df, x=x_col, y=y_col, title=title or "")
        fig.update_xaxes(tickangle=0)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.bar_chart(df.set_index(x_col)[y_col])

def draw_line_chart_no_rotate(df: pd.DataFrame, x_col: str, y_cols: List[str], title: Optional[str] = None):
    """xì¶• ë¼ë²¨ ê°ë„ 0Â°, ë©€í‹° ì‹œë¦¬ì¦ˆ ì§€ì›"""
    if alt is not None:
        long_df = df.melt(id_vars=[x_col], value_vars=y_cols, var_name="ì§€í‘œ", value_name="ê°’")
        chart = (
            alt.Chart(long_df)
            .mark_line(point=False)
            .encode(
                x=alt.X(f"{x_col}:T", axis=alt.Axis(labelAngle=0, labelOverlap="greedy", title=None)),
                y=alt.Y("ê°’:Q", axis=alt.Axis(title=None)),
                color="ì§€í‘œ:N",
                tooltip=[x_col, "ì§€í‘œ", "ê°’"],
            )
            .properties(height=350, title=title or "")
        )
        st.altair_chart(chart, use_container_width=True)
    elif px is not None:
        fig = px.line(df, x=x_col, y=y_cols, title=title or "")
        fig.update_xaxes(tickangle=0)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.line_chart(df.set_index(x_col)[y_cols])

# =============================
# Feature Extraction Classes
# =============================
class VoiceFeatureExtractor:
    """Prosody feature extractor with graceful fallbacks."""

    def __init__(self, target_sr: int = 22050):
        self.sample_rate = target_sr

    def _load_audio(self, audio_bytes: bytes):
        librosa = get_librosa()
        if not librosa:
            return None, None
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp.write(audio_bytes)
                tmp_path = tmp.name
            y, sr = librosa.load(tmp_path, sr=self.sample_rate, mono=True, res_type="kaiser_fast")
            return y, sr
        except Exception:
            return None, None
        finally:
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except Exception:
                    pass

    def extract(self, audio_bytes: bytes) -> Dict:
        librosa = get_librosa()
        if not librosa:
            return self._default_features()
        try:
            y, sr = self._load_audio(audio_bytes)
            if y is None or np.size(y) == 0 or sr is None:
                return self._default_features()

            duration_sec = max(0.001, float(len(y) / sr))
            
            # RMS energy
            rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]
            energy_mean = float(np.mean(rms))
            energy_max = float(np.max(rms))
            
            # Tempo (guard for short audio)
            if duration_sec >= 2.5:
                tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            else:
                tempo = 110.0
                
            # ZCR
            zcr = librosa.feature.zero_crossing_rate(y, frame_length=1024, hop_length=256)[0]
            zcr_mean = float(np.mean(zcr))
            
            # Spectral centroid
            sc = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_centroid_mean = float(np.mean(sc))
            
            # Pitch proxy
            pitch_mean = 150.0
            pitch_var = 0.13
            try:
                if duration_sec >= 1.0:
                    pitches, mags = librosa.piptrack(y=y, sr=sr, fmin=50, fmax=400)
                    valid = []
                    for t in range(pitches.shape[1]):
                        idx = int(np.argmax(mags[:, t]))
                        p = float(pitches[idx, t])
                        if p > 0:
                            valid.append(p)
                    if valid:
                        va = np.array(valid, dtype=float)
                        pitch_mean = float(np.mean(va))
                        pitch_var = float(np.std(va) / (np.mean(va) + 1e-6))
            except Exception:
                pass

            # HNR / Jitter via parselmouth (optional)
            hnr = 15.0
            jitter = 0.012
            parselmouth = get_parselmouth()
            if parselmouth:
                tmp2 = None
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t2:
                        t2.write(audio_bytes)
                        tmp2 = t2.name
                    snd = parselmouth.Sound(tmp2)
                    harm = snd.to_harmonicity_cc()
                    hnr = float(np.nan_to_num(harm.values.mean(), nan=15.0))
                    pp = parselmouth.praat.call(snd, "To PointProcess (periodic, cc)", 75, 500)
                    jitter = float(parselmouth.praat.call(pp, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3))
                except Exception:
                    pass
                finally:
                    if tmp2 and os.path.exists(tmp2):
                        try:
                            os.unlink(tmp2)
                        except Exception:
                            pass

            return {
                "duration_sec": duration_sec,
                "pitch_mean": pitch_mean,
                "pitch_variation": pitch_var,
                "energy_mean": energy_mean,
                "energy_max": energy_max,
                "tempo": float(tempo),
                "zcr_mean": zcr_mean,
                "spectral_centroid_mean": spectral_centroid_mean,
                "hnr": hnr,
                "jitter": jitter,
            }
        except Exception:
            return self._default_features()

    def _default_features(self) -> Dict:
        return {
            "duration_sec": 0.0,
            "pitch_mean": 150.0,
            "pitch_variation": 0.13,
            "energy_mean": 0.08,
            "energy_max": 0.12,
            "tempo": 110.0,
            "zcr_mean": 0.10,
            "spectral_centroid_mean": 2000.0,
            "hnr": 15.0,
            "jitter": 0.012,
        }

# =============================
# Voice Analysis Functions
# =============================
def prosody_to_dimensions(f: Dict, baseline: Optional[Dict] = None) -> Dict:
    def norm(key: str, val: float) -> float:
        if not baseline or key not in baseline:
            return val
        b = float(baseline.get(key, 0.0))
        return (val / b) if b else val

    tempo = norm("tempo", float(f.get("tempo", 110.0)))
    energy = norm("energy_mean", float(f.get("energy_mean", 0.08)))
    hnr = norm("hnr", float(f.get("hnr", 15.0)))
    jitter = float(f.get("jitter", 0.012))
    zcr = float(f.get("zcr_mean", 0.10))
    sc = norm("spectral_centroid_mean", float(f.get("spectral_centroid_mean", 2000.0)))

    arousal = float(np.clip(35 + 120 * energy + 0.06 * (tempo - 110) + 0.004 * (sc - 2000), 0, 100))
    tension = float(np.clip(28 + 120 * jitter + 0.55 * (zcr - 0.10) * 100, 0, 100))
    stability = float(np.clip(60 + 1.3 * (hnr - 15) - 85 * jitter, 0, 100))

    duration = float(f.get("duration_sec", 4.0))
    quality = float(np.clip(
        0.28 * (duration / 8.0) + 0.42 * np.clip((hnr - 10) / 15, 0, 1) + 0.30 * np.clip((energy - 0.06) / 0.20, 0, 1),
        0, 1
    ))

    return {"arousal": arousal, "tension": tension, "stability": stability, "quality": quality}

def analyze_voice_as_cues(voice_features: Dict, baseline: Optional[Dict] = None) -> Dict:
    dims = prosody_to_dimensions(voice_features, baseline)
    return {"voice_cues": dims, "voice_features": voice_features}

# =============================
# Text Analysis Functions
# =============================
def safe_json_parse(content: str) -> Dict:
    """ì•ˆì „í•œ JSON íŒŒì‹± with ë‹¤ì–‘í•œ í¬ë§· ì§€ì›"""
    if not content or not content.strip():
        return {}
    content = content.strip()
    if content.startswith("```"):
        lines = content.split('\n')
        content = '\n'.join(lines[1:-1]) if len(lines) > 2 else content
    if content.startswith("```json"):
        content = content[7:]
    if content.endswith("```"):
        content = content[:-3]
    content = content.strip()
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        try:
            start = content.find('{')
            end = content.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(content[start:end])
        except json.JSONDecodeError:
            pass
        return {}

def analyze_text_simulation(text: str) -> Dict:
    """LLMì´ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„"""
    t = text.lower()
    pos_kw = ["ì¢‹", "í–‰ë³µ", "ë¿Œë“¯", "ê¸°ì¨", "ì¦ê²", "í‰ì˜¨", "ë§Œì¡±", "ê°ì‚¬", "ì„±ê³µ", "ì¢‹ì•„"]
    neg_kw = ["í˜ë“¤", "ë¶ˆì•ˆ", "ê±±ì •", "ì§œì¦", "í™”", "ìš°ìš¸", "ìŠ¬í””", "ìŠ¤íŠ¸ë ˆìŠ¤", "í”¼ê³¤", "ì–´ë ¤"]
    pos = sum(k in t for k in pos_kw)
    neg = sum(k in t for k in neg_kw)
    if pos > neg:
        tone = "ê¸ì •ì "
        stress = max(10, 40 - 8 * pos)
        energy = min(85, 50 + 10 * pos)
        emos = ["ê¸°ì¨"]
    elif neg > pos:
        tone = "ë¶€ì •ì "
        stress = min(85, 40 + 10 * neg)
        energy = max(20, 55 - 8 * neg)
        emos = ["ìŠ¬í””"]
    else:
        tone = "ì¤‘ë¦½ì "
        stress = 30
        energy = 50
        emos = ["ì¤‘ë¦½"]
    mood = int(np.clip(energy - stress, -70, 70))
    return {
        "emotions": emos,
        "stress_level": int(stress),
        "energy_level": int(energy),
        "mood_score": int(mood),
        "summary": f"{tone} ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.",
        "keywords": [],
        "tone": tone,
        "confidence": 0.55,
    }

def analyze_text_with_llm(text: str, voice_cues_for_prompt: Optional[Dict] = None) -> Dict:
    if not openai_client:
        return analyze_text_simulation(text)
    cues_text = ""
    if voice_cues_for_prompt:
        cues = voice_cues_for_prompt
        cues_text = (
            f"\n(ë³´ì¡°ì§€í‘œ) ê°ì„±:{int(cues.get('arousal',0))}, ê¸´ì¥:{int(cues.get('tension',0))}, "
            f"ì•ˆì •:{int(cues.get('stability',0))}, í’ˆì§ˆ:{cues.get('quality',0):.2f}"
        )
    try:
        sys_msg = (
            "ê°ì • ë¼ë²¨(ê¸°ì¨/ìŠ¬í””/ë¶„ë…¸/ë¶ˆì•ˆ/í‰ì˜¨/ì¤‘ë¦½)ì€ í…ìŠ¤íŠ¸ë¡œë§Œ íŒë‹¨í•˜ì„¸ìš”. "
            "ìŒì„± ì§€í‘œëŠ” ìˆ˜ì¹˜ ë³´ì¡°ë¡œë§Œ ì°¸ê³ í•˜ê³  ë¼ë²¨ì„ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”. "
            "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: "
            '{"emotions": ["ê°ì •1", "ê°ì •2"], "stress_level": ìˆ«ì, "energy_level": ìˆ«ì, "mood_score": ìˆ«ì, "summary": "ìš”ì•½", "keywords": ["í‚¤ì›Œë“œ"], "tone": "í†¤", "confidence": ìˆ«ì}'
        )
        resp = openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.3,
            max_tokens=500,
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": f"ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°: {text}{cues_text}"}
            ],
        )
        content = resp.choices[0].message.content
        if not content:
            return analyze_text_simulation(text)
        data = safe_json_parse(content)
        if not data:
            return analyze_text_simulation(text)
        data.setdefault("emotions", ["ì¤‘ë¦½"])  
        data.setdefault("stress_level", 30)
        data.setdefault("energy_level", 50)
        data.setdefault("mood_score", 0)
        data.setdefault("summary", "ì¼ë°˜ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.")
        data.setdefault("keywords", [])
        data.setdefault("tone", "ì¤‘ë¦½ì ")
        data.setdefault("confidence", 0.7)
        return data
    except Exception as e:
        print(f"LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
        return analyze_text_simulation(text)

# =============================
# Fusion Functions
# =============================
def combine_text_and_voice(text_analysis: Dict, voice_analysis: Optional[Dict]) -> Dict:
    """í…ìŠ¤íŠ¸ ë¶„ì„(ì£¼)ê³¼ ìŒì„± ë¶„ì„(ë³´ì¡°) ê²°í•©"""
    if not voice_analysis or "voice_cues" not in voice_analysis:
        return text_analysis
    cues = voice_analysis["voice_cues"]
    quality = float(cues.get("quality", 0.5))
    base_alpha = 0.25 * quality
    tone = text_analysis.get("tone", "ì¤‘ë¦½ì ")
    if tone == "ê¸ì •ì ":
        base_alpha *= 0.6
    elif tone == "ë¶€ì •ì ":
        base_alpha *= 0.9
    MAX_DS, MAX_DE, MAX_DM = 12, 12, 10
    stress = text_analysis.get("stress_level", 30)
    energy = text_analysis.get("energy_level", 50)
    mood = text_analysis.get("mood_score", 0)
    delta_energy = base_alpha * ((cues["arousal"] - 50) / 50.0) * 12
    delta_stress = base_alpha * (((cues["tension"] - 50) / 50.0) * 12 - ((cues["stability"] - 50) / 50.0) * 6)
    delta_mood = base_alpha * ((cues["stability"] - 50) / 50.0) * 8 - base_alpha * ((cues["tension"] - 50) / 50.0) * 6
    delta_stress = float(np.clip(delta_stress, -MAX_DS, MAX_DS))
    delta_energy = float(np.clip(delta_energy, -MAX_DE, MAX_DE))
    delta_mood = float(np.clip(delta_mood, -MAX_DM, MAX_DM))
    combined = dict(text_analysis)
    combined["stress_level"] = int(np.clip(stress + delta_stress, 0, 100))
    combined["energy_level"] = int(np.clip(energy + delta_energy, 0, 100))
    combined["mood_score"] = int(np.clip(mood + delta_mood, -70, 70))
    combined["confidence"] = float(np.clip(text_analysis.get("confidence", 0.7) + 0.12 * quality, 0, 1))
    combined["voice_analysis"] = voice_analysis
    return combined

# =============================
# Transcription Functions
# =============================
def transcribe_audio(audio_bytes: bytes) -> Optional[str]:
    """Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì „ì‚¬"""
    if not openai_client:
        return None
    try:
        tmp = None
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t:
            t.write(audio_bytes)
            tmp = t.name
        with open(tmp, "rb") as fh:
            out = openai_client.audio.transcriptions.create(
                model="whisper-1", 
                file=fh, 
                language="ko"
            )
        if tmp and os.path.exists(tmp):
            try:
                os.unlink(tmp)
            except Exception:
                pass
        return out.text
    except Exception as e:
        print(f"ìŒì„± ì „ì‚¬ ì˜¤ë¥˜: {e}")
        return None

# =============================
# Baseline Update Functions
# =============================
def update_baseline(vf: Dict):
    """ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸ (ì´ë™í‰ê· )"""
    keys = ["pitch_mean", "tempo", "energy_mean", "hnr", "spectral_centroid_mean"]
    b = st.session_state.prosody_baseline
    count = int(b.get("_count", 0))
    new_count = min(20, count + 1)
    alpha = 1.0 / new_count
    for k in keys:
        v = float(vf.get(k, 0.0))
        prev = float(b.get(k, v))
        b[k] = (1 - alpha) * prev + alpha * v
    b["_count"] = new_count

# =============================
# Coaching Utilities (Rule-based)
# =============================
def extract_positive_events(text: str) -> List[str]:
    t = text.lower()
    keys = [
        ("ì¢‹ì•˜", "ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ ì "),
        ("í–‰ë³µ", "í–‰ë³µí•œ ìˆœê°„"),
        ("ê³ ë§ˆ", "ê°ì‚¬í•œ ì¼"),
        ("ì¦ê²", "ì¦ê±°ì› ë˜ í™œë™"),
        ("í‰ì˜¨", "í‰ì˜¨í–ˆë˜ ìˆœê°„"),
        ("ì„±ê³µ", "ì„±ì·¨"),
        ("ë¿Œë“¯", "ë¿Œë“¯í–ˆë˜ ì¼"),
        ("ë§Œì¡±", "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì¼"),
        ("ì¹œêµ¬", "ì¹œêµ¬ë“¤ê³¼ì˜ ì‹œê°„")
    ]
    tags: List[str] = []
    for k, v in keys:
        if k in t:
            tags.append(v)
    return list(dict.fromkeys(tags))[:4]

def assess_mental_state(text: str, combined: Dict) -> Dict:
    tone = combined.get("tone", "ì¤‘ë¦½ì ")
    stress = combined.get("stress_level", 30)
    energy = combined.get("energy_level", 50)
    mood = combined.get("mood_score", 0)
    cues = combined.get("voice_analysis", {}).get("voice_cues", {})
    arousal = float(cues.get("arousal", 50))
    tension = float(cues.get("tension", 50))
    stability = float(cues.get("stability", 50))
    quality = float(cues.get("quality", 0.5))
    positives = extract_positive_events(text)
    state = "ì¤‘ë¦½"
    if tone == "ê¸ì •ì " and mood >= 15 and stress < 40:
        state = "ì•ˆì •/íšŒë³µ"
    if energy < 40 and mood < 0:
        state = "ì €í™œë ¥"
    if stress >= 60:
        state = "ê³ ìŠ¤íŠ¸ë ˆìŠ¤"
    if quality > 0.4:
        if tension > 65 and stability < 45:
            state = "ê¸´ì¥ ê³¼ë‹¤"
        elif arousal > 70 and stress > 45:
            state = "ê³¼í¥ë¶„/ê³¼ë¶€í•˜ ê°€ëŠ¥"
        elif arousal < 40 and energy < 45:
            state = "ì €ê°ì„±"
    recs: List[str] = []
    if tone == "ê¸ì •ì " or positives:
        if positives:
            recs.append("ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ í¬ì¸íŠ¸ë¥¼ 3ì¤„ë¡œ ê¸°ë¡í•´ ë³´ì„¸ìš” (ê°ì‚¬/ì„±ì·¨/ì¦ê±°ì›€).")
        recs.append("ì¢‹ì•˜ë˜ í™œë™ì„ ë‚´ì¼ 10ë¶„ë§Œ ë” í•´ë³´ê¸°.")
    if tension > 60:
        recs.append("4-7-8 í˜¸í¡ 3íšŒ: 4ì´ˆ ë“¤ì´ë§ˆì‹œê³ , 7ì´ˆ ë©ˆì¶”ê³ , 8ì´ˆ ë‚´ì‰¬ê¸°.")
    if stability < 50:
        recs.append("ëª©/ì–´ê¹¨ ì´ì™„ ìŠ¤íŠ¸ë ˆì¹­ 2ë¶„ (ìƒì²´ íšŒì „, ëª© ì˜†ì„  ëŠ˜ë¦¬ê¸°).")
    if arousal < 45 or energy < 45:
        recs.append("í–‡ë¹› 10ë¶„ ì‚°ì±… + ê°€ë²¼ìš´ ì›Œí‚¹ (Step 800~1000).")
    if arousal > 65 and stress > 50:
        recs.append("ì•Œë¦¼/ìê·¹ ì¤„ì´ê¸°: 25ë¶„ ì§‘ì¤‘ + 5ë¶„ íœ´ì‹(í¬ëª¨ë„ë¡œ 2íšŒ).")
    recs = recs[:4]
    mot = "ì‘ì€ ìŠµê´€ì´ ì˜¤ëŠ˜ì˜ ì¢‹ì€ íë¦„ì„ ë‚´ì¼ë¡œ ì´ì–´ì¤ë‹ˆë‹¤."
    if state in ("ê³ ìŠ¤íŠ¸ë ˆìŠ¤", "ê¸´ì¥ ê³¼ë‹¤"):
        mot = "í˜¸í¡ì„ ê³ ë¥´ê³ , ì²œì²œíˆ. ë‹¹ì‹ ì˜ ì†ë„ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
    elif state in ("ì €í™œë ¥", "ì €ê°ì„±"):
        mot = "ì‘ì€ í•œ ê±¸ìŒì´ ì—ë„ˆì§€ë¥¼ ê¹¨ì›ë‹ˆë‹¤. 10ë¶„ë§Œ ì›€ì§ì—¬ë³¼ê¹Œìš”?"
    summary = (
        f"ìƒíƒœ: {state} Â· ìŠ¤íŠ¸ë ˆìŠ¤ {stress} Â· ì—ë„ˆì§€ {energy} Â· "
        f"ê°ì„± {int(arousal)} / ê¸´ì¥ {int(tension)} / ì•ˆì • {int(stability)}"
    )
    return {
        "state": state,
        "summary": summary,
        "positives": positives,
        "recommendations": recs,
        "motivation": mot,
        "voice_cues": {
            "arousal": arousal,
            "tension": tension,
            "stability": stability,
            "quality": quality
        }
    }

# =============================
# RAG Knowledge Base (PDF -> chunks -> embeddings -> retrieval)
# =============================
def _clean_text_for_kb(text: str) -> str:
    """ë¼ì¸ ë íŠ¹ìˆ˜ë¬¸ì/ìˆ«ì ì œê±°, ê³µë°± ì •ë¦¬ (PDF ì¶”ì¶œ ë…¸ì´ì¦ˆ ì œê±°)"""
    import re
    lines = [re.sub(r"[ \t]*[â€¢Â·\\-â€“â€”]*\s*$", "", ln) for ln in text.splitlines()]
    lines = [re.sub(r"[ \t]*\d{1,3}\s*$", "", ln) for ln in lines]  # ëë‹¨ ìˆ«ì ì œê±°
    blob = "\n".join(ln.strip() for ln in lines if ln.strip())
    blob = re.sub(r"\n{3,}", "\n\n", blob)
    return blob

def _chunk_text(text: str, max_chars: int = 700, overlap: int = 120) -> List[str]:
    """ë¬¸ë‹¨/ë¬¸ì¥ ê²½ê³„ ìš°ì„  ìŠ¬ë¼ì´ë”© ì²­í‚¹ (í•œêµ­ì–´ ì¹œí™”)"""
    paras = [p.strip() for p in text.split("\n\n") if p.strip()]
    chunks: List[str] = []
    buf = ""
    for p in paras:
        if not buf:
            buf = p
        elif len(buf) + 2 + len(p) <= max_chars:
            buf += "\n\n" + p
        else:
            chunks.append(buf)
            tail = buf[-overlap:] if overlap > 0 else ""
            buf = (tail + "\n\n" + p).strip()
            if len(buf) > max_chars:
                for i in range(0, len(buf), max_chars - overlap):
                    sub = buf[i : i + max_chars]
                    chunks.append(sub)
                buf = ""
    if buf:
        chunks.append(buf)
    return chunks

@st.cache_resource(show_spinner=False)
def _get_embedder():
    """ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ìœ í‹¸ (OpenAI ì—†ìœ¼ë©´ í•´ì‹œ ê¸°ë°˜ ëŒ€ì²´)"""
    def embed_with_openai(texts: List[str]) -> List[List[float]]:
        resp = openai_client.embeddings.create(model="text-embedding-3-small", input=texts)
        return [d.embedding for d in resp.data]
    def embed_with_hash(texts: List[str]) -> List[List[float]]:
        dim = 256
        vecs = []
        for t in texts:
            v = np.zeros(dim, dtype=np.float32)
            for tok in t.split():
                idx = (hash(tok) % dim)
                v[idx] += 1.0
            n = np.linalg.norm(v)
            if n > 0:
                v = v / n
            vecs.append(v.tolist())
        return vecs
    if openai_client:
        return embed_with_openai
    else:
        return embed_with_hash

def _cosine_sim(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    an = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)
    bn = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-12)
    return np.dot(an, bn.T)

def _read_pdf_text(path: str) -> str:
    """PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyPDF2 -> pdfplumber í´ë°±)"""
    text = ""
    try:
        import PyPDF2  # type: ignore
        with open(path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                text += page.extract_text() or ""
    except Exception:
        try:
            import pdfplumber  # type: ignore
            with pdfplumber.open(path) as pdf:
                for p in pdf.pages:
                    text += p.extract_text() or ""
        except Exception:
            text = ""
    return text

def rag_build_from_pdf(files: List[Tuple[str, bytes]]) -> Dict:
    """
    files: [(filename, file_bytes)]
    return: {"chunks": List[str], "embeddings": np.ndarray, "meta": List[Dict]}
    """
    all_chunks: List[str] = []
    meta: List[Dict] = []
    for fname, fb in files:
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(fb)
                tmp_path = tmp.name
            raw = _read_pdf_text(tmp_path)
        finally:
            try:
                if tmp_path and os.path.exists(tmp_path):
                    os.unlink(tmp_path)
            except Exception:
                pass
        clean = _clean_text_for_kb(raw)
        chunks = _chunk_text(clean)
        all_chunks.extend(chunks)
        meta.extend([{"source": fname}] * len(chunks))
    if not all_chunks:
        return {"chunks": [], "embeddings": np.zeros((0,256)), "meta": []}
    embedder = _get_embedder()
    vecs = np.array(embedder(all_chunks), dtype=np.float32)
    return {"chunks": all_chunks, "embeddings": vecs, "meta": meta}

def rag_search(query: str, kb: Dict, top_k: int = 5) -> List[Dict]:
    if not kb or not kb.get("chunks"):
        return []
    embedder = _get_embedder()
    qv = np.array(embedder([query])[0], dtype=np.float32)[None, :]
    sims = _cosine_sim(kb["embeddings"], qv).reshape(-1)
    idx = np.argsort(-sims)[:top_k]
    out = []
    for i in idx:
        out.append({
            "chunk": kb["chunks"][int(i)],
            "score": float(sims[int(i)]),
            "source": kb["meta"][int(i)]["source"]
        })
    return out

def derive_action_query(text: str, combined: Dict) -> str:
    """1ì°¨ ë¶„ì„ â†’ 2ì°¨ í–‰ë™ ì¶”ì²œìš© ì§ˆì˜ ì‘ì„±"""
    stress = combined.get("stress_level", 30)
    energy = combined.get("energy_level", 50)
    tone = combined.get("tone", "ì¤‘ë¦½ì ")
    cues = combined.get("voice_analysis", {}).get("voice_cues", {})
    tension = int(cues.get("tension", 50))
    stability = int(cues.get("stability", 50))
    topics = []
    if stress >= 60 or tension >= 60:
        topics += ["ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”", "í˜¸í¡", "ì ì§„ì  ê·¼ìœ¡ ì´ì™„", "ë§ˆìŒì±™ê¹€"]
    if energy <= 40 or stability <= 45:
        topics += ["ì €í™œë ¥ ê°œì„ ", "í–‡ë¹› ì‚°ì±…", "ì§§ì€ íœ´ì‹", "í¬ëª¨ë„ë¡œ"]
    if "ì " in text or "ìˆ˜ë©´" in text or "í”¼ê³¤" in text:
        topics += ["ìˆ˜ë©´ ìœ„ìƒ", "ì·¨ì¹¨ ì „ ë£¨í‹´"]
    if tone == "ê¸ì •ì ":
        topics += ["ê¸ì • ì‹¬ë¦¬", "ê°ì‚¬ ì¼ê¸°"]
    topics = list(dict.fromkeys(topics))
    base = " ".join(topics) if topics else "ë§ˆìŒì±™ê¹€ ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™” íšŒë³µ ê¸ì • ìˆ˜ë©´ íœ´ì‹"
    return f"{base}\nì‚¬ìš©ì ë‚´ìš©: {text[:400]}"

# =============================
# 2ì°¨ LLM ì½”ì¹­ (RAG ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©)
# =============================
def generate_llm_coach_report(text: str, combined: Dict, recent: Optional[List[Dict]] = None) -> Dict:
    """
    1ì°¨(í…ìŠ¤íŠ¸+ë³´ì´ìŠ¤) ê²°ê³¼ + RAG(ì§€ì‹ë² ì´ìŠ¤) ê·¼ê±°ë¡œ
    ìƒíƒœ ìš”ì•½/í–‰ë™ ì¶”ì²œ/ë¯¸ì‹œì¡°ì • ì œì•ˆ ìƒì„±
    """
    kb = st.session_state.get("kb")
    rag_contexts = []
    if kb:
        q = derive_action_query(text, combined)
        rag_contexts = rag_search(q, kb, top_k=5)

    if not openai_client:
        base = assess_mental_state(text, combined)
        if rag_contexts:
            tips = []
            for r in rag_contexts[:3]:
                first_line = r["chunk"].split("\n")[0].strip()
                tips.append(first_line[:120])
            base["recommendations"] = (base.get("recommendations", []) + tips)[:4]
        return base

    cues = combined.get("voice_analysis", {}).get("voice_cues", {})
    history_blob: List[Dict] = []
    if recent:
        for e in recent[-5:]:
            a = e.get("analysis", {})
            history_blob.append({
                "date": e.get("date"),
                "tone": a.get("tone"),
                "stress": a.get("stress_level"),
                "energy": a.get("energy_level"),
                "mood": a.get("mood_score")
            })

    kb_chunks = []
    for r in rag_contexts:
        kb_chunks.append(f"[{r['source']}] {r['chunk']}")
    kb_text = "\n\n".join(kb_chunks[:5])

    sys_msg = (
        "ë‹¹ì‹ ì€ ë”°ëœ»í•œ í•œêµ­ì–´ ì›°ë¹™ ì½”ì¹˜ì…ë‹ˆë‹¤. "
        "ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ ë¶„ì„ì´ ê¸°ì¤€ì´ë©°, ìŒì„±ì€ ê°ì„±/ê¸´ì¥/ì•ˆì •ì˜ ë³´ì¡°ì§€í‘œë¡œë§Œ ê³ ë ¤í•˜ì„¸ìš”. "
        "ì•„ë˜ ì§€ì‹ë² ì´ìŠ¤(KB) ì¡°ê°ë§Œì„ ê·¼ê±°ë¡œ, ê·¼ê±°ì— ë§ëŠ” 'í–‰ë™ ì¶”ì²œ/ë¯¸ì‹œì¡°ì • íŒ'ì„ ì œì‹œí•˜ì„¸ìš”. "
        "ì˜ë£Œì  ì§„ë‹¨/ì¹˜ë£ŒëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”: "
        '{"state": "ìƒíƒœ", "summary": "ìš”ì•½", "positives": ["ê¸ì •ìš”ì†Œ"], "recommendations": ["ì¶”ì²œì‚¬í•­"], "motivation": "ê²©ë ¤ë©”ì‹œì§€"}'
    )

    user_payload = {
        "text": text,
        "text_analysis": {
            "emotions": combined.get("emotions", []),
            "stress": combined.get("stress_level", 30),
            "energy": combined.get("energy_level", 50),
            "mood": combined.get("mood_score", 0),
            "tone": combined.get("tone", "ì¤‘ë¦½ì "),
        },
        "voice_cues": {
            "arousal": int(cues.get("arousal", 50)),
            "tension": int(cues.get("tension", 50)),
            "stability": int(cues.get("stability", 50)),
            "quality": float(cues.get("quality", 0.5)),
        },
        "recent_summary": history_blob,
        "kb_context": kb_text
    }

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.4,
            max_tokens=700,
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)}
            ],
        )
        content = resp.choices[0].message.content or ""
        data = safe_json_parse(content)
        if not data:
            return assess_mental_state(text, combined)
        data.setdefault("state", "ì¤‘ë¦½")
        data.setdefault("summary", "ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”.")
        data.setdefault("positives", [])
        data.setdefault("recommendations", [])
        data.setdefault("motivation", "ì‘ì€ ê±¸ìŒì´ í° ë³€í™”ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
        data["recommendations"] = data.get("recommendations", [])[:4]
        data["positives"] = data.get("positives", [])[:4]
        return data
    except Exception as e:
        print(f"ì½”ì¹­ ë¦¬í¬íŠ¸(RAG) ì˜¤ë¥˜: {e}")
        return assess_mental_state(text, combined)

# =============================
# Weekly Report Functions
# =============================
def generate_simple_weekly_report(entries: List[Dict]) -> Dict:
    if len(entries) < 3:
        return {
            "overall_trend": "ì•ˆì •ì ",
            "key_insights": ["ì•„ì§ ë¶„ì„í•˜ê¸°ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."],
            "patterns": {"best_days": [], "challenging_days": [], "emotional_patterns": "ë” ë§ì€ ê¸°ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤."},
            "recommendations": {
                "priority_actions": ["ê¾¸ì¤€í•œ ê¸°ë¡ ìœ ì§€í•˜ê¸°"],
                "wellness_tips": ["í•˜ë£¨ 10ë¶„ ìê¸° ì„±ì°° ì‹œê°„ ê°–ê¸°"],
                "goals_for_next_week": ["ë§¤ì¼ ê°ì • ê¸°ë¡í•˜ê¸°"]
            },
            "encouragement": "ì¢‹ì€ ì‹œì‘ì…ë‹ˆë‹¤! ê¾¸ì¤€íˆ ê¸°ë¡í•´ë³´ì„¸ìš”."
        }
    recent = entries[-7:]
    avg_stress = np.mean([e.get("analysis", {}).get("stress_level", 0) for e in recent])
    avg_energy = np.mean([e.get("analysis", {}).get("energy_level", 0) for e in recent])
    avg_mood = np.mean([e.get("analysis", {}).get("mood_score", 0) for e in recent])
    if avg_stress < 40 and avg_energy > 60:
        trend = "ê°œì„ ë¨"
    elif avg_stress > 70 or avg_energy < 30:
        trend = "ì£¼ì˜í•„ìš”"
    else:
        trend = "ì•ˆì •ì "
    best_day = max(recent, key=lambda x: x.get("analysis", {}).get("mood_score", 0))
    worst_day = min(recent, key=lambda x: x.get("analysis", {}).get("mood_score", 0))
    return {
        "overall_trend": trend,
        "key_insights": [f"í‰ê·  ìŠ¤íŠ¸ë ˆìŠ¤: {avg_stress:.0f}ì ", f"í‰ê·  ì—ë„ˆì§€: {avg_energy:.0f}ì ", f"í‰ê·  ê¸°ë¶„: {avg_mood:.0f}ì "],
        "patterns": {
            "best_days": [best_day.get("date", "")],
            "challenging_days": [worst_day.get("date", "")],
            "emotional_patterns": f"ì´ë²ˆ ì£¼ëŠ” ì „ë°˜ì ìœ¼ë¡œ {trend} ìƒíƒœë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤."
        },
        "recommendations": {
            "priority_actions": ["ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ì— ì§‘ì¤‘", "ê·œì¹™ì ì¸ ìš´ë™"] if avg_stress > 50 else ["í˜„ì¬ ìƒíƒœ ìœ ì§€"],
            "wellness_tips": ["ëª…ìƒ 5ë¶„", "ìì—° ì‚°ì±…", "ì¶©ë¶„í•œ ìˆ˜ë©´"],
            "goals_for_next_week": ["ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ 40 ì´í•˜ ìœ ì§€", "ë§¤ì¼ ê°ì • ê¸°ë¡"]
        },
        "encouragement": "ë§¤ì¼ ê¸°ë¡í•˜ê³  ê³„ì‹œëŠ” ë…¸ë ¥ì´ ëŒ€ë‹¨í•©ë‹ˆë‹¤!"
    }

def generate_weekly_report(entries: List[Dict]) -> Dict:
    if not openai_client or len(entries) < 7:
        return generate_simple_weekly_report(entries)
    try:
        week_data = []
        for entry in entries[-7:]:
            analysis = entry.get("analysis", {})
            week_data.append({
                "date": entry.get("date"),
                "emotions": analysis.get("emotions", []),
                "stress": analysis.get("stress_level", 0),
                "energy": analysis.get("energy_level", 0),
                "mood": analysis.get("mood_score", 0),
                "tone": analysis.get("tone", "ì¤‘ë¦½ì "),
                "text_summary": entry.get("text", "")[:100] + "..." if len(entry.get("text", "")) > 100 else entry.get("text", "")
            })
        sys_msg = (
            "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì›°ë¹™ ì½”ì¹˜ì…ë‹ˆë‹¤. ì§€ë‚œ 7ì¼ê°„ì˜ ê°ì • ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. "
            "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”: "
            '{"overall_trend": "ì¶”ì„¸", "key_insights": ["ì¸ì‚¬ì´íŠ¸"], "patterns": {"best_days": ["ë‚ ì§œ"], "challenging_days": ["ë‚ ì§œ"], "emotional_patterns": "íŒ¨í„´ì„¤ëª…"}, "recommendations": {"priority_actions": ["í–‰ë™"], "wellness_tips": ["íŒ"], "goals_for_next_week": ["ëª©í‘œ"]}, "encouragement": "ê²©ë ¤ë©”ì‹œì§€"}'
        )
        user_content = f"ì§€ë‚œ 7ì¼ê°„ì˜ ë°ì´í„°: {json.dumps(week_data, ensure_ascii=False)}"
        resp = openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.4,
            max_tokens=800,
            messages=[{"role": "system", "content": sys_msg}, {"role": "user", "content": user_content}]
        )
        content = resp.choices[0].message.content
        if not content:
            return generate_simple_weekly_report(entries)
        data = safe_json_parse(content)
        if not data:
            return generate_simple_weekly_report(entries)
        return data
    except Exception as e:
        print(f"ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return generate_simple_weekly_report(entries)

# =============================
# Calendar Functions
# =============================
def get_emotion_color(emotions: List[str]) -> str:
    if not emotions:
        return "#f8f9fa"
    color_map = {
        "ê¸°ì¨": "#28a745", "í–‰ë³µ": "#28a745",
        "í‰ì˜¨": "#17a2b8", "ë§Œì¡±": "#6f42c1",
        "ìŠ¬í””": "#6c757d", "ë¶ˆì•ˆ": "#ffc107", "ê±±ì •": "#ffc107",
        "ë¶„ë…¸": "#dc3545", "ì§œì¦": "#fd7e14", "ìŠ¤íŠ¸ë ˆìŠ¤": "#dc3545",
        "í”¼ë¡œ": "#6c757d", "ì„¤ë ˜": "#e83e8c", "ì¤‘ë¦½": "#e9ecef",
    }
    for emotion in emotions:
        if emotion in color_map:
            return color_map[emotion]
    return "#e9ecef"

def get_emotion_emoji(emotions: List[str]) -> str:
    if not emotions:
        return "ğŸ˜"
    emoji_map = {
        "ê¸°ì¨": "ğŸ˜Š", "í–‰ë³µ": "ğŸ˜Š", "í‰ì˜¨": "ğŸ˜Œ", "ë§Œì¡±": "ğŸ™‚",
        "ìŠ¬í””": "ğŸ˜¢", "ë¶ˆì•ˆ": "ğŸ˜°", "ê±±ì •": "ğŸ˜Ÿ", "ë¶„ë…¸": "ğŸ˜ ",
        "ì§œì¦": "ğŸ˜¤", "ìŠ¤íŠ¸ë ˆìŠ¤": "ğŸ˜µ", "í”¼ë¡œ": "ğŸ˜´", "ì„¤ë ˜": "ğŸ˜",
        "ì¤‘ë¦½": "ğŸ˜"
    }
    for emotion in emotions:
        if emotion in emoji_map:
            return emoji_map[emotion]
    return "ğŸ˜"

def create_emotion_calendar():
    st.subheader("ğŸ“… ë‚˜ì˜ ê°ì • ìº˜ë¦°ë”")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ìŒ“ì´ë©´ ìº˜ë¦°ë”ë¡œ ê°ì • íŒ¨í„´ì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”!")
        return
    today = get_korean_time()
    available_months = set()
    for entry in st.session_state.diary_entries:
        entry_date = entry.get("date", "")
        if entry_date:
            year_month = entry_date[:7]
            available_months.add(year_month)
    current_month = today.strftime("%Y-%m")
    available_months.add(current_month)
    sorted_months = sorted(list(available_months), reverse=True)
    col1, col2 = st.columns([1, 3])
    with col1:
        if sorted_months:
            selected_month_str = st.selectbox(
                "ì›” ì„ íƒ",
                sorted_months,
                index=0,
                format_func=lambda x: f"{x.split('-')[0]}ë…„ {int(x.split('-')[1])}ì›”"
            )
            year, month = map(int, selected_month_str.split('-'))
            selected_month = datetime(year, month, 1).date()
        else:
            selected_month = today.date().replace(day=1)
    month_str = selected_month.strftime("%Y-%m")
    month_entries = {}
    for entry in st.session_state.diary_entries:
        entry_date = entry.get("date", "")
        if entry_date.startswith(month_str):
            try:
                day = int(entry_date.split("-")[2])
                if day not in month_entries:
                    month_entries[day] = []
                month_entries[day].append(entry)
            except (IndexError, ValueError):
                continue
    year = selected_month.year
    month = selected_month.month
    with col2:
        st.markdown(f"### {year}ë…„ {month}ì›”")
        total_entries_this_month = sum(len(entries) for entries in month_entries.values())
        st.caption(f"ì´ë²ˆ ë‹¬ ì´ {total_entries_this_month}ê°œì˜ ê¸°ë¡")
    try:
        cal = calendar.monthcalendar(year, month)
    except Exception:
        st.error("ìº˜ë¦°ë” ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return
    weekdays = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    cols = st.columns(7)
    for i, day in enumerate(weekdays):
        cols[i].markdown(f"<div style='text-align: center; font-weight: bold; padding: 8px;'>{day}</div>", 
                        unsafe_allow_html=True)
    for week_idx, week in enumerate(cal):
        cols = st.columns(7)
        for day_idx, day in enumerate(week):
            if day == 0:
                cols[day_idx].markdown("<div style='height: 60px;'></div>", unsafe_allow_html=True)
            else:
                entries_for_day = month_entries.get(day, [])
                is_today = (day == today.day and month == today.month and year == today.year)
                if entries_for_day:
                    latest_entry = entries_for_day[-1]
                    emotions = latest_entry.get("analysis", {}).get("emotions", [])
                    emoji = get_emotion_emoji(emotions)
                    color = get_emotion_color(emotions)
                    button_key = f"cal_{year}_{month}_{day}_{week_idx}_{day_idx}"
                    with cols[day_idx]:
                        button_clicked = st.button(
                            f"{emoji}\n{day}",
                            key=button_key,
                            help=f"{', '.join(emotions)} ({len(entries_for_day)}ê°œ ê¸°ë¡)",
                            use_container_width=True
                        )
                        if button_clicked:
                            st.session_state[f"show_day_{year}_{month}_{day}"] = True
                        border_style = "border: 2px solid #667eea;" if is_today else "border: 1px solid #ddd;"
                        background_style = f"background: {color}; opacity: 0.3;"
                        st.markdown(
                            f"""
                            <div style='{background_style} {border_style} 
                                       border-radius: 8px; height: 10px; margin-top: 2px;'>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                else:
                    border_style = "border: 2px solid #667eea;" if is_today else "border: 1px solid #ddd;"
                    cols[day_idx].markdown(
                        f"""
                        <div style='{border_style} border-radius: 8px; padding: 20px; margin: 2px; 
                                   text-align: center; background: #fafafa; color: #999;'>
                            {day}
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
    show_day_details = False
    for day in range(1, 32):
        session_key = f"show_day_{year}_{month}_{day}"
        if st.session_state.get(session_key, False):
            show_day_details = True
            entries_for_day = month_entries.get(day, [])
            if entries_for_day:
                st.markdown(f"### {year}ë…„ {month}ì›” {day}ì¼ ê¸°ë¡")
                for i, entry in enumerate(entries_for_day):
                    emotions_str = ', '.join(entry.get('analysis', {}).get('emotions', []))
                    with st.expander(f"ğŸ“ {entry.get('time', '')} - {emotions_str}", expanded=(i==0)):
                        st.write(entry.get("text", ""))
                        analysis = entry.get("analysis", {})
                        col1, col2, col3 = st.columns(3)
                        col1.metric("ìŠ¤íŠ¸ë ˆìŠ¤", f"{analysis.get('stress_level', 0)}%")
                        col2.metric("ì—ë„ˆì§€", f"{analysis.get('energy_level', 0)}%")
                        col3.metric("ê¸°ë¶„", f"{analysis.get('mood_score', 0)}")
                if st.button("ë‹«ê¸°", key=f"close_{year}_{month}_{day}"):
                    st.session_state[session_key] = False
                    st.rerun()
                break

# =============================
# Goal Management Functions
# =============================
def add_goal(goal_type: str, target_value: float, description: str):
    goal = {
        "id": len(st.session_state.user_goals) + 1,
        "type": goal_type,
        "target": target_value,
        "description": description,
        "created_date": today_key(),
        "active": True
    }
    st.session_state.user_goals.append(goal)

def check_goal_progress(goal: Dict) -> Dict:
    recent_entries = st.session_state.diary_entries[-7:]
    if not recent_entries:
        return {"progress": 0, "current_value": 0, "status": "ì§„í–‰ì¤‘"}
    goal_type = goal["type"]
    target = goal["target"]
    if goal_type == "consistency":
        current_value = len(recent_entries)
        progress = min(100, (current_value / target) * 100)
    else:
        values = []
        for entry in recent_entries:
            analysis = entry.get("analysis", {})
            if goal_type == "stress":
                values.append(analysis.get("stress_level", 0))
            elif goal_type == "energy":
                values.append(analysis.get("energy_level", 0))
            elif goal_type == "mood":
                values.append(analysis.get("mood_score", 0))
        if values:
            current_value = np.mean(values)
            if goal_type == "stress":
                progress = max(0, min(100, (target - current_value) / target * 100)) if current_value <= target else 100
            else:
                progress = min(100, (current_value / target) * 100)
        else:
            current_value = 0
            progress = 0
    status = "ë‹¬ì„±!" if progress >= 100 else "ì§„í–‰ì¤‘"
    return {"progress": progress, "current_value": current_value, "status": status}

def create_goals_page():
    st.header("ğŸ¯ ë‚˜ì˜ ëª©í‘œ ì„¤ì • & ì¶”ì ")
    with st.expander("â• ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€í•˜ê¸°"):
        col1, col2 = st.columns(2)
        with col1:
            goal_type = st.selectbox(
                "ëª©í‘œ ìœ í˜•",
                ["stress", "energy", "mood", "consistency"],
                format_func=lambda x: {
                    "stress": "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ (ë‚®ì¶”ê¸°)",
                    "energy": "ì—ë„ˆì§€ ì¦ì§„ (ë†’ì´ê¸°)", 
                    "mood": "ê¸°ë¶„ ê°œì„  (ë†’ì´ê¸°)",
                    "consistency": "ê¾¸ì¤€í•œ ê¸°ë¡ (ì¼ì£¼ì¼ ê¸°ì¤€)"
                }[x]
            )
        with col2:
            if goal_type == "consistency":
                target_value = st.slider("ì£¼ê°„ ëª©í‘œ ê¸°ë¡ íšŸìˆ˜", 1, 7, 5)
                description = f"ì¼ì£¼ì¼ì— {target_value}ë²ˆ ì´ìƒ ê¸°ë¡í•˜ê¸°"
            elif goal_type == "stress":
                target_value = st.slider("ëª©í‘œ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ (ì´í•˜)", 10, 50, 30)
                description = f"ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ë¥¼ {target_value} ì´í•˜ë¡œ ìœ ì§€í•˜ê¸°"
            elif goal_type == "energy":
                target_value = st.slider("ëª©í‘œ ì—ë„ˆì§€ ì§€ìˆ˜ (ì´ìƒ)", 50, 90, 70)
                description = f"ì—ë„ˆì§€ ì§€ìˆ˜ë¥¼ {target_value} ì´ìƒìœ¼ë¡œ ìœ ì§€í•˜ê¸°"
            else:
                target_value = st.slider("ëª©í‘œ ê¸°ë¶„ ì ìˆ˜ (ì´ìƒ)", 0, 50, 20)
                description = f"ê¸°ë¶„ ì ìˆ˜ë¥¼ {target_value} ì´ìƒìœ¼ë¡œ ìœ ì§€í•˜ê¸°"
        custom_desc = st.text_input("ëª©í‘œ ì„¤ëª… (ì„ íƒì‚¬í•­)", value=description)
        if st.button("ëª©í‘œ ì¶”ê°€"):
            add_goal(goal_type, target_value, custom_desc)
            st.success("ìƒˆë¡œìš´ ëª©í‘œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    active_goals = [g for g in st.session_state.user_goals if g.get("active", True)]
    if not active_goals:
        st.info("ì•„ì§ ì„¤ì •ëœ ëª©í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ìƒˆë¡œìš´ ëª©í‘œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”!")
        return
    st.subheader("ğŸ“Š ëª©í‘œ ì§„í–‰ ìƒí™©")
    for goal in active_goals:
        progress_info = check_goal_progress(goal)
        progress = progress_info["progress"]
        current = progress_info["current_value"]
        status = progress_info["status"]
        with st.container():
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.write(f"**{goal['description']}**")
                st.progress(progress / 100)
                st.caption(f"ì§„í–‰ë¥ : {progress:.1f}% | í˜„ì¬ê°’: {current:.1f}")
            with col2:
                st.success(status) if status == "ë‹¬ì„±!" else st.info(status)
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"delete_goal_{goal['id']}", help="ëª©í‘œ ì‚­ì œ"):
                    goal["active"] = False
                    st.success("ëª©í‘œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

# =============================
# Onboarding Functions
# =============================
def show_onboarding_guide():
    if not st.session_state.onboarding_completed:
        with st.expander("ğŸŒŸ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ í• ì§€ ë§‰ë§‰í•˜ì‹ ê°€ìš”? (ì²˜ìŒ ì‚¬ìš©ì ê°€ì´ë“œ)", expanded=True):
            st.markdown("""
            ### ğŸ’­ ì´ëŸ° ì´ì•¼ê¸°ë“¤ì„ ë‚˜ëˆ ë³´ì„¸ìš”
            **ğŸŒ… í•˜ë£¨ ì‹œì‘/ë§ˆë¬´ë¦¬**
            - "ì˜¤ëŠ˜ í•˜ë£¨ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?"
            - "ì˜¤ëŠ˜ ê°€ì¥ ê°ì‚¬í–ˆë˜ ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            - "ë‚´ì¼ ê°€ì¥ ê¸°ëŒ€ë˜ëŠ” ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            **ğŸ’š ê°ì •ê³¼ ê¸°ë¶„**
            - "ì§€ê¸ˆ ì´ ìˆœê°„ ì–´ë–¤ ê¸°ë¶„ì´ì‹ ê°€ìš”?"
            - "ìš”ì¦˜ ë‚˜ë¥¼ ê°€ì¥ í˜ë“¤ê²Œ í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
            - "ì‚¬ì†Œí•˜ì§€ë§Œ ë‚˜ë¥¼ ì›ƒê²Œ ë§Œë“¤ì—ˆë˜ ì¼ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
            **ğŸ¯ ëª©í‘œì™€ ì„±ì¥**
            - "ì˜¤ëŠ˜ í•œ ì¼ ì¤‘ì—ì„œ ê°€ì¥ ë¿Œë“¯í–ˆë˜ ê²ƒì€?"
            - "ë‚´ê°€ ìµœê·¼ì— ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ëŠ” ë¶€ë¶„ì´ ìˆë‚˜ìš”?"
            - "ì§€ê¸ˆ ê°€ì¥ ì§‘ì¤‘í•˜ê³  ì‹¶ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
            **ğŸ”„ ì¼ìƒê³¼ ë£¨í‹´**
            - "ì˜¤ëŠ˜ì˜ ì»¨ë””ì…˜ì„ 10ì  ë§Œì ì— ëª‡ ì ìœ¼ë¡œ í‰ê°€í•˜ì‹œë‚˜ìš”?"
            - "ìµœê·¼ ì ì€ ì˜ ì£¼ë¬´ì‹œê³  ê³„ì‹ ê°€ìš”?"
            - "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì„ ë•Œ ì–´ë–»ê²Œ í•´ì†Œí•˜ì‹œë‚˜ìš”?"
            """)
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ¯ ë°”ë¡œ ì‹œì‘í•˜ê¸°"):
                    st.session_state.onboarding_completed = True
                    st.rerun()
            with col2:
                if st.button("ğŸ“š ë” ë§ì€ íŒ ë³´ê¸°"):
                    st.session_state.show_more_tips = True
        if st.session_state.get("show_more_tips", False):
            with st.expander("ğŸ“‹ íš¨ê³¼ì ì¸ ê¸°ë¡ì„ ìœ„í•œ íŒ"):
                st.markdown("""
                ### ğŸ™ï¸ ìŒì„± ë…¹ìŒ íŒ
                - **ì¡°ìš©í•œ í™˜ê²½**ì—ì„œ ë…¹ìŒí•˜ì„¸ìš”
                - **ìì—°ìŠ¤ëŸ½ê²Œ** ë§í•´ì£¼ì„¸ìš” (ì—°ê¸°í•  í•„ìš” ì—†ì–´ìš”!)
                - **2-3ë¶„** ì •ë„ê°€ ì ë‹¹í•©ë‹ˆë‹¤
                - **í•¸ë“œí°ì„ ì…ì—ì„œ 20cm** ì •ë„ ë–¨ì–´ëœ¨ë ¤ ì£¼ì„¸ìš”
                ### âœï¸ í…ìŠ¤íŠ¸ ì…ë ¥ íŒ  
                - **ì†”ì§í•œ ê°ì •**ì„ í‘œí˜„í•´ì£¼ì„¸ìš”
                - **êµ¬ì²´ì ì¸ ìƒí™©**ì„ í¬í•¨í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•´ìš”
                - **5-10ë¬¸ì¥** ì •ë„ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤
                - **ì–´ë ¤ìš´ ë‚ ë„** ê¸°ë¡í•´ë³´ì„¸ìš” - íŒ¨í„´ì„ ì°¾ëŠ” ë° ë„ì›€ë©ë‹ˆë‹¤
                """)

# =============================
# Sidebar
# =============================
if not st.session_state.show_disclaimer:
    with st.sidebar:
        st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        librosa = get_librosa()
        parselmouth = get_parselmouth()
        st.markdown(f"- {'âœ…' if openai_client else 'âš ï¸'} OpenAI API")
        st.markdown(f"- {'âœ…' if librosa else 'âš ï¸'} ìŒì„± ë¶„ì„(Librosa)")
        st.markdown(f"- {'âœ…' if parselmouth else 'â„¹ï¸'} ê³ ê¸‰ ìŒì„±í•™(Praat)")
        if not openai_client:
            with st.expander("ğŸ”‘ OpenAI API í‚¤ ì…ë ¥"):
                api_key = st.text_input("OpenAI API í‚¤", type="password")
                if st.button("ì €ì¥"):
                    if api_key.startswith("sk-"):
                        st.session_state.openai_api_key = api_key
                        st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ Rerun ë²„íŠ¼ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error("ì˜¬ë°”ë¥¸ í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.markdown("---")
        page = st.selectbox(
            "í˜ì´ì§€", 
            [
                "ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°", 
                "ğŸ’– ë§ˆìŒ ë¶„ì„", 
                "ğŸ“ˆ ê°ì • ì—¬ì •", 
                "ğŸ“… ê°ì • ìº˜ë¦°ë”",
                "ğŸ¯ ë‚˜ì˜ ëª©í‘œ", 
                "ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ", 
                "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤"
            ]
        )

        # --- RAG KB ê´€ë¦¬ ---
        st.markdown("---")
        st.markdown("### ğŸ“š í–‰ë™ ì¶”ì²œ ì§€ì‹ë² ì´ìŠ¤ (RAG)")

        uploaded = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"], accept_multiple_files=True, help="í–‰ë™ ì¶”ì²œì˜ ê·¼ê±°ë¡œ ì‚¬ìš©í•  ìë£Œ")
        files_to_build: List[Tuple[str, bytes]] = []

        if uploaded:
            for uf in uploaded:
                files_to_build.append((uf.name, uf.read()))
        else:
            # ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ëœ ê¸°ë³¸ PDF ìë™ íƒìƒ‰
            default_paths = find_default_kb_paths()
            if default_paths and not st.session_state.get("kb_auto_loaded", False):
                auto_files = []
                for p in default_paths:
                    try:
                        auto_files.append((p.name, p.read_bytes()))
                    except Exception:
                        pass
                if auto_files:
                    files_to_build = auto_files
                    st.session_state.kb_auto_loaded = True
                    st.caption(f"ê¸°ë³¸ KB íŒŒì¼ ìë™ ê°ì§€: {', '.join(p.name for p in default_paths)}")

        if st.button("ğŸ“¦ ì§€ì‹ë² ì´ìŠ¤ êµ¬ì¶•/ê°±ì‹ "):
            if files_to_build:
                with st.spinner("PDFì—ì„œ ì§€ì‹ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ì¤‘..."):
                    kb = rag_build_from_pdf(files_to_build)
                    st.session_state.kb = kb
                    st.success(f"ì²­í¬ {len(kb['chunks'])}ê°œ ìƒ‰ì¸ ì™„ë£Œ!")
            else:
                st.warning("PDFë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¦¬í¬ì§€í† ë¦¬ì— ê¸°ë³¸ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš” (ì˜ˆ: ì†Œë¦¬ì¼ê¸°/data/...)")

        if st.session_state.get("kb"):
            st.caption(f"KB ì¤€ë¹„ë¨ Â· ì²­í¬ {len(st.session_state.kb['chunks'])}ê°œ")
        else:
            st.caption("KB ë¯¸êµ¬ì¶•")

        # í˜„ì¬ ìƒíƒœ ìš”ì•½
        if st.session_state.diary_entries:
            st.markdown("### ğŸ“Š í˜„ì¬ ìƒíƒœ")
            latest = st.session_state.diary_entries[-1]
            analysis = latest.get("analysis", {})
            st.metric("ê¸°ë¡ ìˆ˜", f"{len(st.session_state.diary_entries)}ê°œ")
            st.metric("ìµœê·¼ ìŠ¤íŠ¸ë ˆìŠ¤", f"{analysis.get('stress_level', 0)}%")
            st.metric("ìµœê·¼ ì—ë„ˆì§€", f"{analysis.get('energy_level', 0)}%")
            if len(st.session_state.diary_entries) >= 7:
                st.markdown("---")
                if st.button("ğŸ“‹ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±"):
                    st.session_state.show_weekly_report = True

        st.markdown("---")
        with st.expander("â„¹ï¸ ì„œë¹„ìŠ¤ ì•ˆë‚´"):
            st.markdown("""
            **ğŸ›¡ï¸ ë°ì´í„° ë³´ì•ˆ**
            - ëª¨ë“  ê¸°ë¡ì€ ì„¸ì…˜ì—ë§Œ ì €ì¥
            - ë¸Œë¼ìš°ì € ì¢…ë£Œ ì‹œ ìë™ ì‚­ì œ
            **âš•ï¸ ì˜ë£Œì  í•œê³„**
            - ìê¸° ì„±ì°° ë³´ì¡° ë„êµ¬
            - ì˜ë£Œ ì§„ë‹¨/ì¹˜ë£Œ ëŒ€ì²´ ë¶ˆê°€
            **ğŸ¤– AI ë¶„ì„**
            - ê°ì • ë¼ë²¨: í…ìŠ¤íŠ¸ ê¸°ë°˜
            - ìŒì„±: ë³´ì¡° ì§€í‘œë¡œë§Œ í™œìš©
            """)

# =============================
# Main Pages
# =============================
if not st.session_state.show_disclaimer:
    extractor = VoiceFeatureExtractor()

    if page == "ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°":
        st.header("ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?")
        show_onboarding_guide()
        audio_val = st.audio_input("ğŸ¤ ë§ˆìŒì„ í¸í•˜ê²Œ ë§í•´ë³´ì„¸ìš”", help="ë…¹ìŒ í›„ ì—…ë¡œë“œ")
        text_input = st.text_area("âœï¸ ê¸€ë¡œ í‘œí˜„í•´ë„ ì¢‹ì•„ìš”", placeholder="ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ë¥¼ ì ì–´ì£¼ì„¸ìš”...", height=120)

        if st.button("ğŸ’ ë¶„ì„í•˜ê³  ì €ì¥", type="primary"):
            diary_text = text_input.strip()
            voice_analysis = None
            audio_b64 = None
            if audio_val is not None:
                audio_bytes = audio_val.read()
                audio_b64 = base64.b64encode(audio_bytes).decode()
                with st.spinner("ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘..."):
                    vf = extractor.extract(audio_bytes)
                    update_baseline(vf)
                    voice_analysis = analyze_voice_as_cues(vf, st.session_state.prosody_baseline)
                if openai_client and not diary_text:
                    with st.spinner("ğŸ¤– ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                        tx = transcribe_audio(audio_bytes)
                        if tx:
                            diary_text = tx
                            st.info(f"ğŸ¤ ë“¤ì€ ì´ì•¼ê¸°: {tx}")
            if not diary_text:
                st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„±ì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")
            else:
                cues_for_prompt = voice_analysis["voice_cues"] if voice_analysis else None
                with st.spinner("ğŸ¤– í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„ ì¤‘..."):
                    t_res = analyze_text_with_llm(diary_text, cues_for_prompt)
                final = combine_text_and_voice(t_res, voice_analysis)
                recent_entries = st.session_state.diary_entries[-7:] if st.session_state.diary_entries else []
                ms_card = generate_llm_coach_report(diary_text, final, recent_entries)
                entry = {
                    "id": len(st.session_state.diary_entries) + 1,
                    "date": today_key(),
                    "time": current_time(),
                    "text": diary_text,
                    "analysis": final,
                    "audio_data": audio_b64,
                    "mental_state": ms_card,
                }
                st.session_state.diary_entries.append(entry)
                st.success("ğŸ‰ ì†Œì¤‘í•œ ì´ì•¼ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("<div class='card'>", unsafe_allow_html=True)
                    st.subheader("ğŸ’– ê°ì • (í…ìŠ¤íŠ¸ ê¸°ë°˜)")
                    emotions_text = ", ".join(final.get("emotions", []))
                    st.write(emotions_text)
                    st.caption("ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.")
                    st.markdown("</div>", unsafe_allow_html=True)
                with col2:
                    st.markdown("<div class='card'>", unsafe_allow_html=True)
                    st.subheader("ğŸ“Š ë§ˆìŒ ìƒíƒœ")
                    stress_color = "metric-negative" if final['stress_level'] > 60 else ("metric-positive" if final['stress_level'] < 30 else "metric-neutral")
                    energy_color = "metric-positive" if final['energy_level'] > 60 else ("metric-negative" if final['energy_level'] < 40 else "metric-neutral")
                    st.markdown(f"**ìŠ¤íŠ¸ë ˆìŠ¤:** <span class='{stress_color}'>{final['stress_level']}%</span>", unsafe_allow_html=True)
                    st.markdown(f"**í™œë ¥:** <span class='{energy_color}'>{final['energy_level']}%</span>", unsafe_allow_html=True)
                    st.markdown("</div>", unsafe_allow_html=True)
                with col3:
                    st.markdown("<div class='card'>", unsafe_allow_html=True)
                    st.subheader("ğŸ¯ ì»¨ë””ì…˜")
                    mood_color = "metric-positive" if final['mood_score'] > 10 else ("metric-negative" if final['mood_score'] < -10 else "metric-neutral")
                    st.markdown(f"**ë§ˆìŒ ì ìˆ˜:** <span class='{mood_color}'>{final['mood_score']}</span>", unsafe_allow_html=True)
                    st.metric("ë¶„ì„ ì‹ ë¢°ë„", f"{final.get('confidence', 0.6):.2f}")
                    st.markdown("</div>", unsafe_allow_html=True)
                if voice_analysis:
                    st.markdown("### ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ (ë³´ì¡° ì§€í‘œ)")
                    cues = final["voice_analysis"]["voice_cues"]
                    quality_text = "ë†’ìŒ" if cues["quality"] > 0.7 else ("ë³´í†µ" if cues["quality"] > 0.4 else "ë‚®ìŒ")
                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100")
                    c2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100")
                    c3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100")
                    c4.metric("ë…¹ìŒ í’ˆì§ˆ", quality_text)
                    st.caption("â€» ëª©ì†Œë¦¬ ì‹ í˜¸ëŠ” ë³´ì¡° ì§€í‘œì…ë‹ˆë‹¤. ê°ì • íŒë‹¨ì€ í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•©ë‹ˆë‹¤.")
                st.markdown("### ğŸ§  ì˜¤ëŠ˜ì˜ ë§ˆìŒ ì½”ì¹˜")
                card_class = "success-card" if ms_card.get("state") == "ì•ˆì •/íšŒë³µ" else ("warning-card" if "ìŠ¤íŠ¸ë ˆìŠ¤" in ms_card.get("state", "") else "card")
                with st.container():
                    st.markdown(f"<div class='{card_class}'>", unsafe_allow_html=True)
                    st.write(f"**ìƒíƒœ:** {ms_card.get('state', 'ì¤‘ë¦½')}")
                    st.write(ms_card.get("summary", "ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”."))
                    if ms_card.get("positives"):
                        st.write("**ğŸŒŸ ì˜¤ëŠ˜ì˜ ë°ì€ í¬ì¸íŠ¸**")
                        for positive in ms_card["positives"]:
                            st.write(f"â€¢ {positive}")
                    st.write("**ğŸ’¡ ì¶”ì²œ í–‰ë™**")
                    for i, rec in enumerate(ms_card.get("recommendations", []), 1):
                        st.write(f"{i}. {rec}")
                    st.info(f"ğŸ’ª {ms_card.get('motivation', 'ì˜¤ëŠ˜ë„ ì˜ í•´ë‚´ì…¨ì–´ìš”.')}")
                    st.markdown("</div>", unsafe_allow_html=True)

    elif page == "ğŸ“… ê°ì • ìº˜ë¦°ë”":
        create_emotion_calendar()

    elif page == "ğŸ¯ ë‚˜ì˜ ëª©í‘œ":
        create_goals_page()

    elif page == "ğŸ’– ë§ˆìŒ ë¶„ì„":
        st.header("ë§ˆìŒ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        if not st.session_state.diary_entries:
            st.info("ê¸°ë¡ì´ ì•„ì§ ì—†ì–´ìš”. ì²« ë²ˆì§¸ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”! ğŸ“")
        else:
            st.subheader("ğŸ“Š ì „ì²´ í†µê³„")
            total_entries = len(st.session_state.diary_entries)
            recent_entries = st.session_state.diary_entries[-30:]
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ê¸°ë¡ ìˆ˜", f"{total_entries}ê°œ")
            with col2:
                avg_stress = np.mean([e["analysis"].get("stress_level", 0) for e in recent_entries])
                st.metric("í‰ê·  ìŠ¤íŠ¸ë ˆìŠ¤", f"{avg_stress:.0f}%")
            with col3:
                avg_energy = np.mean([e["analysis"].get("energy_level", 0) for e in recent_entries])
                st.metric("í‰ê·  ì—ë„ˆì§€", f"{avg_energy:.0f}%")
            with col4:
                avg_mood = np.mean([e["analysis"].get("mood_score", 0) for e in recent_entries])
                st.metric("í‰ê·  ê¸°ë¶„", f"{avg_mood:.0f}")
            st.subheader("ğŸ˜Š ê°ì • ë¶„í¬ (ìµœê·¼ 30ê°œ ê¸°ë¡)")
            emotion_counts = {}
            for entry in recent_entries:
                emotions = entry["analysis"].get("emotions", [])
                for emotion in emotions:
                    emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
            if emotion_counts:
                emotion_df = pd.DataFrame(list(emotion_counts.items()), columns=["ê°ì •", "íšŸìˆ˜"])
                draw_bar_chart_no_rotate(emotion_df, "ê°ì •", "íšŸìˆ˜", title="ê°ì • ë¶„í¬ (ìµœê·¼ 30ê°œ)")
            st.subheader("ğŸ“‹ ìƒì„¸ ê¸°ë¡")
            df = pd.DataFrame([
                {
                    "ë‚ ì§œ": e["date"],
                    "ì‹œê°„": e["time"],
                    "ê°ì •": ", ".join(e["analysis"].get("emotions", [])),
                    "ìŠ¤íŠ¸ë ˆìŠ¤": e["analysis"].get("stress_level", 0),
                    "ì—ë„ˆì§€": e["analysis"].get("energy_level", 0),
                    "ê¸°ë¶„": e["analysis"].get("mood_score", 0),
                    "í†¤": e["analysis"].get("tone", "ì¤‘ë¦½ì "),
                    "ì‹ ë¢°ë„": f"{e['analysis'].get('confidence', 0.6):.2f}"
                }
                for e in st.session_state.diary_entries
            ])
            col1, col2 = st.columns(2)
            with col1:
                date_filter = st.date_input("ë‚ ì§œ í•„í„° (ì´í›„)", value=None)
            with col2:
                emotion_filter = st.selectbox("ê°ì • í•„í„°", ["ì „ì²´"] + list(emotion_counts.keys()))
            filtered_df = df.copy()
            if date_filter:
                filtered_df = filtered_df[pd.to_datetime(filtered_df["ë‚ ì§œ"]) >= pd.to_datetime(date_filter)]
            if emotion_filter != "ì „ì²´":
                filtered_df = filtered_df[filtered_df["ê°ì •"].str.contains(emotion_filter)]
            st.dataframe(
                filtered_df, 
                use_container_width=True, 
                hide_index=True,
                column_config={
                    "ìŠ¤íŠ¸ë ˆìŠ¤": st.column_config.ProgressColumn("ìŠ¤íŠ¸ë ˆìŠ¤", max_value=100),
                    "ì—ë„ˆì§€": st.column_config.ProgressColumn("ì—ë„ˆì§€", max_value=100),
                }
            )

    elif page == "ğŸ“ˆ ê°ì • ì—¬ì •":
        st.header("ì‹œê°„ì— ë”°ë¥¸ ë³€í™”")
        if not st.session_state.diary_entries:
            st.info("ê¸°ë¡ì´ ìŒ“ì´ë©´ ì¶”ì„¸ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”. ê¾¸ì¤€íˆ ê¸°ë¡í•´ë³´ì„¸ìš”! ğŸ“ˆ")
        else:
            col1, col2 = st.columns(2)
            with col1:
                period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì „ì²´", "ìµœê·¼ 30ì¼", "ìµœê·¼ 14ì¼", "ìµœê·¼ 7ì¼"])
            entries = st.session_state.diary_entries
            if period == "ìµœê·¼ 30ì¼":
                entries = entries[-30:]
            elif period == "ìµœê·¼ 14ì¼":
                entries = entries[-14:]
            elif period == "ìµœê·¼ 7ì¼":
                entries = entries[-7:]
            if len(entries) < 2:
                st.warning("ì¶”ì„¸ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ê¸°ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                df = pd.DataFrame([
                    {
                        "ë‚ ì§œì‹œê°„": f"{e['date']} {e['time']}",
                        "ë‚ ì§œ": e['date'],
                        "ìŠ¤íŠ¸ë ˆìŠ¤": e["analysis"].get("stress_level", 0),
                        "ì—ë„ˆì§€": e["analysis"].get("energy_level", 0),
                        "ê¸°ë¶„": e["analysis"].get("mood_score", 0) + 70
                    }
                    for e in entries
                ])
                with col2:
                    metric = st.selectbox("ì§€í‘œ ì„ íƒ", ["ì „ì²´", "ìŠ¤íŠ¸ë ˆìŠ¤", "ì—ë„ˆì§€", "ê¸°ë¶„"])
                df = df.copy()
                df["dt"] = pd.to_datetime(df["ë‚ ì§œì‹œê°„"])
                if metric == "ì „ì²´":
                    draw_line_chart_no_rotate(df[["dt","ìŠ¤íŠ¸ë ˆìŠ¤","ì—ë„ˆì§€","ê¸°ë¶„"]], "dt", ["ìŠ¤íŠ¸ë ˆìŠ¤","ì—ë„ˆì§€","ê¸°ë¶„"], title="ì‹œê°„ì— ë”°ë¥¸ ë³€í™”")
                else:
                    if metric == "ê¸°ë¶„":
                        draw_line_chart_no_rotate(df[["dt","ê¸°ë¶„"]], "dt", ["ê¸°ë¶„"], title="ê¸°ë¶„ ì¶”ì„¸")
                        st.caption("â€» ê¸°ë¶„ ì ìˆ˜ëŠ” ì‹œê°í™”ë¥¼ ìœ„í•´ +70 ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤ (ì‹¤ì œ: -70~70)")
                    else:
                        draw_line_chart_no_rotate(df[["dt", metric]], "dt", [metric], title=f"{metric} ì¶”ì„¸")
                st.subheader("ğŸ“Š ì¶”ì„¸ ë¶„ì„")
                stress_trend = np.polyfit(range(len(entries)), [e["analysis"].get("stress_level", 0) for e in entries], 1)[0]
                energy_trend = np.polyfit(range(len(entries)), [e["analysis"].get("energy_level", 0) for e in entries], 1)[0]
                mood_trend = np.polyfit(range(len(entries)), [e["analysis"].get("mood_score", 0) for e in entries], 1)[0]
                col1, col2, col3 = st.columns(3)
                with col1:
                    trend_icon = "ğŸ“‰" if stress_trend < -0.1 else ("ğŸ“ˆ" if stress_trend > 0.1 else "â¡ï¸")
                    trend_text = "ê°ì†Œ" if stress_trend < -0.1 else ("ì¦ê°€" if stress_trend > 0.1 else "ì•ˆì •")
                    st.metric("ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì„¸", f"{trend_icon} {trend_text}", delta=f"{stress_trend:.2f}")
                with col2:
                    trend_icon = "ğŸ“ˆ" if energy_trend > 0.1 else ("ğŸ“‰" if energy_trend < -0.1 else "â¡ï¸")
                    trend_text = "ì¦ê°€" if energy_trend > 0.1 else ("ê°ì†Œ" if energy_trend < -0.1 else "ì•ˆì •")
                    st.metric("ì—ë„ˆì§€ ì¶”ì„¸", f"{trend_icon} {trend_text}", delta=f"{energy_trend:.2f}")
                with col3:
                    trend_icon = "ğŸ“ˆ" if mood_trend > 0.1 else ("ğŸ“‰" if mood_trend < -0.1 else "â¡ï¸")
                    trend_text = "ê°œì„ " if mood_trend > 0.1 else ("í•˜ë½" if mood_trend < -0.1 else "ì•ˆì •")
                    st.metric("ê¸°ë¶„ ì¶”ì„¸", f"{trend_icon} {trend_text}", delta=f"{mood_trend:.2f}")
                st.subheader("ğŸ” ì¸ì‚¬ì´íŠ¸")
                insights = []
                if stress_trend < -0.5:
                    insights.append("âœ¨ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ê¾¸ì¤€íˆ ê°ì†Œí•˜ê³  ìˆì–´ìš”! í˜„ì¬ ë°©ì‹ì„ ìœ ì§€í•´ë³´ì„¸ìš”.")
                elif stress_trend > 0.5:
                    insights.append("âš ï¸ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤. íœ´ì‹ê³¼ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ê°€ í•„ìš”í•´ ë³´ì—¬ìš”.")
                if energy_trend > 0.5:
                    insights.append("ğŸ”‹ ì—ë„ˆì§€ ë ˆë²¨ì´ ìƒìŠ¹í•˜ê³  ìˆì–´ìš”! ì¢‹ì€ ìŠµê´€ë“¤ì„ ê³„ì† ì´ì–´ê°€ì„¸ìš”.")
                elif energy_trend < -0.5:
                    insights.append("ğŸ˜´ ì—ë„ˆì§€ê°€ ë–¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì¶©ë¶„í•œ íœ´ì‹ê³¼ ìš´ë™ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
                if mood_trend > 0.5:
                    insights.append("ğŸ˜Š ê¸°ë¶„ì´ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì•„ì§€ê³  ìˆì–´ìš”! ê¸ì •ì ì¸ ë³€í™”ë„¤ìš”.")
                elif mood_trend < -0.5:
                    insights.append("ğŸ’™ ê¸°ë¶„ì´ ë‹¤ì†Œ ê°€ë¼ì•‰ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤. ìì‹ ì„ ëŒë³´ëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”.")
                if not insights:
                    insights.append("ğŸ“Š ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆì–´ìš”.")
                for insight in insights:
                    st.info(insight)

    elif page == "ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ":
        st.header("ëª©ì†Œë¦¬ ì‹ í˜¸ ìƒì„¸ ë¶„ì„")
        entries_with_voice = [e for e in st.session_state.diary_entries if e.get("analysis", {}).get("voice_analysis")]
        if not entries_with_voice:
            st.info("ìŒì„±ìœ¼ë¡œ ê¸°ë¡ëœ í•­ëª©ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ì²« ìŒì„± ê¸°ë¡ì„ ë‚¨ê²¨ë³´ì„¸ìš”! ğŸ¤")
        else:
            selected_entry = st.selectbox(
                "ë¶„ì„í•  ê¸°ë¡ ì„ íƒ",
                entries_with_voice,
                format_func=lambda x: f"{x['date']} {x['time']} - {', '.join(x['analysis'].get('emotions', []))}",
                index=len(entries_with_voice) - 1
            )
            voice = selected_entry["analysis"]["voice_analysis"]
            vf = voice["voice_features"]
            cues = voice["voice_cues"]
            st.subheader("ğŸ¯ ìŒì„± ë³´ì¡°ì§€í‘œ")
            quality_text = "ë†’ìŒ" if cues["quality"] > 0.7 else ("ë³´í†µ" if cues["quality"] > 0.4 else "ë‚®ìŒ")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100", help="ìŒì„±ì˜ í™œê¸°ì°¬ ì •ë„")
            c2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100", help="ìŒì„±ì˜ ê¸´ì¥ëœ ì •ë„")
            c3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100", help="ìŒì„±ì˜ ì•ˆì •ëœ ì •ë„")
            c4.metric("ë…¹ìŒ í’ˆì§ˆ", quality_text, help="ë¶„ì„ ì‹ ë¢°ë„ì— ì˜í–¥")
            st.subheader("ğŸ”¬ ê¸°ì´ˆ ìŒì„± íŠ¹ì„±")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ğŸ“Š ê¸°ë³¸ ì¸¡ì •ê°’**")
                d1, d2 = st.columns(2)
                d1.metric("í”¼ì¹˜ í‰ê· ", f"{vf.get('pitch_mean',0):.1f} Hz")
                d2.metric("í”¼ì¹˜ ë³€ë™", f"{vf.get('pitch_variation',0):.3f}")
                d3, d4 = st.columns(2)
                d3.metric("ìŒì„± ì—ë„ˆì§€", f"{vf.get('energy_mean',0):.3f}")
                d4.metric("ìµœëŒ€ ì—ë„ˆì§€", f"{vf.get('energy_max',0):.3f}")
            with col2:
                st.markdown("**ğŸµ ê³ ê¸‰ ì¸¡ì •ê°’**")
                d5, d6 = st.columns(2)
                d5.metric("ë§í•˜ê¸° ì†ë„", f"{vf.get('tempo',0):.0f} BPM")
                d6.metric("ì˜êµì°¨ìœ¨", f"{vf.get('zcr_mean',0):.3f}")
                d7, d8 = st.columns(2)
                d7.metric("HNR (ëª…ë£Œë„)", f"{vf.get('hnr',0):.1f} dB")
                d8.metric("Jitter (ì•ˆì •ì„±)", f"{vf.get('jitter',0):.4f}")
            if st.session_state.prosody_baseline:
                st.subheader("ğŸ“ˆ ê°œì¸ ë² ì´ìŠ¤ë¼ì¸")
                baseline = st.session_state.prosody_baseline
                baseline_count = baseline.get("_count", 0)
                st.info(f"í˜„ì¬ {baseline_count}ê°œ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ ë² ì´ìŠ¤ë¼ì¸ì´ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                if st.button("ë² ì´ìŠ¤ë¼ì¸ ì´ˆê¸°í™”"):
                    st.session_state.prosody_baseline = {}
                    st.success("ë² ì´ìŠ¤ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
            st.caption("â€» ì´ ìˆ˜ì¹˜ë“¤ì€ ê°ì • ë¶„ì„ì„ ìœ„í•œ ë³´ì¡° ì§€í‘œë¡œë§Œ ì‚¬ìš©ë˜ë©°, í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¼ë²¨ì„ ì§ì ‘ ê²°ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    elif page == "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤":
        st.header("ë‚˜ì˜ ì´ì•¼ê¸° ì•„ì¹´ì´ë¸Œ")
        if not st.session_state.diary_entries:
            st.info("ì•„ì§ ê¸°ë¡ëœ ì´ì•¼ê¸°ê°€ ì—†ì–´ìš”. ì²« ë²ˆì§¸ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”! âœ¨")
        else:
            if len(st.session_state.diary_entries) >= 7:
                col1, col2 = st.columns([1, 3])
                with col1:
                    if st.button("ğŸ“‹ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
                        with st.spinner("ğŸ“Š ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            report = generate_weekly_report(st.session_state.diary_entries)
                            st.session_state.weekly_report = report
                            st.session_state.show_weekly_report = True
            if st.session_state.get("show_weekly_report", False) and "weekly_report" in st.session_state:
                report = st.session_state.weekly_report
                st.markdown("### ğŸ“Š ì£¼ê°„ ì›°ë¹™ ë¦¬í¬íŠ¸")
                trend_color = {"ê°œì„ ë¨": "ğŸŸ¢", "ì•ˆì •ì ": "ğŸŸ¡", "ì£¼ì˜í•„ìš”": "ğŸ”´"}
                trend_icon = trend_color.get(report.get("overall_trend", "ì•ˆì •ì "), "ğŸŸ¡")
                st.markdown(f"**ì „ì²´ ì¶”ì„¸:** {trend_icon} {report.get('overall_trend', 'ì•ˆì •ì ')}")
                if report.get("key_insights"):
                    st.markdown("**ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­**")
                    for insight in report["key_insights"]:
                        st.write(f"â€¢ {insight}")
                patterns = report.get("patterns", {})
                if patterns:
                    col1, col2 = st.columns(2)
                    with col1:
                        if patterns.get("best_days"):
                            st.markdown("**ğŸŒŸ ì¢‹ì•˜ë˜ ë‚ ë“¤**")
                            for day in patterns["best_days"]:
                                st.write(f"â€¢ {day}")
                    with col2:
                        if patterns.get("challenging_days"):
                            st.markdown("**ğŸ’ª ë„ì „ì ì´ì—ˆë˜ ë‚ ë“¤**")
                            for day in patterns["challenging_days"]:
                                st.write(f"â€¢ {day}")
                    if patterns.get("emotional_patterns"):
                        st.markdown("**ğŸ“ˆ ê°ì • íŒ¨í„´**")
                        st.write(patterns["emotional_patterns"])
                recommendations = report.get("recommendations", {})
                if recommendations:
                    st.markdown("### ğŸ’¡ ë‹¤ìŒ ì£¼ë¥¼ ìœ„í•œ ì¶”ì²œ")
                    if recommendations.get("priority_actions"):
                        st.markdown("**ğŸ¯ ìš°ì„ ìˆœìœ„ í–‰ë™**")
                        for i, action in enumerate(recommendations["priority_actions"], 1):
                            st.write(f"{i}. {action}")
                    if recommendations.get("wellness_tips"):
                        st.markdown("**ğŸŒ± ì›°ë¹™ íŒ**")
                        for tip in recommendations["wellness_tips"]:
                            st.write(f"â€¢ {tip}")
                    if recommendations.get("goals_for_next_week"):
                        st.markdown("**ğŸ¯ ë‹¤ìŒ ì£¼ ëª©í‘œ**")
                        for goal in recommendations["goals_for_next_week"]:
                            st.write(f"â€¢ {goal}")
                if report.get("encouragement"):
                    st.success(f"ğŸ’ª {report['encouragement']}")
                if st.button("ë¦¬í¬íŠ¸ ë‹«ê¸°"):
                    st.session_state.show_weekly_report = False
                    st.rerun()
                st.markdown("---")
            st.subheader("ğŸ” ê¸°ë¡ íƒìƒ‰")
            col1, col2, col3 = st.columns(3)
            with col1:
                search_text = st.text_input("ğŸ” í…ìŠ¤íŠ¸ ê²€ìƒ‰", placeholder="í‚¤ì›Œë“œë¡œ ê²€ìƒ‰...")
            with col2:
                emotion_options = ["ì „ì²´"] + list(set([
                    emotion for entry in st.session_state.diary_entries 
                    for emotion in entry.get("analysis", {}).get("emotions", [])
                ]))
                emotion_filter = st.selectbox("ğŸ˜Š ê°ì • í•„í„°", emotion_options)
            with col3:
                date_filter = st.date_input("ğŸ“… ë‚ ì§œ ì´í›„", value=None)
            filtered_entries = st.session_state.diary_entries
            if search_text:
                filtered_entries = [e for e in filtered_entries if search_text.lower() in e.get("text", "").lower()]
            if emotion_filter != "ì „ì²´":
                filtered_entries = [e for e in filtered_entries if emotion_filter in e.get("analysis", {}).get("emotions", [])]
            if date_filter:
                filtered_entries = [e for e in filtered_entries if e.get("date", "") >= date_filter.strftime("%Y-%m-%d")]
            st.write(f"**ì´ {len(filtered_entries)}ê°œì˜ ê¸°ë¡** (ì „ì²´ {len(st.session_state.diary_entries)}ê°œ ì¤‘)")
            display_entries = list(reversed(filtered_entries[-20:]))
            for i, entry in enumerate(display_entries):
                analysis = entry.get("analysis", {})
                emotions = analysis.get("emotions", [])
                state = entry.get("mental_state", {}).get("state", "")
                if state == "ì•ˆì •/íšŒë³µ":
                    card_style = "success-card"
                elif any(keyword in state for keyword in ["ìŠ¤íŠ¸ë ˆìŠ¤", "ê¸´ì¥", "ê³¼ë¶€í•˜"]):
                    card_style = "warning-card"
                else:
                    card_style = "card"
                emotion_emoji = get_emotion_emoji(emotions)
                with st.expander(
                    f"{emotion_emoji} {entry['date']} {entry['time']} Â· {', '.join(emotions)} Â· {state}",
                    expanded=(i == 0)
                ):
                    st.markdown(f"<div class='{card_style}'>", unsafe_allow_html=True)
                    st.markdown("**ğŸ“ ê¸°ë¡ ë‚´ìš©**")
                    st.write(entry["text"])
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        stress_color = "ğŸ”´" if analysis.get("stress_level", 0) > 60 else ("ğŸŸ¡" if analysis.get("stress_level", 0) > 30 else "ğŸŸ¢")
                        st.write(f"**ìŠ¤íŠ¸ë ˆìŠ¤:** {stress_color} {analysis.get('stress_level', 0)}%")
                    with col2:
                        energy_color = "ğŸŸ¢" if analysis.get("energy_level", 0) > 60 else ("ğŸŸ¡" if analysis.get("energy_level", 0) > 40 else "ğŸ”´")
                        st.write(f"**ì—ë„ˆì§€:** {energy_color} {analysis.get('energy_level', 0)}%")
                    with col3:
                        mood_score = analysis.get("mood_score", 0)
                        mood_color = "ğŸŸ¢" if mood_score > 10 else ("ğŸŸ¡" if mood_score > -10 else "ğŸ”´")
                        st.write(f"**ê¸°ë¶„:** {mood_color} {mood_score}")
                    mental_state = entry.get("mental_state", {})
                    if mental_state.get("summary"):
                        st.markdown("**ğŸ§  ì½”ì¹˜ ìš”ì•½**")
                        st.info(mental_state["summary"])
                    if analysis.get("voice_analysis"):
                        voice_cues = analysis["voice_analysis"]["voice_cues"]
                        st.markdown("**ğŸµ ìŒì„± ë³´ì¡°ì§€í‘œ**")
                        vc1, vc2, vc3 = st.columns(3)
                        vc1.write(f"ê°ì„±: {int(voice_cues.get('arousal', 0))}")
                        vc2.write(f"ê¸´ì¥: {int(voice_cues.get('tension', 0))}")
                        vc3.write(f"ì•ˆì •: {int(voice_cues.get('stability', 0))}")
                    st.markdown("</div>", unsafe_allow_html=True)

    # =============================
    # Sidebar: Export / Reset / Additional Info
    # =============================
    with st.sidebar:
        if st.session_state.diary_entries:
            st.markdown("---")
            st.markdown("### ğŸ“ ë°ì´í„° ê´€ë¦¬")
            if st.button("ğŸ“Š CSV ë‚´ë³´ë‚´ê¸°"):
                rows: List[Dict] = []
                for e in st.session_state.diary_entries:
                    a = e["analysis"]
                    row = {
                        "ë‚ ì§œ": e["date"],
                        "ì‹œê°„": e["time"],
                        "í…ìŠ¤íŠ¸": e["text"],
                        "ê°ì •": ", ".join(a.get("emotions", [])),
                        "ìŠ¤íŠ¸ë ˆìŠ¤": a.get("stress_level", 0),
                        "ì—ë„ˆì§€": a.get("energy_level", 0),
                        "ê¸°ë¶„": a.get("mood_score", 0),
                        "í†¤": a.get("tone", "ì¤‘ë¦½ì "),
                        "ì‹ ë¢°ë„": a.get("confidence", 0.6)
                    }
                    if e.get("mental_state"):
                        ms = e["mental_state"]
                        row.update({
                            "ìƒíƒœ": ms.get("state", ""),
                            "ì½”ì¹˜ìš”ì•½": ms.get("summary", ""),
                            "ì¶”ì²œì‚¬í•­": " | ".join(ms.get("recommendations", []))
                        })
                    if a.get("voice_analysis"):
                        v = a["voice_analysis"]
                        vc = v["voice_cues"]
                        vf = v["voice_features"]
                        row.update({
                            "ê°ì„±ë„": vc.get("arousal", ""),
                            "ê¸´ì¥ë„": vc.get("tension", ""),
                            "ì•ˆì •ë„": vc.get("stability", ""),
                            "ìŒì§ˆ": vc.get("quality", ""),
                            "í”¼ì¹˜í‰ê· ": vf.get("pitch_mean", ""),
                            "ìŒì„±ì—ë„ˆì§€": vf.get("energy_mean", ""),
                            "ë§ì†ë„": vf.get("tempo", ""),
                            "HNR": vf.get("hnr", "")
                        })
                    rows.append(row)
                df = pd.DataFrame(rows)
                csv = df.to_csv(index=False, encoding="utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                    csv,
                    file_name=f"voice_diary_{get_korean_time().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
            if st.button("ğŸ“‹ JSON ë‚´ë³´ë‚´ê¸°"):
                export_data = {
                    "exported_at": get_korean_time().isoformat(),
                    "total_entries": len(st.session_state.diary_entries),
                    "entries": st.session_state.diary_entries,
                    "goals": st.session_state.user_goals,
                    "baseline": st.session_state.prosody_baseline
                }
                json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
                st.download_button(
                    "ğŸ“¥ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                    json_str,
                    file_name=f"voice_diary_full_{get_korean_time().strftime('%Y%m%d_%H%M')}.json",
                    mime="application/json"
                )
            st.markdown("---")
            if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ë¡ ì‚­ì œ", type="secondary"):
                if st.button("âš ï¸ ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?", type="secondary"):
                    st.session_state.diary_entries = []
                    st.session_state.user_goals = []
                    st.session_state.prosody_baseline = {}
                    st.success("ëª¨ë“  ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
        st.markdown("---")
        st.markdown("### â„¹ï¸ ì•± ì •ë³´")
        st.markdown(f"**ë²„ì „:** v2.0-rag")
        st.markdown(f"**í˜„ì¬ ì‹œê°„:** {current_time()}")
        st.markdown(f"**ì‹œê°„ëŒ€:** í•œêµ­ í‘œì¤€ì‹œ (KST)")
        with st.expander("â“ ë„ì›€ë§"):
            st.markdown("""
            **ğŸ™ï¸ ìŒì„± ë…¹ìŒ íŒ**
            - ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ë…¹ìŒ
            - í•¸ë“œí°ì„ ì…ì—ì„œ 20cm ê±°ë¦¬
            - 2-3ë¶„ ì •ë„ê°€ ì ë‹¹
            **ğŸ“ í…ìŠ¤íŠ¸ ì…ë ¥ íŒ**
            - ì†”ì§í•œ ê°ì • í‘œí˜„
            - êµ¬ì²´ì ì¸ ìƒí™© í¬í•¨
            - 5-10ë¬¸ì¥ ì •ë„ë©´ ì¶©ë¶„
            **ğŸ“Š ë¶„ì„ ì´í•´í•˜ê¸°**
            - ê°ì • ë¼ë²¨: í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒì •
            - ìŒì„± ì§€í‘œ: ë³´ì¡° ì°¸ê³  ìë£Œ
            - ì‹ ë¢°ë„: ë¶„ì„ ì •í™•ë„ ì¶”ì •ì¹˜
            """)

# =============================
# Footer
# =============================
if not st.session_state.show_disclaimer:
    st.markdown("---")
    st.markdown(
        f"""
        <div style='text-align: center; color: #666; font-size: 0.9rem; padding: 1rem;'>
            Made with â¤ï¸ | ê°ì • ë¼ë²¨ì€ <strong>í…ìŠ¤íŠ¸ ìš°ì„ </strong> Â· ëª©ì†Œë¦¬ëŠ” <strong>ë³´ì¡° ì§€í‘œ</strong><br>
            ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {get_korean_time().strftime('%Y-%m-%d %H:%M KST')} | 
            ê¸°ë¡ ìˆ˜: {len(st.session_state.diary_entries)}ê°œ | 
            ëª©í‘œ ìˆ˜: {len([g for g in st.session_state.user_goals if g.get('active', True)])}ê°œ
        </div>
        """,
        unsafe_allow_html=True,
    )

import streamlit as st
import pandas as pd
from datetime import datetime
import json
import os
import base64
import tempfile
import warnings
warnings.filterwarnings("ignore")

# Lightweight stdlib
import numpy as np
from typing import Dict, List, Optional

# =============================
# Page / App Config
# =============================
st.set_page_config(
    page_title="ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ - LLM ì½”ì¹˜ ë²„ì „(ì•ˆì •í™”)",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================
# Lazy Import Helpers (cached)
# =============================
@st.cache_resource(show_spinner=False)
def get_librosa():
    try:
        import librosa  # type: ignore
        return librosa
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_parselmouth():
    try:
        import parselmouth  # type: ignore
        from parselmouth.praat import call  # noqa: F401
        return parselmouth
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def get_openai_client():
    try:
        import openai  # type: ignore
        if "OPENAI_API_KEY" in st.secrets:
            return openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])  # type: ignore
        elif "openai_api_key" in st.session_state and st.session_state.openai_api_key:
            return openai.OpenAI(api_key=st.session_state.openai_api_key)  # type: ignore
        else:
            return None
    except Exception:
        return None

openai_client = get_openai_client()

# =============================
# Session State
# =============================
if "diary_entries" not in st.session_state:
    st.session_state.diary_entries: List[Dict] = []
if "prosody_baseline" not in st.session_state:
    st.session_state.prosody_baseline: Dict[str, float] = {}

# =============================
# Styles (minimal)
# =============================
st.markdown(
    """
    <style>
      .main-header{ text-align:center; padding:1.1rem; background:linear-gradient(90deg,#667eea 0%,#764ba2 100%); color:#fff; border-radius:12px; margin-bottom:12px; }
      .card{ background:#fff; border:1px solid #eee; border-left:4px solid #667eea; border-radius:12px; padding:1rem; box-shadow:0 2px 8px rgba(0,0,0,0.04); }
      .note{ color:#666; font-size:0.85rem; }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    """
    <div class="main-header">
      <h1>ğŸ™ï¸ ì†Œë¦¬ë¡œ ì“°ëŠ” í•˜ë£¨ â€“ LLM ì½”ì¹˜(ì•ˆì •í™”)</h1>
      <p>ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ê°€ ê²°ì •í•˜ê³ , ëª©ì†Œë¦¬ëŠ” ê°ì„±/ê¸´ì¥/ì•ˆì •ì˜ <b>ë³´ì¡°ì§€í‘œ</b>ë¡œë§Œ ë°˜ì˜í•©ë‹ˆë‹¤.</p>
    </div>
    """,
    unsafe_allow_html=True,
)

# =============================
# Feature Extraction
# =============================
class VoiceFeatureExtractor:
    """Prosody feature extractor with graceful fallbacks."""

    def __init__(self, target_sr: int = 22050):
        self.sample_rate = target_sr

    def _load_audio(self, audio_bytes: bytes):
        librosa = get_librosa()
        if not librosa:
            return None, None
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp.write(audio_bytes)
                tmp_path = tmp.name
            y, sr = librosa.load(tmp_path, sr=self.sample_rate, mono=True, res_type="kaiser_fast")
            return y, sr
        except Exception:
            return None, None
        finally:
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except Exception:
                    pass

    def extract(self, audio_bytes: bytes) -> Dict:
        librosa = get_librosa()
        if not librosa:
            return self._default_features()
        try:
            y, sr = self._load_audio(audio_bytes)
            if y is None or y.size == 0 or sr is None:
                return self._default_features()

            duration_sec = max(0.001, float(len(y) / sr))
            # RMS energy
            rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]
            energy_mean = float(np.mean(rms))
            energy_max = float(np.max(rms))
            # Tempo (guard for short audio)
            if duration_sec >= 2.5:
                tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            else:
                tempo = 110.0
            # ZCR
            zcr = librosa.feature.zero_crossing_rate(y, frame_length=1024, hop_length=256)[0]
            zcr_mean = float(np.mean(zcr))
            # Spectral centroid
            sc = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_centroid_mean = float(np.mean(sc))
            # Pitch proxy
            pitch_mean = 150.0
            pitch_var = 0.13
            try:
                if duration_sec >= 1.0:
                    pitches, mags = librosa.piptrack(y=y, sr=sr, fmin=50, fmax=400)
                    valid = []
                    for t in range(pitches.shape[1]):
                        idx = int(np.argmax(mags[:, t]))
                        p = float(pitches[idx, t])
                        if p > 0:
                            valid.append(p)
                    if valid:
                        va = np.array(valid, dtype=float)
                        pitch_mean = float(np.mean(va))
                        pitch_var = float(np.std(va) / (np.mean(va) + 1e-6))
            except Exception:
                pass

            # HNR / Jitter via parselmouth (optional)
            hnr = 15.0
            jitter = 0.012
            parselmouth = get_parselmouth()
            if parselmouth:
                tmp2 = None
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t2:
                        t2.write(audio_bytes)
                        tmp2 = t2.name
                    snd = parselmouth.Sound(tmp2)
                    harm = snd.to_harmonicity_cc()
                    hnr = float(np.nan_to_num(harm.values.mean(), nan=15.0))
                    pp = parselmouth.praat.call(snd, "To PointProcess (periodic, cc)", 75, 500)
                    jitter = float(parselmouth.praat.call(pp, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3))
                except Exception:
                    pass
                finally:
                    if tmp2 and os.path.exists(tmp2):
                        try:
                            os.unlink(tmp2)
                        except Exception:
                            pass

            return {
                "duration_sec": duration_sec,
                "pitch_mean": pitch_mean,
                "pitch_variation": pitch_var,
                "energy_mean": energy_mean,
                "energy_max": energy_max,
                "tempo": float(tempo),
                "zcr_mean": zcr_mean,
                "spectral_centroid_mean": spectral_centroid_mean,
                "hnr": hnr,
                "jitter": jitter,
            }
        except Exception:
            return self._default_features()

    def _default_features(self) -> Dict:
        return {
            "duration_sec": 0.0,
            "pitch_mean": 150.0,
            "pitch_variation": 0.13,
            "energy_mean": 0.08,
            "energy_max": 0.12,
            "tempo": 110.0,
            "zcr_mean": 0.10,
            "spectral_centroid_mean": 2000.0,
            "hnr": 15.0,
            "jitter": 0.012,
        }

# =============================
# Voice Cues (Arousal/Tension/Stability/Quality)
# =============================

def prosody_to_dimensions(f: Dict, baseline: Optional[Dict] = None) -> Dict:
    def norm(key: str, val: float) -> float:
        if not baseline or key not in baseline:
            return val
        b = float(baseline.get(key, 0.0))
        return (val / b) if b else val

    tempo = norm("tempo", float(f.get("tempo", 110.0)))
    energy = norm("energy_mean", float(f.get("energy_mean", 0.08)))
    hnr = norm("hnr", float(f.get("hnr", 15.0)))
    jitter = float(f.get("jitter", 0.012))
    zcr = float(f.get("zcr_mean", 0.10))
    sc = norm("spectral_centroid_mean", float(f.get("spectral_centroid_mean", 2000.0)))

    arousal = float(np.clip(35 + 120 * energy + 0.06 * (tempo - 110) + 0.004 * (sc - 2000), 0, 100))
    tension = float(np.clip(28 + 120 * jitter + 0.55 * (zcr - 0.10) * 100, 0, 100))
    stability = float(np.clip(60 + 1.3 * (hnr - 15) - 85 * jitter, 0, 100))

    duration = float(f.get("duration_sec", 4.0))
    quality = float(np.clip(
        0.28 * (duration / 8.0) + 0.42 * np.clip((hnr - 10) / 15, 0, 1) + 0.30 * np.clip((energy - 0.06) / 0.20, 0, 1),
        0, 1
    ))

    return {"arousal": arousal, "tension": tension, "stability": stability, "quality": quality}


def analyze_voice_as_cues(voice_features: Dict, baseline: Optional[Dict] = None) -> Dict:
    dims = prosody_to_dimensions(voice_features, baseline)
    return {"voice_cues": dims, "voice_features": voice_features}

# =============================
# Text Analysis (LLM or fallback)
# =============================

def analyze_text_with_llm(text: str, voice_cues_for_prompt: Optional[Dict] = None) -> Dict:
    if not openai_client:
        return analyze_text_simulation(text)
    cues_text = ""
    if voice_cues_for_prompt:
        cues = voice_cues_for_prompt
        cues_text = (
            f"\n(ë³´ì¡°ì§€í‘œ) ê°ì„±:{int(cues.get('arousal',0))}, ê¸´ì¥:{int(cues.get('tension',0))}, ì•ˆì •:{int(cues.get('stability',0))}, í’ˆì§ˆ:{cues.get('quality',0):.2f}"
        )
    try:
        sys = (
            "ê°ì • ë¼ë²¨(ê¸°ì¨/ìŠ¬í””/ë¶„ë…¸/ë¶ˆì•ˆ/í‰ì˜¨/ì¤‘ë¦½)ì€ í…ìŠ¤íŠ¸ë¡œë§Œ íŒë‹¨í•˜ì„¸ìš”. "
            "ìŒì„± ì§€í‘œëŠ” ìˆ˜ì¹˜ ë³´ì¡°ë¡œë§Œ ì°¸ê³ í•˜ê³  ë¼ë²¨ì„ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”. JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."
        )
        schema = (
            "{\n  \"emotions\": [..ìµœëŒ€3ê°œ..],\n  \"stress_level\": 0-100,\n  \"energy_level\": 0-100,\n  \"mood_score\": -70~70,\n  \"summary\": \"í•œë‘ ë¬¸ì¥\",\n  \"keywords\": [..],\n  \"tone\": \"ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì \",\n  \"confidence\": 0.0-1.0\n}"
        )
        resp = openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.3,
            max_tokens=800,
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": f"ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°: {text}{cues_text}"},
                {"role": "system", "content": schema},
            ],
        )
        content = resp.choices[0].message.content.strip()
        if "```" in content:
            parts = content.split("```")
            data = None
            for part in parts:
                try:
                    data = json.loads(part)
                    break
                except Exception:
                    continue
            if data is None:
                data = json.loads(parts[-1])
        else:
            data = json.loads(content)
        data.setdefault("emotions", ["ì¤‘ë¦½"])  
        data.setdefault("stress_level", 30)
        data.setdefault("energy_level", 50)
        data.setdefault("mood_score", 0)
        data.setdefault("summary", "ì¼ë°˜ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.")
        data.setdefault("keywords", [])
        data.setdefault("tone", "ì¤‘ë¦½ì ")
        data.setdefault("confidence", 0.7)
        return data
    except Exception:
        return analyze_text_simulation(text)


def analyze_text_simulation(text: str) -> Dict:
    t = text.lower()
    pos_kw = ["ì¢‹", "í–‰ë³µ", "ë¿Œë“¯", "ê¸°ì¨", "ì¦ê²", "í‰ì˜¨", "ë§Œì¡±"]
    neg_kw = ["í˜ë“¤", "ë¶ˆì•ˆ", "ê±±ì •", "ì§œì¦", "í™”", "ìš°ìš¸", "ìŠ¬í””"]
    pos = sum(k in t for k in pos_kw)
    neg = sum(k in t for k in neg_kw)
    if pos > neg:
        tone = "ê¸ì •ì "; stress = max(10, 40 - 8 * pos); energy = min(85, 50 + 10 * pos)
    elif neg > pos:
        tone = "ë¶€ì •ì "; stress = min(85, 40 + 10 * neg); energy = max(20, 55 - 8 * neg)
    else:
        tone = "ì¤‘ë¦½ì "; stress = 30; energy = 50
    mood = int(np.clip(energy - stress, -70, 70))
    emos = ["ê¸°ì¨"] if tone == "ê¸ì •ì " else (["ìŠ¬í””"] if tone == "ë¶€ì •ì " else ["ì¤‘ë¦½"])
    return {
        "emotions": emos,
        "stress_level": int(stress),
        "energy_level": int(energy),
        "mood_score": int(mood),
        "summary": f"{tone} ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.",
        "keywords": [],
        "tone": tone,
        "confidence": 0.55,
    }

# =============================
# Fusion: Text (anchor) + Voice Cues (aux)
# =============================

def combine_text_and_voice(text_analysis: Dict, voice_analysis: Optional[Dict]) -> Dict:
    if not voice_analysis or "voice_cues" not in voice_analysis:
        return text_analysis
    cues = voice_analysis["voice_cues"]
    quality = float(cues.get("quality", 0.5))
    base_alpha = 0.25 * quality
    tone = text_analysis.get("tone", "ì¤‘ë¦½ì ")
    if tone == "ê¸ì •ì ":
        base_alpha *= 0.6
    elif tone == "ë¶€ì •ì ":
        base_alpha *= 0.9
    MAX_DS, MAX_DE, MAX_DM = 12, 12, 10
    stress = text_analysis.get("stress_level", 30)
    energy = text_analysis.get("energy_level", 50)
    mood = text_analysis.get("mood_score", 0)
    delta_energy = base_alpha * ((cues["arousal"] - 50) / 50.0) * 12
    delta_stress = base_alpha * (((cues["tension"] - 50) / 50.0) * 12 - ((cues["stability"] - 50) / 50.0) * 6)
    delta_mood = base_alpha * ((cues["stability"] - 50) / 50.0) * 8 - base_alpha * ((cues["tension"] - 50) / 50.0) * 6
    delta_stress = float(np.clip(delta_stress, -MAX_DS, MAX_DS))
    delta_energy = float(np.clip(delta_energy, -MAX_DE, MAX_DE))
    delta_mood = float(np.clip(delta_mood, -MAX_DM, MAX_DM))
    combined = dict(text_analysis)
    combined["stress_level"] = int(np.clip(stress + delta_stress, 0, 100))
    combined["energy_level"] = int(np.clip(energy + delta_energy, 0, 100))
    combined["mood_score"] = int(np.clip(mood + delta_mood, -70, 70))
    combined["confidence"] = float(np.clip(text_analysis.get("confidence", 0.7) + 0.12 * quality, 0, 1))
    combined["voice_analysis"] = voice_analysis
    return combined

# =============================
# Whisper Transcription (optional)
# =============================

def transcribe_audio(audio_bytes: bytes) -> Optional[str]:
    if not openai_client:
        return None
    try:
        tmp = None
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as t:
            t.write(audio_bytes)
            tmp = t.name
        with open(tmp, "rb") as fh:
            out = openai_client.audio.transcriptions.create(model="whisper-1", file=fh, language="ko")
        if tmp and os.path.exists(tmp):
            try:
                os.unlink(tmp)
            except Exception:
                pass
        return out.text
    except Exception:
        return None

# =============================
# Baseline Update
# =============================

def update_baseline(vf: Dict):
    keys = ["pitch_mean", "tempo", "energy_mean", "hnr", "spectral_centroid_mean"]
    b = st.session_state.prosody_baseline
    count = int(b.get("_count", 0))
    new_count = min(20, count + 1)
    alpha = 1.0 / new_count
    for k in keys:
        v = float(vf.get(k, 0.0))
        prev = float(b.get(k, v))
        b[k] = (1 - alpha) * prev + alpha * v
    b["_count"] = new_count

# =============================
# Simple Rules Coaching (fallback)
# =============================

def extract_positive_events(text: str) -> List[str]:
    t = text.lower()
    keys = [("ì¢‹ì•˜", "ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ ì "), ("í–‰ë³µ", "í–‰ë³µí•œ ìˆœê°„"), ("ê³ ë§ˆ", "ê°ì‚¬í•œ ì¼"), ("ì¦ê²", "ì¦ê±°ì› ë˜ í™œë™"), ("í‰ì˜¨", "í‰ì˜¨í–ˆë˜ ìˆœê°„"), ("ì„±ê³µ", "ì„±ì·¨"), ("ë¿Œë“¯", "ë¿Œë“¯í–ˆë˜ ì¼")]
    tags: List[str] = []
    for k, v in keys:
        if k in t:
            tags.append(v)
    return list(dict.fromkeys(tags))[:4]


def assess_mental_state(text: str, combined: Dict) -> Dict:
    tone = combined.get("tone", "ì¤‘ë¦½ì ")
    stress = combined.get("stress_level", 30)
    energy = combined.get("energy_level", 50)
    mood = combined.get("mood_score", 0)
    cues = combined.get("voice_analysis", {}).get("voice_cues", {})
    arousal = float(cues.get("arousal", 50))
    tension = float(cues.get("tension", 50))
    stability = float(cues.get("stability", 50))
    quality = float(cues.get("quality", 0.5))
    positives = extract_positive_events(text)
    state = "ì¤‘ë¦½"
    if tone == "ê¸ì •ì " and mood >= 15 and stress < 40:
        state = "ì•ˆì •/íšŒë³µ"
    if energy < 40 and mood < 0:
        state = "ì €í™œë ¥"
    if stress >= 60:
        state = "ê³ ìŠ¤íŠ¸ë ˆìŠ¤"
    if quality > 0.4:
        if tension > 65 and stability < 45:
            state = "ê¸´ì¥ ê³¼ë‹¤"
        elif arousal > 70 and stress > 45:
            state = "ê³¼í¥ë¶„/ê³¼ë¶€í•˜ ê°€ëŠ¥"
        elif arousal < 40 and energy < 45:
            state = "ì €ê°ì„±"
    recs: List[str] = []
    if tone == "ê¸ì •ì " or positives:
        if positives:
            recs.append("ì˜¤ëŠ˜ ì¢‹ì•˜ë˜ í¬ì¸íŠ¸ë¥¼ 3ì¤„ë¡œ ê¸°ë¡í•´ ë³´ì„¸ìš” (ê°ì‚¬/ì„±ì·¨/ì¦ê±°ì›€).")
        recs.append("ì¢‹ì•˜ë˜ í™œë™ì„ ë‚´ì¼ 10ë¶„ë§Œ ë” í•´ë³´ê¸°.")
    if tension > 60:
        recs.append("4-7-8 í˜¸í¡ 3íšŒ: 4ì´ˆ ë“¤ì´ë§ˆì‹œê³ , 7ì´ˆ ë©ˆì¶”ê³ , 8ì´ˆ ë‚´ì‰¬ê¸°.")
    if stability < 50:
        recs.append("ëª©/ì–´ê¹¨ ì´ì™„ ìŠ¤íŠ¸ë ˆì¹­ 2ë¶„ (ìƒì²´ íšŒì „, ëª© ì˜†ì„  ëŠ˜ë¦¬ê¸°).")
    if arousal < 45 or energy < 45:
        recs.append("í–‡ë¹› 10ë¶„ ì‚°ì±… + ê°€ë²¼ìš´ ì›Œí‚¹ (Step 800~1000).")
    if arousal > 65 and stress > 50:
        recs.append("ì•Œë¦¼/ìê·¹ ì¤„ì´ê¸°: 25ë¶„ ì§‘ì¤‘ + 5ë¶„ íœ´ì‹(í¬ëª¨ë„ë¡œ 2íšŒ).")
    recs = recs[:4]
    mot = "ì‘ì€ ìŠµê´€ì´ ì˜¤ëŠ˜ì˜ ì¢‹ì€ íë¦„ì„ ë‚´ì¼ë¡œ ì´ì–´ì¤ë‹ˆë‹¤."
    if state in ("ê³ ìŠ¤íŠ¸ë ˆìŠ¤", "ê¸´ì¥ ê³¼ë‹¤"):
        mot = "í˜¸í¡ì„ ê³ ë¥´ê³ , ì²œì²œíˆ. ë‹¹ì‹ ì˜ ì†ë„ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
    elif state in ("ì €í™œë ¥", "ì €ê°ì„±"):
        mot = "ì‘ì€ í•œ ê±¸ìŒì´ ì—ë„ˆì§€ë¥¼ ê¹¨ì›ë‹ˆë‹¤. 10ë¶„ë§Œ ì›€ì§ì—¬ë³¼ê¹Œìš”?"
    summary = f"ìƒíƒœ: {state} Â· ìŠ¤íŠ¸ë ˆìŠ¤ {stress} Â· ì—ë„ˆì§€ {energy} Â· ê°ì„± {int(arousal)} / ê¸´ì¥ {int(tension)} / ì•ˆì • {int(stability)}"
    return {"state": state, "summary": summary, "positives": positives, "recommendations": recs, "motivation": mot, "voice_cues": {"arousal": arousal, "tension": tension, "stability": stability, "quality": quality}}

# =============================
# LLM Coach Report (primary)
# =============================

def generate_llm_coach_report(text: str, combined: Dict, recent: Optional[List[Dict]] = None) -> Dict:
    """Use LLM to produce a rich, structured coaching card. Falls back to rules if needed."""
    if not openai_client:
        return assess_mental_state(text, combined)
    cues = combined.get("voice_analysis", {}).get("voice_cues", {})
    try:
        history_blob: List[Dict] = []
        if recent:
            for e in recent[-5:]:
                a = e.get("analysis", {})
                history_blob.append({"date": e.get("date"), "tone": a.get("tone"), "stress": a.get("stress_level"), "energy": a.get("energy_level"), "mood": a.get("mood_score")})
        sys_msg = """
ë‹¹ì‹ ì€ ë”°ëœ»í•œ í•œêµ­ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ëŠ” ê°ì • ë¼ë²¨ì˜ ê¸°ì¤€ì´ë©°, ìŒì„±ì€ ê°ì„±/ê¸´ì¥/ì•ˆì •ì˜ ë³´ì¡°ì§€í‘œë¡œë§Œ ê³ ë ¤í•˜ì„¸ìš”.
ì•„ë˜ ì •ë³´ë¥¼ ì¢…í•©í•´ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. ë¼ë²¨(ê¸°ì¨/ìŠ¬í””/ë¶„ë…¸/ë¶ˆì•ˆ/í‰ì˜¨/ì¤‘ë¦½)ì€ ë°”ê¾¸ì§€ ë§ê³ ,
ìƒíƒœ ìš”ì•½ê³¼ 2~4ê°œì˜ êµ¬ì²´ ì¶”ì²œ, ë™ê¸°ë¶€ì—¬ í•œ ì¤„ì„ ìƒì„±í•˜ì„¸ìš”. ìµœê·¼ ê¸°ë¡ì´ ìˆìœ¼ë©´ ì§§ê²Œ ë°˜ì˜í•˜ì„¸ìš”.
"""
        user_payload = {
            "text": text,
            "text_analysis": {
                "emotions": combined.get("emotions", []),
                "stress": combined.get("stress_level", 30),
                "energy": combined.get("energy_level", 50),
                "mood": combined.get("mood_score", 0),
                "tone": combined.get("tone", "ì¤‘ë¦½ì "),
            },
            "voice_cues": {
                "arousal": int(cues.get("arousal", 50)),
                "tension": int(cues.get("tension", 50)),
                "stability": int(cues.get("stability", 50)),
                "quality": float(cues.get("quality", 0.5)),
            },
            "recent_summary": history_blob,
        }
        schema_hint = """
ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ë‹µ:
{
  "state": "ì•ˆì •/íšŒë³µ|ê³ ìŠ¤íŠ¸ë ˆìŠ¤|ê¸´ì¥ ê³¼ë‹¤|ê³¼í¥ë¶„/ê³¼ë¶€í•˜ ê°€ëŠ¥|ì €í™œë ¥|ì €ê°ì„±|ì¤‘ë¦½",
  "summary": "í•œë‘ ë¬¸ì¥ ìš”ì•½",
  "positives": ["..."],
  "recommendations": ["ê°„ê²°í•œ ì‹¤í–‰ ë¬¸ì¥"],
  "motivation": "ì§§ì€ ê²©ë ¤ ë¬¸ì¥"
}
"""
        resp = openai_client.chat.completions.create(
            model="gpt-4o",
            temperature=0.4,
            max_tokens=700,
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
                {"role": "system", "content": schema_hint},
            ],
        )
        content = resp.choices[0].message.content.strip()
        if "```" in content:
            parts = content.split("```")
            data = None
            for part in parts:
                try:
                    data = json.loads(part)
                    break
                except Exception:
                    continue
            if data is None:
                data = json.loads(parts[-1])
        else:
            data = json.loads(content)
        data.setdefault("state", "ì¤‘ë¦½")
        data.setdefault("summary", "ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”.")
        data.setdefault("positives", [])
        data.setdefault("recommendations", [])
        data.setdefault("motivation", "ì‘ì€ ê±¸ìŒì´ í° ë³€í™”ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
        data["recommendations"] = data.get("recommendations", [])[:4]
        data["positives"] = data.get("positives", [])[:4]
        return data
    except Exception:
        return assess_mental_state(text, combined)

# =============================
# UI Helpers
# =============================

def today_key() -> str:
    return datetime.now().strftime("%Y-%m-%d")

# =============================
# Sidebar (status + nav)
# =============================
with st.sidebar:
    st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    librosa = get_librosa()
    parselmouth = get_parselmouth()
    st.markdown(f"- {'âœ…' if openai_client else 'âš ï¸'} OpenAI API")
    st.markdown(f"- {'âœ…' if librosa else 'âš ï¸'} ìŒì„± ë¶„ì„(Librosa)")
    st.markdown(f"- {'âœ…' if parselmouth else 'â„¹ï¸'} ê³ ê¸‰ ìŒì„±í•™(Praat)")
    if not openai_client:
        with st.expander("ğŸ”‘ OpenAI API í‚¤ ì…ë ¥"):
            api_key = st.text_input("OpenAI API í‚¤", type="password")
            if st.button("ì €ì¥"):
                if api_key.startswith("sk-"):
                    st.session_state.openai_api_key = api_key
                    st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ Rerun ë²„íŠ¼ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
                else:
                    st.error("ì˜¬ë°”ë¥¸ í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    st.markdown("---")
    page = st.selectbox("í˜ì´ì§€", ["ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°", "ğŸ’– ë§ˆìŒ ë¶„ì„", "ğŸ“ˆ ê°ì • ì—¬ì •", "ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ", "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤"])

# =============================
# Main Pages
# =============================
extractor = VoiceFeatureExtractor()

if page == "ğŸ™ï¸ ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°":
    st.header("ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?")
    audio_val = st.audio_input("ğŸ¤ ë§ˆìŒì„ í¸í•˜ê²Œ ë§í•´ë³´ì„¸ìš”", help="ë…¹ìŒ í›„ ì—…ë¡œë“œ")
    text_input = st.text_area("âœï¸ ê¸€ë¡œ í‘œí˜„í•´ë„ ì¢‹ì•„ìš”", placeholder="ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ë¥¼ ì ì–´ì£¼ì„¸ìš”...", height=120)

    if st.button("ğŸ’ ë¶„ì„í•˜ê³  ì €ì¥", type="primary"):
        diary_text = text_input.strip()
        voice_analysis = None
        audio_b64 = None
        if audio_val is not None:
            audio_bytes = audio_val.read()
            audio_b64 = base64.b64encode(audio_bytes).decode()
            with st.spinner("ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘..."):
                vf = extractor.extract(audio_bytes)
                update_baseline(vf)
                voice_analysis = analyze_voice_as_cues(vf, st.session_state.prosody_baseline)
            if openai_client and not diary_text:
                with st.spinner("ğŸ¤– ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                    tx = transcribe_audio(audio_bytes)
                    if tx:
                        diary_text = tx
                        st.info(f"ë“¤ì€ ì´ì•¼ê¸°: {tx}")
        if not diary_text:
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„±ì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")
        else:
            cues_for_prompt = voice_analysis["voice_cues"] if voice_analysis else None
            with st.spinner("ğŸ¤– í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„ ì¤‘..."):
                t_res = analyze_text_with_llm(diary_text, cues_for_prompt)
            final = combine_text_and_voice(t_res, voice_analysis)
            recent_entries = st.session_state.diary_entries[-7:] if st.session_state.diary_entries else []
            ms_card = generate_llm_coach_report(diary_text, final, recent_entries)
            entry = {
                "id": len(st.session_state.diary_entries) + 1,
                "date": today_key(),
                "time": datetime.now().strftime("%H:%M"),
                "text": diary_text,
                "analysis": final,
                "audio_data": audio_b64,
                "mental_state": ms_card,
            }
            st.session_state.diary_entries.append(entry)
            st.success("ğŸ‰ ì†Œì¤‘í•œ ì´ì•¼ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("<div class='card'>", unsafe_allow_html=True)
                st.subheader("ğŸ’– ê°ì • (í…ìŠ¤íŠ¸ ê¸°ë°˜)")
                st.write(", ".join(final.get("emotions", [])))
                st.caption("ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.")
                st.markdown("</div>", unsafe_allow_html=True)
            with col2:
                st.markdown("<div class='card'>", unsafe_allow_html=True)
                st.subheader("ğŸ“Š ë§ˆìŒ ìƒíƒœ")
                st.metric("ìŠ¤íŠ¸ë ˆìŠ¤", f"{final['stress_level']}%")
                st.metric("í™œë ¥", f"{final['energy_level']}%")
                st.markdown("</div>", unsafe_allow_html=True)
            with col3:
                st.markdown("<div class='card'>", unsafe_allow_html=True)
                st.subheader("ğŸ¯ ì»¨ë””ì…˜")
                st.metric("ë§ˆìŒ ì ìˆ˜", f"{final['mood_score']}")
                st.metric("ë¶„ì„ ì‹ ë¢°ë„", f"{final.get('confidence', 0.6):.2f}")
                st.markdown("</div>", unsafe_allow_html=True)
            if voice_analysis:
                st.markdown("### ğŸµ ëª©ì†Œë¦¬ ì‹ í˜¸ (ë³´ì¡° ì§€í‘œ)")
                cues = final["voice_analysis"]["voice_cues"]
                qtxt = "ë†’ìŒ" if cues["quality"] > 0.7 else ("ë³´í†µ" if cues["quality"] > 0.4 else "ë‚®ìŒ")
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100")
                c2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100")
                c3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100")
                c4.metric("ë…¹ìŒ í’ˆì§ˆ", qtxt)
                st.caption("â€» ëª©ì†Œë¦¬ ì‹ í˜¸ëŠ” ë³´ì¡° ì§€í‘œì…ë‹ˆë‹¤. ê°ì • íŒë‹¨ì€ í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•©ë‹ˆë‹¤.")
            st.markdown("### ğŸ§  ì˜¤ëŠ˜ì˜ ë§ˆìŒ ì½”ì¹˜")
            with st.container():
                st.markdown("<div class='card'>", unsafe_allow_html=True)
                st.write(ms_card.get("summary", "ì˜¤ëŠ˜ì˜ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì •ë¦¬í–ˆì–´ìš”."))
                if ms_card.get("positives"):
                    st.write("**ì˜¤ëŠ˜ì˜ ë°ì€ í¬ì¸íŠ¸**: " + ", ".join(ms_card["positives"]))
                st.write("**ì¶”ì²œ**")
                for r in ms_card.get("recommendations", []):
                    st.write(f"- {r}")
                st.info(ms_card.get("motivation", "ì˜¤ëŠ˜ë„ ì˜ í•´ë‚´ì…¨ì–´ìš”."))
                st.markdown("</div>", unsafe_allow_html=True)

elif page == "ğŸµ ëª©ì†Œë¦¬ ë³´ì¡°ì§€í‘œ":
    st.header("ìµœê·¼ ë…¹ìŒì˜ ë³´ì¡°ì§€í‘œ ìƒì„¸")
    entries = [e for e in st.session_state.diary_entries if e.get("analysis", {}).get("voice_analysis")]
    if not entries:
        st.info("ìŒì„±ìœ¼ë¡œ ê¸°ë¡ëœ í•­ëª©ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    else:
        latest = entries[-1]
        voice = latest["analysis"]["voice_analysis"]
        vf = voice["voice_features"]
        cues = voice["voice_cues"]
        qtxt = "ë†’ìŒ" if cues["quality"] > 0.7 else ("ë³´í†µ" if cues["quality"] > 0.4 else "ë‚®ìŒ")
        st.subheader("ë³´ì¡°ì§€í‘œ")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ê°ì„±ë„", f"{int(cues['arousal'])}/100")
        c2.metric("ê¸´ì¥ë„", f"{int(cues['tension'])}/100")
        c3.metric("ì•ˆì •ë„", f"{int(cues['stability'])}/100")
        c4.metric("ë…¹ìŒ í’ˆì§ˆ", qtxt)
        st.subheader("ê¸°ì´ˆ ìŒì„± íŠ¹ì„±")
        d1, d2, d3, d4 = st.columns(4)
        d1.metric("í”¼ì¹˜ í‰ê· (Hz)", f"{vf.get('pitch_mean',0):.1f}")
        d2.metric("ì—ë„ˆì§€(mean)", f"{vf.get('energy_mean',0):.3f}")
        d3.metric("ë§í•˜ê¸° ì†ë„(BPM)", f"{vf.get('tempo',0):.0f}")
        d4.metric("HNR", f"{vf.get('hnr',0):.1f}")
        st.caption("â€» ì´ ìˆ˜ì¹˜ëŠ” ìƒíƒœ ë‹¨ì„œë¡œë§Œ ì‚¬ìš©ë˜ë©° ê°ì • ë¼ë²¨ì„ ì§ì ‘ ê²°ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

elif page == "ğŸ’– ë§ˆìŒ ë¶„ì„":
    st.header("ë§ˆìŒ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ì•„ì§ ì—†ì–´ìš”.")
    else:
        df = pd.DataFrame([
            {"date": e["date"], "time": e["time"], "emotions": ", ".join(e["analysis"].get("emotions", [])), "stress": e["analysis"].get("stress_level", 0), "energy": e["analysis"].get("energy_level", 0), "mood": e["analysis"].get("mood_score", 0), "tone": e["analysis"].get("tone", "ì¤‘ë¦½ì "), "confidence": e["analysis"].get("confidence", 0.6)}
            for e in st.session_state.diary_entries
        ])
        st.dataframe(df, use_container_width=True, hide_index=True)

elif page == "ğŸ“ˆ ê°ì • ì—¬ì •":
    st.header("ì‹œê°„ì— ë”°ë¥¸ ë³€í™”")
    if not st.session_state.diary_entries:
        st.info("ê¸°ë¡ì´ ìŒ“ì´ë©´ ì¶”ì„¸ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”.")
    else:
        df = pd.DataFrame([
            {"dt": f"{e['date']} {e['time']}", "stress": e["analysis"].get("stress_level", 0), "energy": e["analysis"].get("energy_level", 0), "mood": e["analysis"].get("mood_score", 0)}
            for e in st.session_state.diary_entries
        ])
        st.line_chart(df.set_index("dt"))
        st.caption("â€» ì„±ëŠ¥ì„ ìœ„í•´ ë‚´ì¥ ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

elif page == "ğŸ“š ë‚˜ì˜ ì´ì•¼ê¸°ë“¤":
    st.header("ì•„ì¹´ì´ë¸Œ")
    if not st.session_state.diary_entries:
        st.info("ì•„ì§ ê¸°ë¡ëœ ì´ì•¼ê¸°ê°€ ì—†ì–´ìš”.")
    else:
        for e in reversed(st.session_state.diary_entries[-20:]):
            with st.expander(f"{e['date']} {e['time']} Â· {', '.join(e['analysis'].get('emotions', []))}"):
                st.write(e["text"])
                st.json({k: e["analysis"][k] for k in ["stress_level", "energy_level", "mood_score", "tone", "confidence"]})
                if e.get("mental_state"):
                    st.write("â€” ì½”ì¹˜ ìš”ì•½: " + e["mental_state"].get("summary", ""))

# =============================
# Sidebar: Export / Reset
# =============================
with st.sidebar:
    if st.session_state.diary_entries:
        st.markdown("---")
        if st.button("ğŸ“ CSV ë‚´ë³´ë‚´ê¸°"):
            rows: List[Dict] = []
            for e in st.session_state.diary_entries:
                a = e["analysis"]
                row = {"date": e["date"], "time": e["time"], "text": e["text"], "emotions": ", ".join(a.get("emotions", [])), "stress": a.get("stress_level", 0), "energy": a.get("energy_level", 0), "mood": a.get("mood_score", 0), "tone": a.get("tone", "ì¤‘ë¦½ì "), "confidence": a.get("confidence", 0.6)}
                if e.get("mental_state"):
                    ms = e["mental_state"]
                    row.update({"state": ms.get("state", ""), "ms_summary": ms.get("summary", ""), "ms_recommendations": " | ".join(ms.get("recommendations", []))})
                if a.get("voice_analysis"):
                    v = a["voice_analysis"]; vc = v["voice_cues"]; vf = v["voice_features"]
                    row.update({"arousal": vc.get("arousal", ""), "tension": vc.get("tension", ""), "stability": vc.get("stability", ""), "quality": vc.get("quality", ""), "pitch_mean": vf.get("pitch_mean", ""), "energy_mean": vf.get("energy_mean", ""), "tempo": vf.get("tempo", ""), "hnr": vf.get("hnr", "")})
                rows.append(row)
            df = pd.DataFrame(rows)
            csv = df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button("ë‹¤ìš´ë¡œë“œ", csv, file_name=f"voice_diary_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv")
        if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ë¡ ì‚­ì œ"):
            st.session_state.diary_entries = []
            st.success("ëª¨ë“  ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# =============================
# Footer
# =============================
st.markdown("---")
st.caption("Made with â¤ï¸ Â· ê°ì • ë¼ë²¨ì€ í…ìŠ¤íŠ¸ ìš°ì„  Â· ëª©ì†Œë¦¬ëŠ” ê°ì„±/ê¸´ì¥/ì•ˆì •ì˜ ë³´ì¡° ì§€í‘œë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
